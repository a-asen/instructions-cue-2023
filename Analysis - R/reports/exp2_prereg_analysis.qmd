---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data, include=FALSE, warning=FALSE}
library(tidyverse)    # Wraggling
library(broom)        # Tidying
library(afex)         # ANOVA
library(lme4)         # Regression mixed models
library(gt)           # Tables
library(BayesFactor)  # Bayesian model (bayes model selection)
library(rstatix)      # Outliers (other?)
library(brms)         # Bayes coefficients 
library(cmdstanr)       # stan
library(bayesplot)    # plots
library(emmeans)
library(pbapply)      # Progresion bar
library(bayestestR)
library(glue)
# library(ggpp)

source("../lib/helper_functions.R")
```

```{r parameters, include=FALSE}
run_bayesian_models <- FALSE
save_bayes_models <- FALSE
```

```{r load data, include=FALSE, message=FALSE}
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames, \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics

```{r , include=FALSE}
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(Sex=="Female"),
    female = sum(Sex=="Male"),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem

# demo |> mutate(n = 1:length(demo$Age)) -> ddemo
# 
# map(1:length(ddemo$Age), \(x){
#   l2 <- ddemo[-x,]
#   map(1:length(l2$Age), \(y){
#     l3 <- ddemo[-y,]
#     
#   }) |> list_rbind()
# }) |> list_rbind()
```

We recruited `r length(demo$Age)`, participants from the
United Kingdom via Prolific. Participants had an average age of `r dem$age` (SD = `r dem$age_sd`; `r dem$female`
females). Note that three participants were excluded from the data analysis, but cannot
be removed from the demographics due to non-connections
between data points and demographics variables.

# Data preparation

```{r prep base data, echo=FALSE}
d <- d_ex <- 
  exp2_d |> 
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, post_cue, congruent, rt, correct_response) |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  mutate(rt = as.integer(ifelse(rt=="null", NA,rt)),
         inducer_run = as.integer(inducer_run))
```

## Exclusion

```{r exclusion start - accuracy, include=FALSE}
loss <- list()
loss$raw_data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d_ex |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d_ex <- d_ex |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d_ex <- d_ex |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded,
representing `r loss[["inducer_practice_prop"]]` percent of
the data.

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (\> 30% error).

```{r due to high SD & NA responses, include=FALSE}
# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d_ex <- d_ex |>
  left_join(
    by = c("id","inducer_run","diagnostic_run"),
    d_ex |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id,
        rt_crit_low   = mean(rt, na.rm=T) - sd(rt, na.rm=T) * 2.5,
        rt_crit_high  = mean(rt, na.rm=T) + sd(rt, na.rm=T) * 2.5,
        rt_crit = ifelse( ( (rt >= rt_crit_high) | (rt <= rt_crit_low) ), 1, NA ),
        rt_na = ifelse(is.na(rt), 1, NA)
      ) |>
      dplyr::select(id,inducer_run, diagnostic_run, rt_crit, rt_na)
  )

# lost trials
loss$rt_sd_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(rt_crit == 1 | rt_na==1) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100

# Exclude
d_ex <- d_ex |>
  filter( is.na(rt_crit) & is.na(rt_na) ) |>
  dplyr::select(-rt_crit, -rt_na)
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.

```{r only correct inducers, include=FALSE}
d_ex <- d_ex |>
  mutate( valid_trials = case_when( 
    trial_info=="Inducer trial" & correct_response==1 ~ 1,
    trial_info=="Inducer trial" & correct_response==0 ~ 0,
    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
      # non-responses count as a wrong response
    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()

loss$inducer_fail_prop <-
  loss$inducer_fail_trials / loss$data_trials * 100


loss$total_lost_trials <- loss$inducer_practice_trials + loss$rt_sd_trials + loss$inducer_fail_trials
loss$total_lost_prop <- loss$inducer_practice_prop + loss$rt_sd_prop + loss$inducer_fail_prop

d_ex <-
  d_ex |>
  filter( valid_trials == 1 ) |>
  dplyr::select(-valid_trials)
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials`
trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)`
percent of the data.

### Paragraph

The exclusion criteria resulted in the removal of
`r fmt_APA_numbers(loss$total_lost_prop)` %
(`r loss$total_lost_trials` trials) of the data. The first
round was considered practice and resulted in the loss of
`r fmt_APA_numbers(loss$inducer_practice_prop)` %
(`r loss$inducer_practice_trials` trials), while highly
deviating response times and non-responses accounted for
`r fmt_APA_numbers(loss$rt_sd_prop)` % (`r loss$rt_sd_trials`
trials), and a wrong response on the inducer trial resulted in
a loss of `r fmt_APA_numbers(loss$inducer_fail_prop)` %
(`r loss$inducer_fail_trials` trials).

# Analysis

```{r calculate BIS and LISAS, echo=FALSE}
# Liesefeld, H. R., & Janczyk, M. (2023). Same same but different: Subtle but consequential differences between two measures to linearly integrate speed and accuracy (LISAS vs. BIS). Behavior Research Methods, 55(3), 1175â€“1192. https://doi.org/10.3758/s13428-022-01843-2

# Grand:
grand <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    g_rt    = mean(rt),
    g_rt_sd = sd(rt),
    g_pc    = mean(correct_response),
    g_pe    = 1 - g_pc,
    g_pc_sd = sd(correct_response) 
  )
  
# LISAS: 
lisas <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    .by = id,
    l_rt_sd = sd(rt),
    l_pe_s  = sqrt( mean(correct_response) * (1 - mean(correct_response)) )
  )  

# Calculation
d_ex_test <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarise(
    .by = c(id, post_cue, congruent), 
    rt_sd   = sd(rt),
    rt      = mean(rt),
    pe_sd   = sd(correct_response),
    pe      = 1 - mean(correct_response),
    pc      = mean(correct_response),
  ) |> 
  left_join(lisas, by="id") |> 
  bind_cols(grand) |>
  mutate(
    lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe), 
    bis    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ),
    inv_bis = bis*-1,
  ) |> 
  dplyr::select(id, post_cue, congruent, rt, rt_sd, pe, pe_sd, lisas, bis, inv_bis)
```

```{r why we have one more than expected, echo=FALSE}
# Why do we have 35? 
d_ex |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 

d |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 
  
table(d_ex$inducer_run)
d_ex |> 
  group_by(id, inducer_run) |>
  summarise(n()) 
```

## Visualize 

```{r data vis calculation, include=FALSE}
data_vis <- 
  d_ex_test |> 
  mutate(
    Cue = ifelse(post_cue==T, 1,0),
    Congruency = fct_relevel( ifelse(congruent==F, "Incongruent", "Congruent"), "Incongruent"),
    bis_inv = -1 * bis,
    con = ifelse(congruent==T, 1,0),
  ) |>
  rename(`Response time` = rt, `Error rate` = pe, LISAS = lisas, BIS = bis_inv) |>
  pivot_longer(c(`Response time`,`Error rate`, LISAS, BIS)) |>
  mutate(name = fct_relevel(name, "Response time", "Error rate", "LISAS", "BIS"))
```

```{r visualize across all, echo=FALSE}
#| fig-width: 8
#| fig-height: 8
#| fig-dpi: 300
data_vis |>
  ggplot(aes(Cue, value, col = Congruency)) +
  facet_wrap(~name, scales="free") + 
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25))+
  labs(x=NULL, y="")+
  theme_bw()
```

```{r bar plot, echo=FALSE}
data_vis |>   
  filter(name == "Response time") |>
  ggplot(aes(Cue, value, fill = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="col", width=.75)+
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="errorbar", width=.5) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.4,1.40), ylim=c(550, 750))+
  labs(x = NULL, y="Response time")+
  theme_bw()
```

## Statistical test

### Normality

```{r calculate residual distribution, echo=FALSE}
residual_norm <- 
  d_ex_test |> 
  pivot_longer(c(rt,pe,lisas,bis)) |>
  reframe(
    .by = name, 
    id = id,
    residuals = resid( lmer( value ~ post_cue + congruent + post_cue:congruent + (1|id) ) )
  ) 
```

```{r residual qqplot, echo=FALSE}
residual_norm |>
  ggplot(aes(sample = residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_qq() +
  geom_qq_line()
```

```{r residual histogram, echo=FALSE}
residual_norm |>
  ggplot(aes(residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_histogram()
```

Generally, the residual errors seems to be normally distributed around 0. There are a couple of outliers, but they are also uniform (i.e., as much on both sides), albeit for the Errors with a slight skew. 

```{r raw distribution, include=FALSE}
d_ex_test |> 
  mutate(Cue = ifelse(post_cue==T, "Post", "Pre"),
         Congruency = fct_relevel(ifelse(congruent==T, "Congruent", "Incongruent"), "Congruent", after=1)) |>
  pivot_longer(c(rt,pe,lisas,inv_bis)) |>
  ggplot(aes(value, col = Congruency)) + 
  facet_wrap(name ~ Cue, scales="free", ncol=2) +
  geom_density()
```

### Outliers
```{r difference distribution, echo=FALSE}
d_ex_test |> 
  mutate(cue = ifelse(post_cue==T, "post","pre"),
         congruent = ifelse(congruent==T, "Congruent", "Incongruent")) |>
  dplyr::select(-rt_sd,-pe_sd, -inv_bis,-post_cue) |>
  pivot_longer(c(rt,pe,bis,lisas)) |> 
  pivot_wider(
    names_from=c(cue, congruent), 
    values_from=c(value) 
  ) |>
  mutate(
    pre_diff   = pre_Incongruent - pre_Congruent,
    post_diff  = post_Incongruent - post_Congruent,
  ) -> d_ex_test_diff

d_ex_test_diff |>
  pivot_longer(c(pre_diff,post_diff),names_to="name2") |>
  ggplot(aes(y=value, col=name2))+
  facet_wrap(~name, scales="free")+
  geom_boxplot()+
  labs(col="Cue")
```

```{r finding outliers and extreme outliers, echo=FALSE}
# Exclude outliers
outlier_values <-
  d_ex_test_diff |> 
  pivot_longer(c(pre_diff, post_diff), names_to="name2") |>
  group_by(name)  |>
  identify_outliers(value)

id_is_outlier <- outlier_values |> filter(is.outlier==T) |> pull(id) |> unique()
id_is_extreme <- outlier_values |> filter(is.extreme==T) |> pull(id) |> unique()
```

Some outliers, check without. 

### Frequentist rmANOVA
Statistical test of all 35 participants:

#### Table

```{r transform data object output, include=FALSE}
aovs <- list()
trns_mod <- function(data){
  d <- data$anova_table
  
  Fname <- paste0(
    "F (", unique(d$`num Df`), ",",
     unique(d$`den Df`),")" )
  
  d |> 
    mutate(names = c("Congrunecy","Cue", "Congruency_X_Cue")) |> 
    rename(!!Fname := `F`, p = `Pr(>F)`) |>
    dplyr::select(names, all_of(Fname), p, pes) |> 
    mutate(across(2, ~fmt_APA_numbers(.x, .chr=T)),
           p = fmt_APA_numbers(p, .p=T),
           pes = fmt_APA_numbers(pes, .low_val=T)) |> 
    as_tibble()
}

freq_test <- function(data, dep){
  aov_car(
    as.formula(glue::glue("{dep} ~ Error(id/(congruent*post_cue))")),
    data, 
    detailed=T, anova_table = list(es="pes"))
}

```

```{r frequent rmanova models, echo=FALSE}
aovs$rt <- freq_test(d_ex_test, "rt")
aovs$pe <- freq_test(d_ex_test, "pe")
aovs$lisas <- freq_test(d_ex_test, "lisas")
aovs$bis <- freq_test(d_ex_test, "bis")
```

```{r table rmanovas, echo=FALSE}
trns_mod(aovs$rt) |> 
  mutate(group="Response time") |>
  bind_rows(
    trns_mod(aovs$pe) |> mutate(group="Error rate") ) |>
  bind_rows(
    trns_mod(aovs$lisas) |> mutate(group="LISAS") ) |>
  bind_rows(
    trns_mod(aovs$bis) |> mutate(group="BIS") ) |>
  pivot_wider(names_from = group, values_from = c(`F (1,34)`, p, pes)) |>
  dplyr::select(names, ends_with("Error rate"), 
                ends_with("Response time"), 
                ends_with("LISAS"), ends_with("BIS")) |>
  mutate(e="",e2="",e3="",e4="") |>
  gt() |>
  cols_move(c(`F (1,34)_Response time`, `p_Response time`, `pes_Response time`), names) |> 
  tab_spanner(
    "Response time", c(`F (1,34)_Response time`, `p_Response time`, `pes_Response time`)) |>
  tab_spanner(
    "Error rate", c(`F (1,34)_Error rate`, `p_Error rate`, `pes_Error rate`)) |>
  tab_spanner("LISAS", c(`F (1,34)_LISAS`, `p_LISAS`, `pes_LISAS`)) |>
  tab_spanner("BIS", c(`F (1,34)_BIS`, `p_BIS`, `pes_BIS`)) |>
  cols_move(e, `pes_Response time`) |> 
  cols_move(e2, `pes_Error rate`) |> 
  cols_move(e3, `pes_LISAS`) |> 
  cols_move(e4, `pes_BIS`) |> 
  cols_label(
    `F (1,34)_BIS` = md("*F*(1,34)"), `F (1,34)_LISAS` = md("*F*(1,34)"), 
    `F (1,34)_Response time` = md("*F*(1,34)"), `F (1,34)_Error rate` = md("*F*(1,34)"), 
    p_LISAS = md("*p*"), p_BIS = md("*p*"), `p_Error rate`= md("*p*"), 
    `p_Response time` = md("*p*"), `pes_Error rate` = "n^2", `pes_Response time` = "n^2", 
    pes_LISAS = "n^2", `pes_BIS`="n^2", names = "Variables",
    e="", e2="",e3="",e4="") |>
  cols_align("center", 2:13) |>
  tab_header("Results for the whole sample", ) |>
  tab_footnote("dawd")
```

```{r long-table frequentist rmanova, echo=FALSE}
trns_mod(aovs$rt) |> 
  mutate(group="Response time") |>
  bind_rows(
    trns_mod(aovs$pe) |> mutate(group="Error rate") ) |>
  bind_rows(
    trns_mod(aovs$lisas) |> mutate(group="LISAS") ) |>
  bind_rows(
    trns_mod(aovs$bis) |> mutate(group="BIS") ) |>
  gt(groupname_col = "group") |>
  cols_label(p = md("*p*"), pes = "n^2",) |>
  cols_align("center", 2:5) |>
  tab_header("Results for the whole sample", ) |>
  tab_footnote("dawd")
```


##### Pairwise test

```{r tukey test list, include=FALSE}
tuk_t <- list()

par_test <- function(dep){
  emmeans(tuk_t[[dep]], pairwise ~ congruent * post_cue) -> test
  test$contrasts |>
    as_tibble() |> 
    mutate(n=1:6) |> 
    filter(n<4) |> 
    mutate(.before=1,name=c("Congruency","Cue","Congruency_X_Cue"), n=NULL, contrast=NULL,
           group=dep)
}
```

```{r linear mixed-effect model , include=FALSE}
tuk_t$rt <- lmer(rt ~ post_cue * congruent + (1|id), d_ex_test)
tuk_t$pe <- lmer(pe ~ post_cue * congruent + (1|id), d_ex_test)
tuk_t$lisas <- lmer(lisas ~ post_cue * congruent  + (1|id), d_ex_test)
tuk_t$bis <- lmer(bis ~ post_cue * congruent+ (1|id), d_ex_test)
```

```{r wide-table - linear mixed-effect model , echo=FALSE}
par_test("rt") |>
  bind_rows( par_test("pe") ) |> 
  bind_rows( par_test("lisas") ) |>
  bind_rows( par_test("bis") ) |>
  pivot_wider(names_from=group, values_from=c(estimate,SE,df,t.ratio,p.value)) |>
  mutate(
    across(c(starts_with("SE"), starts_with("t.rat"), starts_with("est")) , ~fmt_APA_numbers(.x, .chr=T)),
    across(starts_with("p.value"), ~fmt_APA_numbers(.x, .p=T)),
    em="",em2="",em3="",em4="") |>
  gt() |>
  tab_spanner("Response time", c(estimate_rt, df_rt, SE_rt, t.ratio_rt, p.value_rt)) |>
  tab_spanner("Error rate", c(estimate_pe, df_pe, SE_pe, t.ratio_pe, p.value_pe)) |>
  tab_spanner("LISAS", c(estimate_lisas, df_lisas, SE_lisas, t.ratio_lisas, p.value_lisas)) |>
  tab_spanner("BIS", c(estimate_bis, df_bis, SE_bis, t.ratio_bis, p.value_bis)) |>
  cols_label(starts_with("SE") ~ ("SE"), starts_with("estimate") ~ "Est.",
             starts_with("df") ~ md("df"), starts_with("p.value") ~ md("*p*"),
             starts_with("t.ratio") ~ md("*t*" )) |>
  cols_hide(c(starts_with("SE"), starts_with("df"), starts_with("em"))) |>
  cols_move(em, p.value_rt) |> 
  cols_move(em2, p.value_pe) |>
  cols_move(em3, p.value_lisas) |>
  cols_move(em4, p.value_bis) |>
  cols_align("center", 2:25)
```

```{r long-table - linear mixed-effect model , echo=FALSE}
par_test("rt") |>
  bind_rows( par_test("pe") ) |> 
  bind_rows( par_test("lisas") ) |>
  bind_rows( par_test("bis") ) |>
  mutate(
    across(2:6, ~fmt_APA_numbers(.x, .chr=T)),
    across(7, ~fmt_APA_numbers(.x, .p=T)),
    group=case_when(
      group=="rt"~ "Response time", 
      group=="pe"~"Error rate",
      group=="lisas" ~ "LISAS",
      group=="bis" ~ "BIS" ,
    )
  ) |>
  gt(groupname_col = "group") |>
  cols_label(
    "estimate" ~ "Est.",
    "t.ratio" = md("*t*"),
    p.value = md("*p*") ) |>
  cols_hide(c("SE", "df")) |>
  cols_align("center", 2:7)
```


##### Paragarph

```{r use this bfr paragraph, include=FALSE}
text_report <- function(data){
  data[["anova_table"]] |> 
    as_tibble() |>
    mutate(
      `F` = fmt_APA_numbers(`F`, .chr=T),
      `pes` = fmt_APA_numbers(`F`, .low_val=T ),
      `Pr(>F)` = fmt_APA_numbers(`Pr(>F)`, .psym=T ),
    ) 
}

aov_report <- list()
aov_report$rt <- text_report(aovs$rt) 
aov_report$pe <- text_report(aovs$pe) 
aov_report$lisas <- text_report(aovs$lisas) 
aov_report$bis <- text_report(aovs$bis) 
```

---

The rmANOVA for response time revealed a significant effect of
Congruency (*F*\~`r aov_report$rt[["num Df"]][1]`, `r aov_report$rt[["den Df"]][1]`\~ =
`r aov_report$rt$F[1]`, *p* `r aov_report$rt[["Pr(>F)"]][1]`, $\eta_p^2$ = `r aov_report$rt[["pes"]][1]`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r aov_report$rt[["num Df"]][2]`, `r aov_report$rt[["den Df"]][2]`\~ =
`r aov_report$rt$F[2]`, *p* `r aov_report$rt[["Pr(>F)"]][2]`, $\eta_p^2$ =
`r aov_report$rt[["pes"]][2]`), nor an interaction effect
(*F*\~`r aov_report$rt[["num Df"]][3]`, `r aov_report$rt[["den Df"]][3]`\~ =
`r aov_report$rt$F[3]`, *p* `r aov_report$rt[["Pr(>F)"]][3]`, $\eta_p^2$ =`r aov_report$rt[["pes"]][3]`).

---

The rmANOVA for error revealed a significant effect of
Congruency (*F*\~`r aov_report$pe[["num Df"]][1]`,
`r aov_report$pe[["den Df"]][1]`\~ =
`r aov_report$pe$F[1]`, *p*
`r aov_report$pe[["Pr(>F)"]][1]`,
$\eta_p^2$ =
`r aov_report$pe[["pes"]][1]`),
suggesting lower errors for congruent trials. As for the cue, there was not revealed a main effect of Cue
(*F*\~`r aov_report$pe[["num Df"]][2]`,
`r aov_report$pe[["den Df"]][2]`\~ =
`r aov_report$pe$F[2]`, *p*
`r aov_report$pe[["Pr(>F)"]][2]`,
$\eta_p^2$ =
`r aov_report$pe[["pes"]][2]`),
nor an interaction effect
(*F*\~`r aov_report$pe[["num Df"]][3]`,
`r aov_report$pe[["den Df"]][3]`\~ =
`r aov_report$pe$F[3]`, *p*
`r aov_report$pe[["Pr(>F)"]][3]`,
$\eta_p^2$ =
`r aov_report$pe[["pes"]][3]`).

The rmANOVA for the LISAS revealed a main effect of
Congruency (*F*\~`r aov_report$lisas[["num Df"]][1]`,
`r aov_report$lisas[["den Df"]][1]`\~ =
`r aov_report$lisas$F[1])`, *p*
`r aov_report$lisas[["Pr(>F)"]][1]`,
$\eta_p^2$ =
`r aov_report$lisas[["pes"]][1]`) and Cue
(*F*\~`r aov_report$lisas[["num Df"]][2]`,
`r aov_report$lisas[["den Df"]][2]`\~ =
`r aov_report$lisas$F[2]`, *p*
`r aov_report$lisas[["Pr(>F)"]][2]`,
$\eta_p^2$ =
`r aov_report$lisas[["pes"]][2]`). Suggesting that congruent trials had lower LISAS and post-cue trials had higher LISAS. However, no interaction term was revealed 
(*F*\~`r aov_report$lisas[["num Df"]][3]`,
`r aov_report$lisas[["den Df"]][3]`\~ =
`r aov_report$lisas$F[3]`, *p*
`r aov_report$lisas[["Pr(>F)"]][3]`,
$\eta_p^2$ =
`r aov_report$lisas[["pes"]][3]`).

The rmANOVA for the BIS revealed a significant effect of
Congruency (*F*\~`r aov_report$bis[["num Df"]][1]`,
`r aov_report$bis[["den Df"]][1]`\~ =
`r aov_report$bis$F[1]`, *p*
`r aov_report$bis[["Pr(>F)"]][1]`,
$\eta_p^2$ =
`r aov_report$bis[["pes"]][1]`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r aov_report$bis[["num Df"]][2]`,
`r aov_report$bis[["den Df"]][2]`\~ =
`r aov_report$bis$F[2]`, *p*
`r aov_report$bis[["Pr(>F)"]][2]`,
$\eta_p^2$ =
`r aov_report$bis[["pes"]][2]`),
nor an interaction effect
(*F*\~`r aov_report$bis[["num Df"]][3]`,
`r aov_report$bis[["den Df"]][3]`\~ =
`r aov_report$bis$F[3]`, *p*
`r aov_report$bis[["Pr(>F)"]][3]`,
$\eta_p^2$ =
`r aov_report$bis[["pes"]][3]`).

#### Sample n=34 tests

Since we preregistered a sample of 34, but do not know which
participant to remove, we include tests of all data with n-1.
We then report the minimum and maximum F and p value for the
conditions and interaction.

```{r id list, include=FALSE }
d_ex_test |> 
  pull(id) |> unique() -> id_list
freq_n34 <- list()
```

```{r function to repeat test, echo=FALSE, warning=FALSE}
freq_n34_test <- function(dep){
  map_df(1:35, \(x){
    d <- d_ex_test |> filter(!(id == id_list[x])) 
    an <- freq_test(d, dep)
    an[["anova_table"]] |>
      as_tibble() |>
      mutate(
        .before=1,
        group = dep,
        rm_id = id_list[x],
        names = rownames(an[["anova_table"]])
      )
  })
}
```

```{r long-table anovas with one participant removed, echo=FALSE, warning=FALSE}
freq_n34$rt <- freq_n34_test("rt")
freq_n34$pe <- freq_n34_test("pe")
freq_n34$lisas <- freq_n34_test("lisas")
freq_n34$bis <- freq_n34_test("bis")

freq_n34 |> 
  list_rbind() |>
  mutate(
    names = case_when(
      names=="congruent"~"Congruency", 
      names=="post_cue"~"Cue",
      names=="congruent:post_cue" ~ "Cue X Congruency"
    ),
    group = case_when(
      group=="rt"~"Response time",
      group=="pe"~"Error rate",
      group=="lisas"~"LISAS",
      group=="bis"~"BIS",
    )
  ) |>
  summarise(
    .by = c(group, names),
    minF = min(`F`),
    maxF = max(`F`),
    maxP = max(`Pr(>F)`),
    minP = min(`Pr(>F)`),
    minpe = min(pes),
    maxpe = max(pes)
  ) |>
  mutate(
    across(3:8, ~fmt_APA_numbers(.x, .chr=T)),
    zz="",zz2=""
  ) |>
  gt(groupname_col = "group") |>
  tab_spanner("F test", ends_with("F")) |>
  tab_spanner(md("*p*-value"), ends_with("P")) |>
  tab_spanner("n^2", ends_with("pe")) |>
  cols_move(zz, maxF) |>
  cols_move(zz2, minP) |>
  cols_label(
    starts_with("min") ~ "Min", 
    starts_with("max") ~ "Max",
    "zz"="", "zz2"=""
  ) |>
  cols_align("center", 2:10) |>
  tab_header("Summary of the F and p value for all 34 combinations of the rmANOVA") |>
  tab_footnote("Resulting F and p value for all combinations of a 34 participant sample size")
```

#### Robustness check

```{r remove outliers and test, echo=FALSE}
o_rt_aov <- aov_car(rt ~ Error(id/(congruent*post_cue)), 
                    d_ex_test |> 
                      filter(!(id %in% id_is_outlier)), detailed=T, 
                    anova_table = list(es="pes"))

o_pe_aov <- aov_car(pe ~ Error(id/(congruent*post_cue)), 
                  d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                  anova_table = list(es="pes"))

o_lisas_aov <- aov_car(lisas ~ Error(id/(congruent*post_cue)), 
                     d_ex_test |> 
                       filter(!(id %in% id_is_outlier)), detailed=T, 
                     anova_table = list(es="pes"))

o_bis_aov <- aov_car(bis ~ Error(id/(congruent*post_cue)), 
                   d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                   anova_table = list(es="pes"))
```

```{r wide-table - remove outliers and test, echo=FALSE}
trns_mod(o_rt_aov) |> 
  mutate(group="Response time") |> 
  bind_rows(
    trns_mod(o_pe_aov) |> 
      mutate(group = "Error rate") 
  ) |>
  bind_rows(
    trns_mod(o_lisas_aov) |>
      mutate(group="LISAS")
  ) |>
  bind_rows(
    trns_mod(o_bis_aov) |>
      mutate(group="BIS")
  ) |> 
  pivot_wider(names_from=group, values_from = c(`F (1,25)`, p, pes) ) |>
  mutate(zz="",zz2="",zz3="",zz4="") |>
  gt() |>
  tab_spanner("Response time", ends_with("Response time")) |>
  tab_spanner("Error rate", ends_with("Error rate")) |>
  tab_spanner("LISAS", ends_with("LISAS")) |>
  tab_spanner("BIS", ends_with("BIS")) |>
  cols_label(
    starts_with("F (1,25)") ~ "F (1,25)", 
    starts_with("pes") ~ "n^2",
    starts_with("p_") ~ md("*p*"),
    starts_with("zz") ~ "",
  ) |>
  cols_move(zz, "pes_Response time") |>
  cols_move(zz2, "pes_Error rate") |>
  cols_move(zz3, "pes_LISAS") |>
  cols_move(zz4, "pes_BIS") |>
  cols_align("center", 2:10) |>
  tab_header("Outliers removed from the rmANOVA") |>
  tab_footnote("Outliers removed")
```

```{r long-table - remove outliers and test, echo=FALSE}
trns_mod(o_rt_aov) |> 
  mutate(group="Response time") |> 
  bind_rows(
    trns_mod(o_pe_aov) |> 
      mutate(group = "Error rate") 
  ) |>
  bind_rows(
    trns_mod(o_lisas_aov) |>
      mutate(group="LISAS")
  ) |>
  bind_rows(
    trns_mod(o_bis_aov) |>
      mutate(group="BIS")
  ) |> 
  gt(groupname_col = "group") |>
  cols_label(
    "pes" = "n^2",
    p = md("*p*"),
  ) |>
  cols_align("center", 2:4) |>
  tab_header("Outliers removed from the rmANOVA") |>
  tab_footnote("Outliers removed")
```

### Bayesian Analyses 

#### Coefficients
```{r bayesian functions, include=FALSE}
bayes_plot <- function( data_list, rm_vars = NULL, par_match = TRUE){
  #' @param rm_vars   Vector string. Remove variables from coefficient plot 
  #' @param par_match Partial matching of rm_vars
  
  if(par_match){
    map(rm_vars, \(var){
       variables(data_list)[str_detect(variables(data_list), var)]
    }) |> unlist() -> remove_variables
  } else {
    remove_variables <- rm_vars
  }
  
  int <- variables(data_list)[str_detect(variables(data_list), "Intercept")]
  remove_list <- c(c("disc","lp__", "lprior"), remove_variables, int)
  gpars <- setdiff(variables(data_list), remove_list)
  brms::rhat(data_list) -> b
  
  if(max(b, na.rm=T) > 1.01){
    print(paste("max:", max(b, na.rm=T), " <- High, check model"))
  } else {
    print(paste("max:", max(b, na.rm=T)))
  }
  print(paste("mean:", mean(b, na.rm=T)))
  print(paste("median:", median(b, na.rm=T)))
  
  bayesplot::mcmc_intervals(as.matrix(data_list), pars=gpars, prob_outer = 0.95) + 
    geom_vline(xintercept = 0, linetype = "dashed", )+
    labs(title = colnames(data_list$data)[1])
}

# BAYES MODEL
bayes_run_model <- function(data, dep){
  bay_mod <- brm(
    as.formula(glue::glue("{dep} ~ congruent + post_cue + congruent:post_cue + (1|id)")),
    data, # data  
    save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6,
    iter = 6000, chains = 6, init=0)
}

bayes_diag <- function(model, range){
  vars <- variables(model)[range]
  
  list(
    rhat = mcmc_rhat(brms::rhat(model)[range]),         # Chains at equilibrium? 
    neff = mcmc_neff(brms::neff_ratio(model)[range]),   # Ratio of effective sample size
    acf = mcmc_acf(as.array(model), pars=vars),   # autocorrelation
    trace = mcmc_trace(as.array(model), pars=vars) # mcmc draws
  )
}

# COEFFICIENT
bay_eff_prob <- function(model, var){
  # Get the probability that the effect ({var}) is positive/negative
  da <- as.matrix(model) 
  m <- mean(da[, var])
  
  if(m >= 0){
    fmt_APA_numbers( (sum( da[, var]>=0 ) / length( da[, var])), .p=T )
  } else if(m<0){
    paste0("-", 
      fmt_APA_numbers( 1 - sum(da[, var]>=0) / length(da[, var]), .p=T ) 
    )
  }
}

bay_erate <- function(model, var){
  # Estimate the evidence ration
  da <- as.matrix(model) 
  m <- mean(da[, var])
  
  if(m>=0){
    fmt_APA_numbers( 
      sum(da[, var]>=0) / sum(da[, var]<0), 
      .chr=T
    )
  } else if(m<0){
    paste0(
      "-",
      fmt_APA_numbers(
        sum(da[, var]<=0) / sum(da[, var]>0),
        .chr=T
      )
    )
  }
}

bayes_coefs_to_table <- function(model, group){
  fixef(model) |> 
  as_tibble() |> 
  mutate(
    .before=1, 
    names = rownames(fixef(co_bay$rt)), 
    across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
    Est.Error=NULL,
    group=group) |>
  mutate(
    .after="Estimate", 
    pdir = map_vec(colnames(as.matrix(model))[1:4], 
                    \(x){ bay_eff_prob(model, x) }),
    erat = map_vec(colnames(as.matrix(model))[1:4], 
                    \(x){ bay_erate(model, x) }) ) |>
  filter(!(names=="Intercept"))
}
```

```{r bayesian list vars , include=FALSE}
if(!run_bayesian_models){ 
  load(file = "../data/processed/exp2_bayesian_models.Rdata") 
} else if (run_bayesian_models) {
  co_bay <- list()
}
coefs <- list()
```

```{r rt bay coefs, echo=FALSE, warning=FALSE, message=FALSE}
if(run_bayesian_models){
  co_bay$rt <- bayes_run_model(d_ex_test, "rt")
  
  bayes_diag(co_bay$rt, 1:4)
  # looks ok
}

coefs$rt <- bayes_coefs_to_table(co_bay$rt, "rt")
```

```{r pe bay coefs , echo=FALSE, warning=FALSE, message=FALSE}
if(run_bayesian_models){
  co_bay$pe <- bayes_run_model(d_ex_test, "pe")
  
  bayes_diag(co_bay$pe, 1:4)
  # looks good
}

coefs$pe <- bayes_coefs_to_table(co_bay$pe, "pe")
```

```{r lisas bay coefs, echo=FALSE, warning=FALSE, message=FALSE}
if(run_bayesian_models){
  co_bay$lisas <- bayes_run_model(d_ex_test, "lisas")
  
  bayes_diag(co_bay$lisas, 1:4)
  # looks good
}

coefs$lisas <- bayes_coefs_to_table(co_bay$lisas, "lisas")
```

```{r bis bay coefs, echo=FALSE, warning=FALSE, message=FALSE}
if(run_bayesian_models){
  co_bay$bis <- bayes_run_model(d_ex_test, "bis")
  
  bayes_diag(co_bay$bis, 1:4)
  # looks good
}

coefs$bis <- bayes_coefs_to_table(co_bay$bis, "bis")
```

```{r save models if set, include=FALSE}
if(run_bayesian_models & save_bayes_models){
  save(co_bay, file = "../data/processed/exp2_bayesian_models.Rdata") 
}
```

```{r wide-table of bayesian coefs, echo=FALSE, warning=FALSE, message=FALSE} 
coefs |> 
  list_rbind() |>
  pivot_wider(names_from=group, values_from=c(Estimate, Q2.5,Q97.5, erat, pdir)) |>
  mutate(
    names=case_when(
      names=="congruentTRUE" ~ "Congruency",
      names=="post_cueTRUE"~"Cue", 
      T ~ "Cue_X_Congruency"),
    zz="",zz2="",zz3="",zz4="",
  ) |>
  gt() |>
  tab_spanner("HDI", c(Q2.5_rt, Q97.5_rt)) |>
  tab_spanner("HDI ", c(Q2.5_pe, Q97.5_pe)) |>
  tab_spanner("HDI  ", c(Q2.5_lisas, Q97.5_lisas)) |>
  tab_spanner("HDI    ", c(Q2.5_bis, Q97.5_bis)) |>
  tab_spanner("Response Time", ends_with("_RT")) |>
  tab_spanner("Error rate",    ends_with("_PE"))  |>
  tab_spanner("LISAS",         ends_with("LISAS")) |>
  tab_spanner("BIS",           ends_with("BIS")) |> 
  cols_label(
    starts_with("Estimate") ~ "Est.",
    starts_with("Q2.5") ~ "Low",
    starts_with("Q97.5") ~ "High",
    starts_with("pdir") ~ md("*p*~dir"),
    starts_with("erat") ~ md("ER"),
    starts_with("zz") ~ "",
    ) |> 
  cols_move(ends_with("_RT"),   Estimate_rt) |>
  cols_move(ends_with("_PE"),   Estimate_pe) |>
  cols_move(ends_with("LISAS"), Estimate_lisas) |>
  cols_move(ends_with("BIS"),   Estimate_bis) |>
  cols_move(zz, Q97.5_rt) |> 
  cols_move(zz2, Q97.5_pe) |> 
  cols_move(zz3, Q97.5_lisas) |> 
  cols_move(zz4, Q97.5_bis) |> 
  cols_align("center", 2:25)
```

```{r long-table of bayesian coefs, echo=FALSE, warning=FALSE, message=FALSE} 
coefs |> 
  list_rbind() |>
  mutate(
    names=case_when(
      names=="congruentTRUE" ~ "Congruency",
      names=="post_cueTRUE"~"Cue", 
      T ~ "Cue X Congruency"),
    group=case_when( 
      group=="rt"~"Response time", 
      group=="pe"~"Error rate", 
      group=="lisas"~"LISAS", 
      T ~ "BIS"),
    across(where(is.double), ~fmt_APA_numbers(.x, .chr=T))
  ) |>
  gt(groupname_col = "group") |>
  tab_spanner("HDI", c(Q2.5, Q97.5)) |>
  cols_label(
    Estimate = "Est.", pdir = md("*p*~dir"), erat="ER~dir",
    Q2.5 = "Low", Q97.5 = "High",
    ) |> 
  cols_align("center", 2:7)
```

##### Paragraph

```{r get coefs function, include=FALSE}
coef_hdi <- function(x){
  m <- mean(x)
  ll <- hdi(x)[2]
  ul <- hdi(x)[3]
  erat <- sum(x>=0)/sum(x<0)
  pval <- sum(x>=0)/length(x)
  dir <- "+"
  if(m < 0){
    erat=1./erat
    pval=1-pval
    dir="-"
  }
  pval=sprintf("%.2f",pval)
  if(is.infinite(erat)){
    erat=ifelse(erat<0, "-\\infty", "\\infty")
  } else {
    erat=sprintf("%.2f",erat)
  }
  sprintf("$b=%.2f, [%.2f, %.2f], p^{%s}=%s, \\text{ER}^{%s}=%s$", m, ll, ul, dir, pval, dir, erat)
}
co_bay_m <- list() 
co_bay_m$bis <- as.matrix(co_bay$bis)
co_bay_m$lisas <- as.matrix(co_bay$lisas)
co_bay_m$rt <- as.matrix(co_bay$rt)
co_bay_m$pe <- as.matrix(co_bay$pe)
```

For response time, we found very strong evidence that Congruency decreased response time (`r coef_hdi(co_bay_m$rt[,"b_congruentTRUE"])`). As for the Cue, we found extreme evidence that response time increased after the cue (`r coef_hdi(co_bay_m$rt[,"b_post_cueTRUE"])`). However, no interaction was observed `r coef_hdi(co_bay_m$rt[,"b_congruentTRUE:post_cueTRUE"])`.

As for error rate, we observed extreme evidence that a congruent trials reduced the amount of errors (`r coef_hdi(co_bay_m$pe[,"b_congruentTRUE"])`). However, we did not observe an effect of the Cue (`r coef_hdi(co_bay_m$pe[,"b_post_cueTRUE"])`) nor an interaction (`r coef_hdi(co_bay_m$pe[,"b_congruentTRUE:post_cueTRUE"])`).

In relation to the LISAS, we observed extreme evidence for both a congruent reduction in LISAS (`r coef_hdi(co_bay_m$lisas[,"b_congruentTRUE"])`) and a post-cue increase in the LISAS score (`r coef_hdi(co_bay_m$lisas[,"b_post_cueTRUE"])`). However, no interaction between congruency and cue was found (`r coef_hdi(co_bay_m$lisas[,"b_congruentTRUE:post_cueTRUE"])`)

Lastly, for the BIS, we extreme evidence for a congruent reduction in the BIS (`r coef_hdi(co_bay_m$bis[,"b_congruentTRUE"])`) and very strong evidence for a post-cue increase in the BIS (`r coef_hdi(co_bay_m$bis[,"b_post_cueTRUE"])`). However, no interaction between congruency and cue was found (`r coef_hdi(co_bay_m$bis[,"b_congruentTRUE:post_cueTRUE"])`)

##### n-1 tests

```{r multi-tests, echo=FALSE}
bay_rep_test <- function(dep){
  pblapply(1:35, \(x){
    
    b <- bayes_run_model(
      d_ex_test |> filter(!(id == id_list[x])),
      dep
    )
    
    bayes_coefs_to_table(b, dep) |>
      mutate(.after=group, id_rmd = id_list[x])
  })
}
```

```{r bayesian coefficient n-1 cross prep, include=FALSE}
n34_b_rep <- list()
```

```{r bayesian coefficient n-1 cross test, include=FALSE, warning=FALSE, message=FALSE}
if(run_bayesian_models){
  n34_b_rep$rt     <- bay_rep_test("rt") |> list_rbind()
  n34_b_rep$pe     <- bay_rep_test("pe") |> list_rbind()
  n34_b_rep$lisas  <- bay_rep_test("lisas") |> list_rbind()
  n34_b_rep$bis    <- bay_rep_test("bis") |> list_rbind()
  # save(n34_b_rep, file="../data/processed/bayesian_n34_rep_test.rdata")
} else {
  load("../data/processed/bayesian_n34_rep_test.rdata")
}
```

```{r table for n34 bayesian rep, echo=FALSE}
n34_b_rep |>
  list_rbind() |>
  reframe(
    .by = c(group, names), 
    est_i = min(Estimate),
    est_x = max(Estimate),
    pdir_i = min(as.numeric(pdir)),
    pdir_x = max(as.numeric(pdir)),
    erat_i = min(as.numeric(erat)),
    erat_x = max(as.numeric(erat)),
    q2.5_i = min(Q2.5),
    q2.5_x = max(Q2.5),
    q97.5_i = max(Q97.5),
    q97.5_x = max(Q97.5),
    erat_i = ifelse(est_i<0, -erat_i, erat_i),
    erat_x = ifelse(est_x<0, -erat_x, erat_x),
  ) |> 
  mutate(
    group = case_when( 
      group=="rt" ~ "Response time", 
      group=="pe" ~ "Error rate", 
      group=="lisas" ~ "LISAS", 
      group=="bis" ~ "BIS", 
    ), 
    names = case_when( 
      names=="congruentTRUE" ~ "Congruency", 
      names=="post_cueTRUE"  ~ "Cue",
      T ~ "Congruency X Cue",
    ), 
    across(3:12, ~fmt_APA_numbers(.x, .chr=T)),
    zz="", zz2="", zz3="",zz4=""
  ) |>
  gt(groupname_col = "group") |>
  tab_spanner("Estimate", starts_with("est")) |>
  tab_spanner(md("*p*~dir"), starts_with("pdir")) |>
  tab_spanner(md("ER"), starts_with("erat")) |>
  tab_spanner("Low", starts_with("q2.5")) |>
  tab_spanner("High", starts_with("q97.5")) |>
  cols_label(
    ends_with("_i") ~ "Low",
    ends_with("_x") ~ "High",
    starts_with("zz") ~ ""
  ) |> 
  cols_move(zz, est_x) |>
  cols_move(zz2, pdir_x) |>
  cols_move(zz3, erat_x) |>
  cols_move(zz4, q2.5_x) 
  
```


## ELSE

### Feedback

```{r  feedback, echo=FALSE}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["response"]]) |>
    as_tibble() |>
    mutate(id = x)
}) -> exp2_feedback

exp2_feedback |>
  mutate(loss = id %in% loss$exclude_par)
```

### Interactive

```{r interactive , echo=FALSE}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["interactive"]]) |> as_tibble() |>
    mutate( id = x)
}) -> exp2_interactive
exp2_interactive |> 
  arrange(trial) 
```

Interactive looks fine. 

