---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data}
#| include: FALSE
#| warning: FALSE
library(tidyverse) # 
library(broom)        # tidying
library(afex)         # ANOVA
library(lme4)         # Mixed 
library(BayesFactor)  # bayes

# ??? 
# library(bayestestR)
# library(patchwork)
# library(gt)
# library(ggpp)
# library(lsr)

source("../lib/helper_functions.R")
```

```{r load data}
#| include: false 
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames[1], \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics
```{r}
#| include: false
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(s==1),
    female = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem
dem$age
```

We recruited `r length(demo$Age)+4`, participants from the United Kingdom via Prolific. Due to a coding mistake, four participants did not generate any data. This left us with a mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$females` females) from the United Kingdom via Prolific. Note that two participants were excluded from the data analysis, but cannot be removed from the demographics due to non-connections between data points and demographics variables. 

# Analysis

```{r prep base data}
#| echo: false
d <- d_ex <- 
  exp2_d |> 
  select(id, trial_info, inducer_run, diagnostic_run, post_cue, congruent, rt, correct_response) |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  mutate(rt = as.integer(ifelse(rt=="null", NA,rt)))
```


## Exclusion
```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$raw_data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d_ex |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d_ex |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d_ex <- d_ex |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d_ex <- d_ex |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded, representing `r loss[["inducer_practice_prop"]]` percent of the data. 

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (> 30% error). 

```{r due to high SD & NA responses }
#| include: FALSE

# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d <- d |>
  left_join(
    by = c("id","inducer_run","diagnostic_run"),
    d |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id,
        rt_crit_low   = mean(rt, na.rm=T) - sd(rt, na.rm=T) * 2.5,
        rt_crit_high  = mean(rt, na.rm=T) + sd(rt, na.rm=T) * 2.5,
        rt_crit = ifelse( ( (rt >= rt_crit_high) | (rt <= rt_crit_low) ), 1, NA ),
        rt_na = ifelse(is.na(rt), 1, NA)
      ) |>
      select(id,inducer_run, diagnostic_run, rt_crit, rt_na)
  )

# IMPORTANT NOTE: 
  #' Removing null RT responses are, in all theory, not preregistered. 
  #' While there is a solution to "non-responses" for error (count them as wrong), 
  #' there is no stated solution to response time. Generally, this leads to problems 
  #' because a trial can be considered wrong under error conditions, while the accompanied 
  #' "error" for response time is not obvious. Should the RT be 2000ms (max trial length)? 
  #' Or should it be closer to infinity? 
  #' 
  #' Assuming a max trial length of 2000ms would highly likely yield exclusion based on 
  #' the max rt * 2.5 SD (but that is not a given). 
  #' 
  #' It is not obvious what to do in such a case, and the simplest solution will 
  #' be to exclude (remove) these trials). Even though this may be assumed from
  #' the preregistration, it is *not* preregistered.


# lost trials
loss$rt_sd_trials <- d |>
  filter(diagnostic_run >= 0) |>
  filter(rt_crit == 1 | rt_na==1) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100

# Exclude
d <- d |>
  filter( is.na(rt_crit) & is.na(rt_na) ) |>
  select(-rt_crit, -rt_na)
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.

```{r only correct inducers}
#| include: FALSE
d_ex <- d_ex |>
  mutate( valid_trials = case_when( 
    trial_info=="Inducer trial" & correct_response==1 ~ 1,
    trial_info=="Inducer trial" & correct_response==0 ~ 0,
    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
      # non-responses count as a wrong response
    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()

loss$inducer_fail_prop <-
  loss$inducer_fail_trials / loss$data_trials * 100


loss$total_lost_trials <- loss$inducer_practice_trials + loss$rt_sd_trials + loss$inducer_fail_trials
loss$total_lost_prop <- loss$inducer_practice_prop + loss$rt_sd_prop + loss$inducer_fail_prop

d_ex <-
  d_ex |>
  filter( valid_trials == 1 ) |>
  select(-valid_trials)
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials`
trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)`
percent of the data.

### Paragraph:

The exclusion criteria resulted in the removal of
`r fmt_APA_numbers(loss$total_lost_prop)` %
(`r loss$total_lost_trials` trials) of the data. The first
round was considered practice and resulted in the loss of
`r fmt_APA_numbers(loss$inducer_practice_prop)` %
(`r loss$inducer_practice_trials` trials), while highly
deviating response times and non-responses accounted for
`r fmt_APA_numbers(loss$rt_sd_prop)` % (`r loss$rt_sd_trials`
trials), and a wrong response on the inducer trial resulted in
a loss of `r fmt_APA_numbers(loss$inducer_fail_prop)` %
(`r loss$inducer_fail_trials` trials).


```{r calculate BIS and LISAS }
#| echo: false

# Liesefeld, H. R., & Janczyk, M. (2023). Same same but different: Subtle but consequential differences between two measures to linearly integrate speed and accuracy (LISAS vs. BIS). Behavior Research Methods, 55(3), 1175â€“1192. https://doi.org/10.3758/s13428-022-01843-2

# Grand:
grand <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    g_rt    = mean(rt),
    g_rt_sd = sd(rt),
    g_pc    = mean(correct_response),
    g_pe    = 1 - g_pc,
    g_pc_sd = sd(correct_response) 
  )
  
# LISAS: 
lisas <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    .by = id,
    l_rt_sd = sd(rt),
    l_pe_s  = sqrt( mean(correct_response) * (1 - mean(correct_response)) )
  )  

# Calculation
d_ex_test <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarise(
    .by = c(id, post_cue, congruent), 
    rt_sd   = sd(rt),
    rt      = mean(rt),
    pe_sd   = sd(correct_response),
    pe      = 1 - mean(correct_response),
    pc      = mean(correct_response),
  ) |> 
  left_join(lisas, by="id") |> 
  bind_cols(grand) |>
  mutate(
    lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe), 
    bis    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ),
    inv_bis = bis*-1,
  ) |> 
  select(id, post_cue, congruent, rt, rt_sd, pe, pe_sd, lisas, bis, inv_bis)
```

## Assumption check

```{r normality check }
#| echo: false

# Check the assumption of normality: 
d_ex_test |> 
  pivot_longer(c(rt,pe,lisas,bis)) |>
  summarise(
    .by = name, 
    residuals = resid( lmer( value ~ post_cue*congruent + (1|id) ) )
  ) |>
  ggplot(aes(sample = residuals)) +
  facet_wrap(~ name) +
  geom_qq() +
  geom_qq_line() 
```

```{r outliers}
#| echo: false
d_ex_test |> 
  mutate(Cue = fct_relevel(ifelse(post_cue==T, "Post-cue", "Pre-cue"),"Post-cue", after=1),
         Congruency = fct_relevel(ifelse(congruent==T, "Congruent", "Incongruent"), "Congruenct", after=1)) |>
  pivot_longer(c(rt,pe,lisas,inv_bis)) |>
  ggplot(aes(Cue, value, col = Congruency)) + 
  facet_wrap(~ name, scales="free")+
  geom_boxplot()
```

```{r get the extreme outliers}
d_ex_test |> 
  group_by(post_cue,congruent) |>
  rstatix::identify_outliers(rt)
```

## Statistical test

```{r statistical test and spherisity}
#| echo: false

# aov_car(rt ~ post_cue*congruent + Error(id/(post_cue*congruent)), test) -> testing
# summary(testing)

# rstatix so this should work
rstatix::anova_test(test, dv=rt, wid = id, within=c(post_cue, congruent), detailed=T) -> testing
rstatix::get_anova_table(testing) 

# ez (this as well)
# ez::ezANOVA(test,
#             rt,
#             id,
#             within=c(post_cue, congruent),
#             detailed = T) -> testing


# Bayesian rmANOAV
anovaBF(rt ~ post_cue*congruent + id, d_ex_test, whichRandom = "id")

# brms::brm(rt ~ post_cue*congruent + (1|id), data = testing2) -> brm_test

```


## Tables and figures

```{r visualize}
#| echo: false

d_ex_test |> 
  mutate(
    Cue = fct_relevel( ifelse(post_cue==F, "Pre", "Post"), "Pre"),
    Congruency = fct_relevel( ifelse(congruent==F, "Incongruent", "Congruent"), "Incongruent"),
    bis_inv = -1 * bis
  ) |>
  rename(`Response time` = rt, `Error rate` = pe, LISAS = lisas, BIS = bis_inv) |>
  pivot_longer(c(`Response time`,`Error rate`, LISAS, BIS)) |>
  ggplot(aes(Cue, value, col = Congruency)) +
  facet_wrap(~name, scale="free")+
  # background
  geom_point(alpha = .2, position = position_dodge(.1)) +
  geom_line(aes(group=interaction(id,Congruency)), alpha = .2, position = position_dodge(.1)) +
  stat_summary(fun.data = mean_se) +
  labs(y = "")

```



```{r finished table}
d |>
  filter(trial_info=="Diagnostic trial") |>
  pivot_longer(c(rt,correct_response)) |>
  summarise(
    .by = c(id, con, name),
    mean = mean(value), 
    sd   = sd(value)
  ) |> 
  mutate(mean = ifelse(name=="correct_response", 1-mean, mean)) |>
  reframe(
    .by = name, 
    diff = mean( mean[con==FALSE] - mean[con==TRUE]),
    t = t.test(mean[con==FALSE], mean[con==TRUE], paired=T, alternative="greater")$statistic,
    df = t.test(mean[con==FALSE], mean[con==TRUE], paired=T, alternative="greater")$parameter,
    p = fmt_APA_numbers( 
      t.test(mean[con==FALSE], mean[con==TRUE], paired=T, alternative="greater")$p.value,
      .p=T ),
    d = cohensD( mean[con==FALSE], mean[con==TRUE], method = "paired" ),
    bayes = ttestBF(mean[con==FALSE], mean[con==TRUE], paired=T, iterations=10000, posterior=T)[,"mu"],
    b.est = mean( bayes ),
    bf    = extractBF( ttestBF(mean[con==FALSE], mean[con==TRUE], paired=T, iterations=10000) )$bf,
    hdi   = paste0("[", fmt_APA_numbers( hdi(bayes)$CI_low ), ", ", 
                   fmt_APA_numbers( hdi(bayes)$CI_high ),"]"),
    m_incon  = mean(mean[con==FALSE]),
    m_con    = mean(mean[con==TRUE]),
    sd_incon = sd(mean[con==FALSE]),
    sd_con   = sd(mean[con==TRUE]),
  ) |>
  select(name, m_incon,sd_incon, m_con, sd_con,everything(), -bayes) |>
  unique() |> 
  mutate(
    across(where(is.double), \(x) fmt_APA_numbers(x, .chr=T))
  ) -> exp2_statistic_table
exp2_statistic_table
```

*Note.* <br/>
`r fmt_APA_p_table_fig(exp2_statistic_table$p[2])` <br/>
<!--- This function could be improved by finding the lowest value in a p vector ---> 


