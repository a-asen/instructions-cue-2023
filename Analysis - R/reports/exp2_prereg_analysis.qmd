---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data, include=FALSE, warning=FALSE}
library(tidyverse)    # Wraggling
library(broom)        # Tidying
library(afex)         # ANOVA
library(lme4)         # Regression mixed models
library(gt)           # Tables
library(BayesFactor)  # Bayesian model (bayes model selection)
library(rstatix)      # Outliers (other?)
library(brms)         # Bayes coefficients 
library(cmdstanr)       # stan
library(bayesplot)    # plots

# library(ggpp)

source("../lib/helper_functions.R")
```

```{r , include=FALSE}
bayes_plot <- function( data_list, rm_vars = NULL, par_match = TRUE){
  #' @param rm_vars   Vector string. Remove variables from coefficient plot 
  #' @param par_match Partial matching of rm_vars
  
  if(par_match){
    map(rm_vars, \(var){
       variables(data_list)[str_detect(variables(data_list), var)]
    }) |> unlist() -> remove_variables
  } else {
    remove_variables <- rm_vars
  }
  
  int <- variables(data_list)[str_detect(variables(data_list), "Intercept")]
  remove_list <- c(c("disc","lp__", "lprior"), remove_variables, int)
  gpars <- setdiff(variables(data_list), remove_list)
  brms::rhat(data_list) -> b
  
  if(max(b, na.rm=T) > 1.01){
    print(paste("max:", max(b, na.rm=T), " <- High, check model"))
  } else {
    print(paste("max:", max(b, na.rm=T)))
  }
  print(paste("mean:", mean(b, na.rm=T)))
  print(paste("median:", median(b, na.rm=T)))
  
  bayesplot::mcmc_intervals(as.matrix(data_list), pars=gpars, prob_outer = 0.95) + 
    geom_vline(xintercept = 0, linetype = "dashed", )+
    labs(title = colnames(data_list$data)[1])
}
```

```{r load data, include=FALSE, message=FALSE}
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames, \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics

```{r , include=FALSE}
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(s==1),
    female = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem

# demo |> mutate(n = 1:length(demo$Age)) -> ddemo
# 
# map(1:length(ddemo$Age), \(x){
#   l2 <- ddemo[-x,]
#   map(1:length(l2$Age), \(y){
#     l3 <- ddemo[-y,]
#     
#   }) |> list_rbind()
# }) |> list_rbind()
```

We recruited `r length(demo$Age)+4`, participants from the
United Kingdom via Prolific. Due to a coding mistake, four
participants did not generate any data. This left us with a
mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$females`
females) from the United Kingdom via Prolific. Note that two
participants were excluded from the data analysis, but cannot
be removed from the demographics due to non-connections
between data points and demographics variables.

# Data preparation

```{r prep base data, echo=FALSE}
d <- d_ex <- 
  exp2_d |> 
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, post_cue, congruent, rt, correct_response) |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  mutate(rt = as.integer(ifelse(rt=="null", NA,rt)),
         inducer_run = as.integer(inducer_run))
```

## Exclusion

```{r exclusion start - accuracy, include=FALSE}
loss <- list()
loss$raw_data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d_ex |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d_ex <- d_ex |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d_ex <- d_ex |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded,
representing `r loss[["inducer_practice_prop"]]` percent of
the data.

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (\> 30% error).

```{r due to high SD & NA responses, include=TRUE}
# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d_ex <- d_ex |>
  left_join(
    by = c("id","inducer_run","diagnostic_run"),
    d_ex |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id,
        rt_crit_low   = mean(rt, na.rm=T) - sd(rt, na.rm=T) * 2.5,
        rt_crit_high  = mean(rt, na.rm=T) + sd(rt, na.rm=T) * 2.5,
        rt_crit = ifelse( ( (rt >= rt_crit_high) | (rt <= rt_crit_low) ), 1, NA ),
        rt_na = ifelse(is.na(rt), 1, NA)
      ) |>
      dplyr::select(id,inducer_run, diagnostic_run, rt_crit, rt_na)
  )

# lost trials
loss$rt_sd_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(rt_crit == 1 | rt_na==1) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100

# Exclude
d_ex <- d_ex |>
  filter( is.na(rt_crit) & is.na(rt_na) ) |>
  dplyr::select(-rt_crit, -rt_na)
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.

```{r only correct inducers, include=TRUE}
d_ex <- d_ex |>
  mutate( valid_trials = case_when( 
    trial_info=="Inducer trial" & correct_response==1 ~ 1,
    trial_info=="Inducer trial" & correct_response==0 ~ 0,
    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
      # non-responses count as a wrong response
    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()

loss$inducer_fail_prop <-
  loss$inducer_fail_trials / loss$data_trials * 100


loss$total_lost_trials <- loss$inducer_practice_trials + loss$rt_sd_trials + loss$inducer_fail_trials
loss$total_lost_prop <- loss$inducer_practice_prop + loss$rt_sd_prop + loss$inducer_fail_prop

d_ex <-
  d_ex |>
  filter( valid_trials == 1 ) |>
  dplyr::select(-valid_trials)
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials`
trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)`
percent of the data.

### Paragraph

The exclusion criteria resulted in the removal of
`r fmt_APA_numbers(loss$total_lost_prop)` %
(`r loss$total_lost_trials` trials) of the data. The first
round was considered practice and resulted in the loss of
`r fmt_APA_numbers(loss$inducer_practice_prop)` %
(`r loss$inducer_practice_trials` trials), while highly
deviating response times and non-responses accounted for
`r fmt_APA_numbers(loss$rt_sd_prop)` % (`r loss$rt_sd_trials`
trials), and a wrong response on the inducer trial resulted in
a loss of `r fmt_APA_numbers(loss$inducer_fail_prop)` %
(`r loss$inducer_fail_trials` trials).

# Analysis

```{r calculate BIS and LISAS, echo=TRUE}
# Liesefeld, H. R., & Janczyk, M. (2023). Same same but different: Subtle but consequential differences between two measures to linearly integrate speed and accuracy (LISAS vs. BIS). Behavior Research Methods, 55(3), 1175â€“1192. https://doi.org/10.3758/s13428-022-01843-2

# Grand:
grand <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    g_rt    = mean(rt),
    g_rt_sd = sd(rt),
    g_pc    = mean(correct_response),
    g_pe    = 1 - g_pc,
    g_pc_sd = sd(correct_response) 
  )
  
# LISAS: 
lisas <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    .by = id,
    l_rt_sd = sd(rt),
    l_pe_s  = sqrt( mean(correct_response) * (1 - mean(correct_response)) )
  )  

# Calculation
d_ex_test <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarise(
    .by = c(id, post_cue, congruent), 
    rt_sd   = sd(rt),
    rt      = mean(rt),
    pe_sd   = sd(correct_response),
    pe      = 1 - mean(correct_response),
    pc      = mean(correct_response),
  ) |> 
  left_join(lisas, by="id") |> 
  bind_cols(grand) |>
  mutate(
    lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe), 
    bis    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ),
    inv_bis = bis*-1,
  ) |> 
  dplyr::select(id, post_cue, congruent, rt, rt_sd, pe, pe_sd, lisas, bis, inv_bis)
```

```{r why we have one more than expected, echo=FALSE}
# Why do we have 35? 
d_ex |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 

d |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 
  
table(d_ex$inducer_run)
d_ex |> 
  group_by(id, inducer_run) |>
  summarise(n()) 
```

## Visualize 

```{r data vis calculation, include=FALSE}
data_vis <- 
  d_ex_test |> 
  mutate(
    Cue = ifelse(post_cue==T, 1,0),
    Congruency = fct_relevel( ifelse(congruent==F, "Incongruent", "Congruent"), "Incongruent"),
    bis_inv = -1 * bis,
    con = ifelse(congruent==T, 1,0),
  ) |>
  rename(`Response time` = rt, `Error rate` = pe, LISAS = lisas, BIS = bis_inv) |>
  pivot_longer(c(`Response time`,`Error rate`, LISAS, BIS)) |>
  mutate(name = fct_relevel(name, "Response time", "Error rate", "LISAS", "BIS"))
```

```{r visualize across all, echo=TRUE}
data_vis |>
  ggplot(aes(Cue, value, col = Congruency)) +
  facet_wrap(~name, scales="free") + 
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25))+
  labs(x=NULL, y="Error rate")
```

```{r bar plot, echo=FALSE}
data_vis |>   
  filter(name == "Response time") |>
  ggplot(aes(Cue, value, fill = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="col", width=.75)+
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="errorbar", width=.5) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.4,1.40), ylim=c(550, 750))+
  labs(x = NULL, y="Response time")
```

## Statistical test

### Normality

```{r calculate residual distribution, echo=T}
residual_norm <- 
  d_ex_test |> 
  pivot_longer(c(rt,pe,lisas,bis)) |>
  reframe(
    .by = name, 
    id = id,
    residuals = resid( lmer( value ~ post_cue + congruent + post_cue:congruent + (1|id) ) )
  ) 
```

```{r residual qqplot, echo=TRUE}
residual_norm |>
  ggplot(aes(sample = residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_qq() +
  geom_qq_line()
```

```{r residual histogram, echo=TRUE}
residual_norm |>
  ggplot(aes(residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_histogram()
```

Generally, the residual errors seems to be normally distributed around 0. There are a couple of outliers, but they are also uniform (i.e., as much on both sides), albeit for the Errors with a slight skew. 

```{r raw distribution, include=FALSE}
d_ex_test |> 
  mutate(Cue = ifelse(post_cue==T, "Post", "Pre"),
         Congruency = fct_relevel(ifelse(congruent==T, "Congruent", "Incongruent"), "Congruent", after=1)) |>
  pivot_longer(c(rt,pe,lisas,inv_bis)) |>
  ggplot(aes(value, col = Congruency)) + 
  facet_wrap(name ~ Cue, scales="free", ncol=2) +
  geom_density()
```

### Outliers
```{r difference distribution, echo=TRUE}
d_ex_test |> 
  mutate(cue = ifelse(post_cue==T, "post","pre"),
         congruent = ifelse(congruent==T, "Congruent", "Incongruent")) |>
  dplyr::select(-rt_sd,-pe_sd, -inv_bis,-post_cue) |>
  pivot_longer(c(rt,pe,bis,lisas)) |> 
  pivot_wider(
    names_from=c(cue, congruent), 
    values_from=c(value) 
  ) |>
  mutate(
    pre_diff   = pre_Incongruent - pre_Congruent,
    post_diff  = post_Incongruent - post_Congruent,
  ) -> d_ex_test_diff

d_ex_test_diff |>
  pivot_longer(c(pre_diff,post_diff),names_to="name2") |>
  ggplot(aes(y=value, col=name2))+
  facet_wrap(~name, scales="free")+
  geom_boxplot()+
  labs(col="Cue")
```

```{r finding outliers and extreme outliers, echo=TRUE}
# Exclude outliers
outlier_values <-
  d_ex_test_diff |> 
  pivot_longer(c(pre_diff, post_diff), names_to="name2") |>
  group_by(name)  |>
  identify_outliers(value)

id_is_outlier <- outlier_values |> filter(is.outlier==T) |> pull(id) |> unique()
id_is_extreme <- outlier_values |> filter(is.extreme==T) |> pull(id) |> unique()
```

Some outliers, check without. 

### Frequentist rmANOVA
Statistical test of all 35 participants:

#### Table

```{r transform data object output, include=FALSE}
trns_mod <- function(data){
  d <- data$anova_table
  
  Fname <- paste0(
    "F (", unique(d$`num Df`), ",",
     unique(d$`den Df`),")" )
  
  d |> 
    mutate(names = c("Congrunecy","Cue", "Congruency_X_Cue")) |> 
    rename(!!Fname := `F`, p = `Pr(>F)`) |>
    dplyr::select(names, all_of(Fname), p, pes) |> 
    mutate(across(2, ~fmt_APA_numbers(.x, .chr=T)),
           p = fmt_APA_numbers(p, .p=T),
           pes = fmt_APA_numbers(pes, .low_val=T))
}
```

```{r frequent rmanova, echo=TRUE}
pe_aov <- aov_car(pe ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
rt_aov <- aov_car(rt ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
lisas_aov <- aov_car(lisas ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
bis_aov <- aov_car(bis ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
```

```{r table rmanovas, echo=TRUE}
trns_mod(pe_aov) |> 
  mutate(group="Error rate") |>
  bind_rows(
    trns_mod(rt_aov) |> mutate(group="Response time") ) |>
  bind_rows(
    trns_mod(lisas_aov) |> mutate(group="LISAS") ) |>
  bind_rows(
    trns_mod(bis_aov) |> mutate(group="BIS") ) |>
  pivot_wider(names_from = group, values_from = c(`F (1,34)`, p, pes)) |>
  dplyr::select(names, ends_with("Error rate"), ends_with("Response time"), ends_with("LISAS"), ends_with("BIS")) |>
  mutate(e="",e2="",e3="",e4="") |>
  gt() |>
  cols_move(c(`F (1,34)_Response time`, `p_Response time`, `pes_Response time`), names) |> 
  tab_spanner(
    "Response time", c(`F (1,34)_Response time`, `p_Response time`, `pes_Response time`)) |>
  tab_spanner(
    "Error rate", c(`F (1,34)_Error rate`, `p_Error rate`, `pes_Error rate`)) |>
  tab_spanner("LISAS", c(`F (1,34)_LISAS`, `p_LISAS`, `pes_LISAS`)) |>
  tab_spanner("BIS", c(`F (1,34)_BIS`, `p_BIS`, `pes_BIS`)) |>
  cols_move(e, `pes_Response time`) |> 
  cols_move(e2, `pes_Error rate`) |> 
  cols_move(e3, `pes_LISAS`) |> 
  cols_move(e4, `pes_BIS`) |> 
  cols_label(
    `F (1,34)_BIS` = md("*F*(1,34)"), `F (1,34)_LISAS` = md("*F*(1,34)"), 
    `F (1,34)_Response time` = md("*F*(1,34)"), `F (1,34)_Error rate` = md("*F*(1,34)"), 
    p_LISAS = md("*p*"), p_BIS = md("*p*"), `p_Error rate`= md("*p*"), 
    `p_Response time` = md("*p*"), `pes_Error rate` = "n^2", `pes_Response time` = "n^2", 
    pes_LISAS = "n^2", `pes_BIS`="n^2", names = "Variables",
    e="", e2="",e3="",e4="") |>
  cols_align("center", 2:13) |>
  tab_header("Results for the whole sample", ) |>
  tab_footnote("dawd")
```



```{r tukey test list, include=FALSE}
tuk_t <- list()
library(emmeans)
```

```{r linear mixed-effect model , include=FALSE}
tuk_t$rt <- lmer(rt ~ post_cue * congruent + (1|id), d_ex_test)
tuk_t$pe <- lmer(pe ~ post_cue * congruent + (1|id), d_ex_test)
tuk_t$lisas <- lmer(lisas ~ post_cue * congruent  + (1|id), d_ex_test)
tuk_t$bis <- lmer(bis ~ post_cue * congruent+ (1|id), d_ex_test)

par_test <- function(dep){
  emmeans(tuk_t[[dep]], pairwise ~ congruent * post_cue) -> test
  test$contrasts |>
    as_tibble() |> 
    mutate(n=1:6) |> 
    filter(n<4) |> 
    mutate(.before=1,name=c("Congruency","Cue","Congruency_X_Cue"), n=NULL, contrast=NULL,
           group=dep)
}
```

```{r linear mixed-effect model , include=FALSE}
par_test("rt") |>
  bind_rows( par_test("pe") ) |> 
  bind_rows( par_test("lisas") ) |>
  bind_rows( par_test("bis") ) |>
  pivot_wider(names_from=group, values_from=c(estimate,SE,df,t.ratio,p.value)) |>
  mutate(
    across(c(starts_with("SE"), starts_with("t.rat"), starts_with("est")) , ~fmt_APA_numbers(.x, .chr=T)),
    across(starts_with("p.value"), ~fmt_APA_numbers(.x, .p=T)),
    em="",em2="",em3="",em4="") |>
  gt() |>
  tab_spanner("Response time", c(estimate_rt, df_rt, SE_rt, t.ratio_rt, p.value_rt)) |>
  tab_spanner("Error rate", c(estimate_pe, df_pe, SE_pe, t.ratio_pe, p.value_pe)) |>
  tab_spanner("LISAS", c(estimate_lisas, df_lisas, SE_lisas, t.ratio_lisas, p.value_lisas)) |>
  tab_spanner("BIS", c(estimate_bis, df_bis, SE_bis, t.ratio_bis, p.value_bis)) |>
  cols_label(starts_with("SE") ~ ("SE"), starts_with("estimate") ~ "Est.",
             starts_with("df") ~ md("df"), starts_with("p.value") ~ md("*p*"),
             starts_with("t.ratio") ~ md("*t*" )) |>
  cols_hide(c(starts_with("SE"), starts_with("df"), starts_with("em"))) |>
  cols_move(em, p.value_rt) |> 
  cols_move(em2, p.value_pe) |>
  cols_move(em3, p.value_lisas) |>
  cols_move(em4, p.value_bis) |>
  cols_align("center", 2:25)
```


##### Paragarph

```{r use this bfr paragraph, include=FALSE}
text_report <- function(data){
  data[["anova_table"]] |> 
    as_tibble() |>
    mutate(
      `F` = fmt_APA_numbers(`F`, .chr=T),
      `pes` = fmt_APA_numbers(`F`, .low_val=T ),
      `Pr(>F)` = fmt_APA_numbers(`Pr(>F)`, .p=T ),
    ) 
}

aov_report <- list()
aov_report$rt <- text_report(rt_aov) 
aov_report$pe <- text_report(pe_aov) 
aov_report$lisas <- text_report(lisas_aov) 
aov_report$bis <- text_report(bis_aov) 
```

---

The rmANOVA for error revealed a significant effect of
Congruency (*F*\~`r aov_report$rt[["num Df"]][1]`, `r aov_report$rt[["den Df"]][1]`\~ =
`r aov_report$rt$F[1])`, *p* `r aov_report$rt[["Pr(>F)"]][1]`, $\eta_p^2$ = `r aov_report$rt[["pes"]][1]`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r aov_report$rt[["num Df"]][2]`, `r aov_report$rt[["den Df"]][2]`\~ =
`r aov_report$rt$F[2])`, *p* `r aov_report$rt[["Pr(>F)"]][2]`, $\eta_p^2$ =
`r aov_report$rt[["pes"]][2]`), nor an interaction effect
(*F*\~`r aov_report$rt[["num Df"]][3]`, `r aov_report$rt[["den Df"]][3]`\~ =
`r aov_report$rt$F[3]`, *p* `r aov_report$rt[["Pr(>F)"]][3]`, $\eta_p^2$ =`r aov_report$rt[["pes"]][3]`).

---

The rmANOVA for error revealed a significant effect of
Congruency (*F*\~`r pe_aov$anova_table[["num Df"]][1]`,
`r pe_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(pe_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r pe_aov$anova_table[["num Df"]][2]`,
`r pe_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(pe_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r pe_aov$anova_table[["num Df"]][3]`,
`r pe_aov$anova_table[["den Df"]][3]`\~ =
`r pe_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][3], .low_val=T)`).

The rmANOVA for the LISAS revealed a significant effect of
Congruency (*F*\~`r lisas_aov$anova_table[["num Df"]][1]`,
`r lisas_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(lisas_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r lisas_aov$anova_table[["num Df"]][2]`,
`r lisas_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(lisas_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r lisas_aov$anova_table[["num Df"]][3]`,
`r lisas_aov$anova_table[["den Df"]][3]`\~ =
`r lisas_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][3], .low_val=T)`).

The rmANOVA for the LISAS revealed a significant effect of
Congruency (*F*\~`r bis_aov$anova_table[["num Df"]][1]`,
`r bis_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(bis_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r bis_aov$anova_table[["num Df"]][2]`,
`r bis_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(bis_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r bis_aov$anova_table[["num Df"]][3]`,
`r bis_aov$anova_table[["den Df"]][3]`\~ =
`r bis_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][3], .low_val=T)`).

#### Sample n=34 tests

Since we preregistered a sample of 34, but do not know which
participant to remove, we include tests of all data with n-1.
We then report the minimum and maximum F and p value for the
conditions and interaction.

```{r id list, include=FALSE }
d_ex_test |> 
  pull(id) |> unique() -> id_list
```


```{r anova with one participant removed, echo=FALSE, warning=FALSE}
map_df(1:35, \(x){
  ez::ezANOVA(
    d_ex_test |> filter(!(id == id_list[x])), pe, id,
    within = c(post_cue, congruent), detailed = T)[["ANOVA"]] |>
    mutate(
      .before=1,
      rm_id = id_list[x]
    )
}) -> test_one_less
test_one_less |> 
  filter(Effect != "(Intercept)") |>
  summarise(
    .by = Effect,
    minF = min(`F`),
    maxF = max(`F`),
    maxP = max(p),
    minP = min(p),
  ) |> 
  rename(Variable = Effect) |> 
  mutate(
    Variable = case_when(Variable=="post_cue"~"Cue", 
                         Variable=="congruent"~"Congruency", 
                         Variable=="post_cue:congruent"~"Cue.X.Congruency"),
    across(2:3, ~fmt_APA_numbers(.x, .chr=T)),
    across(4:5, ~fmt_APA_numbers(.x, .p=T)),
    e="") |>
  gt() |>
  tab_spanner("F test", c(minF, maxF)) |>
  tab_spanner(md("*p*-value"), c(maxP, minP)) |>
  cols_move(e, maxF) |>
  cols_label(minF = "Min", maxF = "Max", maxP = "Max", minP = "Min", e="") |>
  cols_align("center", 2:5) |> 
  tab_header("Summary of the F and p value for all 34 combinations of the rmANOVA") |>
  tab_footnote("Resulting F and p value for all combinations of a 34 participant sample size")
```

#### Robustness check

```{r remove outliers and test, echo=FALSE}
# is_extreme # there is no extreme outliers! 
is_outlier

# rt_aov <- aov_car(rt ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
#                      anova_table = list(es="pes"))

o_pe_aov <- aov_car(pe ~ Error(id/(congruent*post_cue)), 
                  d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                  anova_table = list(es="pes"))

o_lisas_aov <- aov_car(lisas ~ Error(id/(congruent*post_cue)), 
                     d_ex_test |> 
                       filter(!(id %in% id_is_outlier)), detailed=T, 
                     anova_table = list(es="pes"))

o_bis_aov <- aov_car(bis ~ Error(id/(congruent*post_cue)), 
                   d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                   anova_table = list(es="pes"))

trns_mod(o_pe_aov) |> 
  mutate(group = "Error") |> 
  bind_rows(
    trns_mod(o_lisas_aov) |>
      mutate(group="LISAS")
  ) |>
  bind_rows(
    trns_mod(o_bis_aov) |>
      mutate(group="BIS")
  ) |> 
  pivot_wider(names_from=group, values_from = c(`F (1,25)`, p, pes)  )

trns_mod(o_pe_aov) |> 
  mutate(group="Error rate") |>
  bind_rows(
    trns_mod(o_lisas_aov) |>
      mutate(group="LISAS") ) |>
  bind_rows(
    trns_mod(o_bis_aov) |> 
      mutate(group="BIS") ) |>
  pivot_wider(names_from = group, values_from=c(`F (1,25)`, p, pes)) |>
  gt() |>
  tab_spanner("Error rate", c("F (1,25)_Error rate", "p_Error rate", "pes_Error rate")) |>
  tab_spanner("LISAS", c("F (1,25)_LISAS", "p_LISAS", "pes_LISAS")) |>
  tab_spanner("BIS", c("F (1,25)_BIS", "p_BIS", "pes_BIS")) |>
  cols_label(
    "F (1,25)_Error rate" = "F (1,25)", "F (1,25)_LISAS" = "F (1,25)", "F (1,25)_BIS" = "F (1,25)",
    "p_Error rate" = md("*p*"), p_LISAS = md("*p*"), p_BIS = md("*p*"), "pes_Error rate"="n^2",
    pes_LISAS="n^2", pes_BIS = "n^2", names = "Variables"
  ) |>
  cols_align("center", 2:10) |>
  tab_header("Outliers removed from the rmANOVA") |>
  tab_footnote("Outliers removed")
```



### Bayesian Analyses 

#### Coefficients
```{r bayesian list vars , include=FALSE}
vars <- list()
coefs <- list()
co_bay <- list()

bay_eff_prob <- function(data, var){
  da <- as.matrix(data) 
  m <- mean(da[, var])
  
  if(m >= 0){
    fmt_APA_numbers( (sum( da[, var]>=0 ) / length( da[, var])), .p=T )
  } else if(m<0){
    paste0("-", 
      fmt_APA_numbers( 1 - sum(da[, var]>=0) / length(da[, var]), .p=T ) 
    )
  }
}
bay_erate <- function(data, var){
  da <- as.matrix(data) 
  m <- mean(da[, var])
  
  if(m>=0){
    fmt_APA_numbers( 
      sum(da[, var]>=0) / sum(da[, var]<0), 
      .chr=T
    )
  } else if(m<0){
    fmt_APA_numbers( 
      sum(da[, var]<=0) / sum(da[, var]>0),
      .chr=T
    )
  }
}
```

```{r rt bay coefs, echo=FALSE, warning=FALSE, message=FALSE}
co_bay$rt <- brm(
  rt ~ congruent + post_cue + congruent:post_cue + (1|id), 
  d_ex_test, 
  save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6,
  iter = 6000, chains = 6, init=0)

variables(co_bay$rt) -> vars$rt
vars$rt[str_detect(vars$rt, "b_")] -> vars$rt
mcmc_acf(as.array(co_bay$rt), pars=vars$rt)   # autocorrelation
mcmc_trace(as.array(co_bay$rt), pars=vars$rt) # mcmc draws
bayes_plot(co_bay$rt, c("z_", "sigma"))    # coefficient plot

coefs$rt <- 
  fixef(co_bay$rt) |> 
  as_tibble() |> 
  mutate(
    .before=1, 
    names = rownames(fixef(co_bay$rt)), 
    across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
    Est.Error=NULL,
    group="RT") |>
  mutate(
    .after="Estimate", 
    pdir = map_vec(colnames(as.matrix(co_bay$rt))[1:4], 
                    \(x){ bay_eff_prob(co_bay$rt, x) }),
    erat = map_vec(colnames(as.matrix(co_bay$rt))[1:4], 
                    \(x){ bay_erate(co_bay$rt, x) }) ) |>
  filter(!(names=="Intercept"))
```

```{r pe bay coefs , echo=FALSE}
co_bay$pe <- brm(
  pe ~ congruent + post_cue + congruent:post_cue + (1|id), 
  d_ex_test, 
  save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6, 
  iter = 6000, chains = 6, init=0)

variables(co_bay$pe) -> vars$pe
vars$pe[str_detect(vars$pe, "b_")] -> vars$pe
mcmc_acf(as.array(co_bay$pe), pars=vars$pe)   # autocorrelation
mcmc_trace(as.array(co_bay$pe), pars=vars$pe) # mcmc draws
bayes_plot(co_bay$pe, c("z_", "sigma"))    # coefficient plot

coefs$pe <-
  fixef(co_bay$pe) |> 
  as_tibble() |> 
  mutate(
    .before=1, 
    names = rownames(fixef(co_bay$pe)), 
    across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
    Est.Error=NULL,
    group="PE") |>
  mutate(
    .after="Estimate", 
    pdir = map_vec(colnames(as.matrix(co_bay$pe))[1:4], 
                    \(x){ bay_eff_prob(co_bay$pe, x) }),
    erat = map_vec(colnames(as.matrix(co_bay$pe))[1:4], 
                    \(x){ bay_erate(co_bay$pe, x) })  ) |>
  filter(!(names=="Intercept"))
```

```{r lisas bay coefs, echo=FALSE}
co_bay$lisas <- brm(
  lisas ~ congruent + post_cue + congruent:post_cue + (1|id), 
  d_ex_test, 
  save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6,
  iter = 6000, chains = 6, init=0)

variables(co_bay$lisas) -> vars$lisas
vars$lisas[str_detect(vars$lisas, "b_")] -> vars$lisas
mcmc_acf(as.array(co_bay$lisas), pars=vars$lisas)   # autocorrelation
mcmc_trace(as.array(co_bay$lisas), pars=vars$lisas) # mcmc draws
bayes_plot(co_bay$lisas, c("z_", "sigma"))    # rhat & coefficient plot

coefs$lisas <- 
  fixef(co_bay$lisas) |> 
  as_tibble() |> 
  mutate(
    .before=1, 
    names = rownames(fixef(co_bay$lisas)), 
    across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
    Est.Error=NULL,
    group = "LISAS") |>
  mutate(
    .after="Estimate", 
    pdir = map_vec(colnames(as.matrix(co_bay$lisas))[1:4], 
                    \(x){ bay_eff_prob(co_bay$lisas, x) }),
    erat = map_vec(colnames(as.matrix(co_bay$lisas))[1:4], 
                    \(x){ bay_erate(co_bay$lisas, x) }) ) |>
  filter(!(names=="Intercept"))
```

```{r bis bay coefs, echo=FALSE}
co_bay$bis <- brm(
  bis ~ congruent + post_cue + congruent:post_cue + (1|id), 
  d_ex_test, 
  save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6, 
  iter = 6000, chains = 6, init=0)

variables(co_bay$bis) -> vars$bis
vars$bis[str_detect(vars$bis, "b_")] -> vars$bis
mcmc_acf(as.array(co_bay$bis), pars=vars$bis)   # autocorrelation
mcmc_trace(as.array(co_bay$bis), pars=vars$bis) # mcmc draws
bayes_plot(co_bay$bis, c("z_", "sigma"))    # coefficient plot

coefs$bis <- 
  fixef(co_bay$bis) |> 
  as_tibble() |> 
  mutate(
    .before=1, 
    names = rownames(fixef(co_bay$bis)), 
    across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
    Est.Error=NULL,
    group = "BIS") |>
  mutate(
    .after="Estimate", 
    pdir = map_vec(colnames(as.matrix(co_bay$bis))[1:4], 
                    \(x){ bay_eff_prob(co_bay$bis, x) }),
    erat = map_vec(colnames(as.matrix(co_bay$bis))[1:4], 
                    \(x){ bay_erate(co_bay$bis, x) }) ) |>
  filter(!(names=="Intercept"))
```

```{r table of bayesian coefs, echo=FALSE}
coefs |> 
  list_rbind() |>
  pivot_wider(names_from=group, values_from=c(Estimate, Q2.5,Q97.5, erat, pdir)) |>
  mutate(
    names=case_when(
      names=="congruentTRUE" ~ "Congruency",
      names=="post_cueTRUE"~"Cue", 
      T ~ "Cue_X_Congruency"),
    e="",e2="",e3="",e4="",
  ) |>
  gt() |>
  tab_spanner("HDI", c(Q2.5_RT, Q97.5_RT)) |>
  tab_spanner("HDI ", c(Q2.5_PE, Q97.5_PE)) |>
  tab_spanner("HDI  ", c(Q2.5_LISAS, Q97.5_LISAS)) |>
  tab_spanner("HDI    ", c(Q2.5_BIS, Q97.5_BIS)) |>
  tab_spanner("Response Time", c(Estimate_RT, pdir_RT, erat_RT, Q2.5_RT, Q97.5_RT)) |>
  tab_spanner("Error rate", c(Estimate_PE, pdir_PE, erat_PE, Q2.5_PE, Q97.5_PE))  |>
  tab_spanner("LISAS", c(Estimate_LISAS, pdir_LISAS, erat_LISAS, Q2.5_LISAS, Q97.5_LISAS)) |>
  tab_spanner("BIS", c(Estimate_BIS, pdir_BIS, erat_BIS, Q2.5_BIS, Q97.5_BIS)) |> 
  cols_label(
    Estimate_PE = "Estimate", Estimate_LISAS="Estimate", Estimate_RT ="Estimate", Estimate_BIS="Estimate", 
    Q2.5_PE = "Lower", Q2.5_RT="Lower",Q2.5_LISAS="Lower", Q2.5_BIS="Lower",
    Q97.5_PE = "Upper",Q97.5_RT = "Upper", Q97.5_LISAS = "Upper", Q97.5_BIS ="Upper",
    e="",e2="",e3="",e4="", pdir_RT = md("*p*~dir~"), pdir_PE = md("*p*~dir~"), pdir_LISAS = md("*p*~dir~"),
    pdir_BIS = md("*p*~dir~"), erat_RT = md("ER+^"), erat_PE = md("ER+^"), erat_LISAS = md("ER+^"), 
    erat_BIS = md("ER+^")) |> 
  cols_move(c(pdir_RT, erat_RT, Q2.5_RT, Q97.5_RT), Estimate_RT) |>
  cols_move(c(pdir_PE, erat_PE, Q2.5_PE, Q97.5_PE), Estimate_PE) |>
  cols_move(c(pdir_LISAS, erat_LISAS, Q2.5_LISAS, Q97.5_LISAS), Estimate_LISAS) |>
  cols_move(c(pdir_BIS, erat_BIS, Q2.5_BIS, Q97.5_BIS), Estimate_BIS) |>
  cols_move(e, Q97.5_RT) |> 
  cols_move(e2, Q97.5_PE) |> 
  cols_move(e3, Q97.5_LISAS) |> 
  cols_move(e4, Q97.5_BIS) |> 
  cols_align("center", 2:25)
```

##### Paragraph


##### n-1 tests

```{r multi-tests, echo=FALSE}
bay_rep_test <- function(dep){
  pblapply(1:35, \(x){
    b <- brm(
      as.formula(glue::glue("{dep} ~ congruent + post_cue + congruent:post_cue + (1|id)")), 
      d_ex_test |> filter(!(id == id_list[x])), 
      save_pars = save_pars(all=T), backend = "cmdstanr", cores = 6,
      iter = 6000, chains = 6,  init=0)
  
    fixef(b) |> 
    as_tibble() |> 
    mutate(
      .before=1, 
      names = rownames(fixef(b)), 
      across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
      Est.Error = NULL,
      group = dep,
      l_out = id_list[x]) |>
    mutate(
      .after="Estimate", 
      pdir = map_vec(colnames(as.matrix(b))[1:4], 
                  \(x){ bay_eff_prob(b, x) }),
      erat = map_vec(colnames(as.matrix(b))[1:4], 
                  \(x){ bay_erate(b, x) })
    ) |>
    filter(!(names=="Intercept"))
  })
}
```

```{r bayesian coefficient n-1 cross prep, include=FALSE}
n34_b_rep <- list()
```


```{r bayesian coefficient n-1 cross test, include=FALSE, warning=FALSE, message=FALSE}
n34_b_rep$rt     <- bay_rep_test("rt")
n34_b_rep$pe     <- bay_rep_test("pe")
n34_b_rep$lisas  <- bay_rep_test("lisas")
n34_b_rep$bis    <- bay_rep_test("bis")

n34_b_rep$rt |> list_rbind()
n34_b_rep$rt  

```


### Model selection

#### Freq 


#### Bayesian

```{r , include=FALSE}
bay_ms <- list()
```

```{r model selection rt, echo=FALSE}
bay_ms$rt <- anovaBF(
  rt ~ post_cue * congruent + id, whichRandom = "id", 
  d_ex_test |> mutate(
    id=factor(id), post_cue=factor(post_cue), congruent=factor(congruent))
  ) 
bay_ms$rt
```

```{r bmodel selection pe, echo=FALSE}
bay_ms$pe <- anovaBF(
  pe ~ post_cue * congruent + id, whichRandom = "id", 
  d_ex_test |> mutate(
    id=factor(id), post_cue=factor(post_cue), congruent=factor(congruent))
  ) 
bay_ms$pe # only model with congruency
```

```{r model selection lisas, echo=FALSE}
bay_ms$lisas <- anovaBF(
  lisas ~ post_cue * congruent + id, whichRandom = "id", 
  d_ex_test |> mutate(
    id=factor(id),
    post_cue=factor(post_cue),
    congruent=factor(congruent))
  ) 
bay_ms$lisas # Congruency + Cue  ---  secondary congruency+cue+interaction
```

```{r model selection bis, echo=FALSE}
bay_ms$bis <- anovaBF(
  bis ~ post_cue * congruent + id, whichRandom = "id", 
  d_ex_test |> mutate(
    id=factor(id),
    post_cue=factor(post_cue),
    congruent=factor(congruent))
  ) 
bay_ms$bis # Congruency + Cue  ---  secondary  congruency+cue+interaction
```

##### Paragraph

For errors, the model containing only congruency is favoured (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[2])`) compared to a model with only the Cue (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[1])`), Congruency and Cue (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[3])`), and Congruency, Cue and their interaction (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[4])`). 

For the LISAS, the model containing both the Congruency and Cue is favoured (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[2])`), but in close succession of the model with the Congruency, Cue and their interaction (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[4])`), followed by the model with only Congruency (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[2])`), and only the Cue (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[1])`). 

A similar picture is found for the BIS model comparison: The model containing both Congruency and Cue is more favoured (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[3])`), but followed by the model including the interaction term (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[4])`), only Congruency (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[2])`), and lastly, only the Cue (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[1])`). 

##### 34 repeated test 

```{r function n-1 repeated bayesian tests, echo=FALSE}
rep_test <- function(dep){
  map(1:35, \(x){
    anovaBF(as.formula(glue::glue("{dep} ~ post_cue * congruent + id")), 
            whichRandom = "id", 
            d_ex_test |>
              mutate(id=factor(id),
                    post_cue=factor(post_cue),
                    congruent=factor(congruent)) |>
              filter(!(id == id_list[x])) ) -> bres
    
    tibble(
      names = rownames(extractBF(bres)),
      bf = extractBF(bres)$bf,
      rm_id = id_list[x]
    )
  }) |> list_rbind() -> test_one_less
  
  test_one_less |> 
    summarise(
      .by = names,
      minBF = min(bf),
      maxBF = max(bf),
    )
}
```

```{r baysian repeat ms start, include=FALSE}
bay_ms_rep <- list()
```

```{r n-1 repeated bayesian tests, echo=FALSE}
bay_ms_rep$rt_34 <- rep_test("rt")
bay_ms_rep$pe_34 <- rep_test("pe")
bay_ms_rep$lisas_34 <- rep_test("lisas")
bay_ms_rep$bis_34 <- rep_test("bis")

bay_ms_rep$rt_34 |>
  mutate(group="ResponseTime") |> 
  bind_rows(
    bay_ms_rep$pe_34 |> 
      mutate(group = "Error") ) |> 
  bind_rows(
    bay_ms_rep$lisas_34 |> 
      mutate(group="LISAS") ) |> 
  bind_rows(
    bay_ms_rep$bis_34 |>
      mutate(group="BIS") ) |>
  mutate(across(where(is.double), ~fmt_APA_numbers(.x, .chr=T)),
         names = str_remove(names,"\\+ id$")) |>
  pivot_wider(names_from=group, values_from=c(minBF, maxBF)) |>
  gt() |>
  tab_spanner("Response time", c(minBF_ResponseTime, maxBF_ResponseTime)) |>
  tab_spanner("Error rate", c(minBF_Error, maxBF_Error)) |>
  tab_spanner("LISAS", c(minBF_LISAS, maxBF_LISAS)) |>
  tab_spanner("BIS", c(minBF_BIS, maxBF_BIS)) |>
  cols_label(
    minBF_ResponseTime="Min", maxBF_ResponseTime="Max", 
    minBF_Error = md("Min"), maxBF_Error = md("Max"), minBF_LISAS = md("Min"), 
    maxBF_LISAS = md("Max"), minBF_BIS = md("Min"), maxBF_BIS = md("Max"), 
    names = "Model selection") |>
  cols_align("center", 2:7) |>
  tab_header("Minimum and maximum Bayesian factor for the error rate, LISAS and BIS")
```

The pattern of results found for the 35 participants is reflected in all 34 sampled tests (n-1), per the preregistered sample size. 


## Figures



```{r indiv vis, echo=TRUE}
data_vis |>
  filter(name =="Error rate") |>
  ggplot(aes(Cue, value, col = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25), ylim=c(0,.1))+
  labs(x=NULL, y="Error rate")

data_vis |>
  filter(name =="BIS") |>
  ggplot(aes(Cue, value, col = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  # coord_cartesian(xlim=c(-.25,1.25), ylim=c(0,.1))+
  labs(x=NULL, y="BIS")



```


## ELSE

### Feedback

```{r}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["response"]]) |>
    as_tibble() |>
    mutate(id = x)
}) -> exp2_feedback

exp2_feedback |>
  mutate(loss = id %in% loss$exclude_par) |> 
  view()
```


### Interactive

```{r}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["interactive"]]) |> as_tibble() |>
    mutate( id = x)
}) -> exp2_interactive
exp2_interactive |> 
  arrange(trial) 
```

