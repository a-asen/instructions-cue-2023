---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data}
#| include: FALSE
#| warning: FALSE
library(tidyverse) # 
library(broom)        # tidying
library(afex)         # ANOVA
library(BayesFactor)  # bayes

# ??? 
library(bayestestR)
library(patchwork)
library(gt)
library(ggpp)
library(lsr)

source("../lib/helper_functions.R")
```

```{r load data}
#| include: false 
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames[1:4], \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics
```{r}
#| include: false
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(s==1),
    female = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem
dem$age
```

We recruited `r length(demo$Age)+4`, participants from the United Kingdom via Prolific. Due to a coding mistake, four participants did not generate any data. This left us with a mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$females` females) from the United Kingdom via Prolific. Note that two participants were excluded from the data analysis, but cannot be removed from the demographics due to non-connections between data points and demographics variables. 

## Exclusion
```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$raw_data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d <- d |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d <- d |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded, representing `r loss[["inducer_practice_prop"]]` percent of the data. 

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (> 30% error). 

<!-- Does not result in any loss of data, since they are replaced --> 

```{r due to high SD & NA responses }
#| include: FALSE

# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d <- d |>
  group_by(id) |>
  mutate(
    # Calculate: rt + SD * 2.5
    rt_crit = ifelse(
      trial_info == "Diagnostic trial",
      mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5, NA ),
      # Trials to retain/remove: 
      retain_trials = ifelse(
        # Diag trial *AND* RT above critical (rt * 2.5SD) OR is missing 
        str_equal(trial_info, "Diagnostic trial") & 
        ( (rt >= rt_crit) | (is.na(rt)) ),
        0, 1 ) 
    )

# IMPORTANT NOTE: 
  #' Removing null RT responses are, in all theory, not preregistered. 
  #' While there is a solution to "non-responses" for error (count them as wrong), 
  #' there is no stated solution to response time. Generally, this leads to problems 
  #' because a trial can be considered wrong under error conditions, while the accompanied 
  #' "error" for response time is not obvious. Should the RT be 2000ms (max trial length)? 
  #' Or should it be closer to infinity? 
  #' 
  #' Assuming a max trial length of 2000ms would highly likely yield exclusion based on 
  #' the max rt * 2.5 SD (but that is not a given). 
  #' 
  #' It is not obvious what to do in such a case, and the simplest solution will 
  #' be to exclude (remove) these trials). Even though this may be assumed from
  #' the preregistration, it is *not* preregistered.


# lost trials
loss$rt_sd_trials <- d |> 
  filter(diagnostic_run >= 0) |> 
  filter(retain_trials == 0) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100


# Exclude
d <- d |>
  filter(retain_trials == 1) 
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.


```{r only correct inducers}
#| include: FALSE
d <- d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()
  
loss$inducer_fail_prop <- 
  loss$inducer_fail_trials / loss$data_trials * 100

d <- d |> filter( valid_trials == 1 )
```
# Summary

```{r }
#| include: FALSE
# data summary
d_ex |> 
  filter(trial_info=="diagnostic trial") |>
  summarize(
    .by = c(id, post_cue, congruent), 
    rt = mean(rt),
    pe = 1 - mean(correct_response)
  ) -> d_ex_test
```

## Table
```{r RT tables}
#| echo: false

# Freq:
## response times
d_ex_test |>
  aov_car(rt ~ post_cue*congruent + Error(id/(post_cue*congruent)), data=_) -> test

d_ex_test |> 
  mutate(post_cue = factor( ifelse(post_cue==F, 0, 1)) ) |>
  ggplot(aes(congruent, rt, col = post_cue)) +
  geom_point(alpha = .3)+
  geom_line(aes(group=interaction(id,post_cue)), alpha = .3)+
  stat_summary(position=position_dodge2nudge(.1, x=.1))
  geom_line(position = position_jitterdodge(.1, dodge.width = ,2)) +
  geom_point(position = position_jitterdodge(.1, dodge.width = ,2)) +

anovaBF(rt ~post_cue*congruent, data= testing2, whichRandom = "id")
brms::brm(rt ~ post_cue*congruent + (1|id), data = testing2) -> brm_test

d2 |>
  summarise(
    name             = "PE",
    m_incongruent    = fmt_APA_numbers( mean(pe_FALSE) ),
    sd_incongruent   = fmt_APA_numbers( sd(pe_FALSE) ),
    m_congruent      = fmt_APA_numbers( mean(pe_TRUE) ),
    sd_congruent     = fmt_APA_numbers( sd(pe_TRUE) ),
    Mdiff            = fmt_APA_numbers( mean(pe_FALSE - pe_TRUE) ),
    t                = fmt_APA_numbers( pe_test$statistic ),
    df               = pe_test$parameter,
    p                = pe_test$p.value,
    ps               = set_p_star(p),
    Mdiff            = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est            = fmt_APA_numbers( mean(pe_test_b2[,"mu"]) ),
    hdi              = paste0("[",fmt_APA_numbers(pe_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(pe_test_hdi$CI_high[1]),"]"),
    bf               = fmt_APA_numbers( extractBF(pe_test_b)$bf ),
    d                = fmt_APA_numbers( cohensD(pe_FALSE, pe_TRUE, method = "paired") ),
  ) -> d_pe

```

Table XX \n
*Test statistics for the experimental conditions*
```{r stat table}
#| echo: false
rbind(d_rt, d_pe) -> b
b |> summarize( m = mean(df) ) |> pull() -> d2_df
b |> pull(p) |> min() -> p_min

if(d2_df != floor(d2_df)){ warning("NOT SIMILAR, CHECK DF") }
  # degrees of freedom

mean(b$df) -> b_df_m
exp1_table_simple <- 
  b |>
  # add bayes row? 
  mutate(em1 = "", em2="", em3="",
         p = fmt_APA_numbers(p, .p=T),
         across(contains(c("con","b")), ~ fmt_APA_numbers(.x, .chr=T) ) ) |>
  gt() |>
  cols_hide(    c(df, ps, Mdiff) ) |>
  tab_spanner(  "Incongruent", c(m_incongruent, sd_incongruent) ) |>
  cols_label(   m_incongruent = md("*M*"), sd_incongruent = md("*SD*" ) ) |>
  tab_spanner(  "Congruent", c(m_congruent, sd_congruent) ) |>
  cols_label(   m_congruent = md("*M*"),  sd_congruent = md("*SD*") ) |>
  tab_spanner(  "Bayes", c(b.est, bf, hdi)) |>
  cols_label(   b.est = md("*M*~est~"), bf = md("BF~10~"), hdi = "HDI", ) |> 
  #fmt_markdown() |>
  #cols_move(    "ps", Mdiff ) |> 
  cols_move(    "em1", sd_incongruent ) |>
  cols_move(    "em2", ps ) |>
  cols_label(   em1 = "", em2 = "", name = "", d = md("Cohen's *d*"), em3 = "", 
                t = md( paste0("*t*(",b_df_m,")")), p = md("*p*") ) |>
  cols_align(   "center", c(2:15)) |> 
  cols_move(    "em3", hdi) 
exp1_table_simple

if(save_outputs){ gtsave(exp1_table_simple, filename = "../outputs/tables/exp2_table_simple.docx") }
```
*Note.* <br/>
`r fmt_APA_p_table_fig(p_min)` <br/>


## Figures
### Linerange
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

p1 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con2, y = rt, group=id, col = factor(con2)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(450, 960))+
                        # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Response time", x = "", y = "Response time (ms)")

p2 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(pct = mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pct, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(.65, 1.01))+
                      # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Proportion of correct trials", x = "", y = "Proportion")

p1+p2
if(save_outputs){ ggsave("../outputs/figs/exp2_rt-pe_line.jpeg", p1+p2, width=8, height=5) }
```

### Bar plot
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

p1 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = rt,fill = factor(con)))+
  stat_summary(fun = mean, geom = "col")+
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .4, size = 1, alpha = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,25), minor_breaks = NULL)+
  coord_cartesian(ylim = c(600, 750))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")+
  annotate("segment", x=-0.1, xend=1.1, y=696, yend=696, size=1)+
  annotate(geom = "text", x = .5, y=700, label="**", size=5)

p2 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(pe = 1 - mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, fill = factor(con2)))+
  stat_summary(fun=mean, geom="col")+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.4, size = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error")+
  annotate("segment", x=-0.1, xend=1.1, y=.13, yend=.13, size=1)+
  annotate(geom = "text", x = .5, y=.137, label="**", size=5)
    
p1 + p2

if(save_outputs){ ggsave("../outputs/figs/exp2_rt-pe_bar.jpeg", p1+p2, width=8, height=5) }
```



