---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data}
#| include: FALSE
#| warning: FALSE
library(tidyverse) # 
library(broom)        # tidying
library(afex)         # ANOVA
library(BayesFactor)  # bayes

# ??? 
library(bayestestR)
library(patchwork)
library(gt)
library(ggpp)
library(lsr)

source("../lib/helper_functions.R")
```

```{r load data}
#| include: false 
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames, \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics
```{r}
#| include: false
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(s==1),
    female = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem
dem$age
```

We recruited `r length(demo$Age)+4`, participants from the United Kingdom via Prolific. Due to a coding mistake, four participants did not generate any data. This left us with a mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$females` females) from the United Kingdom via Prolific. Note that two participants were excluded from the data analysis, but cannot be removed from the demographics due to non-connections between data points and demographics variables. 

# Exclusion
```{r transformation}
#| include: FALSE
# Pre-transformation
data <- 
  exp2_d |>
  filter(trial_info == "diagnostic trial" | trial_info == "inducer trial") |>
  select(id, trial_info, inducer_run, diagnostic_run, stimulus, congruent, post_cue, rt, correct_response) |>
  mutate(inducer_run = as.integer(inducer_run),
         rt = as.integer( ifelse(str_equal(rt, "null"), NA, rt) ) )
```

```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$data_trials <- nrow(data)

### Overall accuracy      ====
data |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = sum(correct_response, na.rm = TRUE) / length( !is.na(correct_response) ) ) |>
  mutate(qua = quantile(acc)[2]) |>
    # If we use boxplot exclusion
  filter( acc < .7 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( data$rt[data$id == loss$exclude_par] )
loss[["exclude_par_pct"]]    <- length( data$rt[data$id == loss$exclude_par] ) / loss$data_trials * 100

d_ex <- 
  data |>
  filter( !(id %in% loss$exclude_par) )
```

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (> 70%). 
<!-- Does not result in any loss of data, since they are replaced --> 

```{r due to high SD & NA responses }
#| include: FALSE
# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d_ex |>
  group_by(id) |>
  mutate(
    # Calculate: rt + SD * 2.5
    rt_crit = ifelse( trial_info == "diagnostic trial",
      mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5, NA 
    ),
    # Trials to retain/remove: 
    retain_trials = ifelse(
      (rt > rt_crit & trial_info == "Diagnostic trial") | (is.na(rt) & trial_info == "Diagnostic trial"), 
        # Remove trials deviating **more** than 2.5 SD | OR | Remove slow (i.e., NA) responses
        0, 1 ) 
    ) -> d_ex

sum(d_ex$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d_ex$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_pct"]]

d_ex |> 
  filter(retain_trials == 1 ) -> d_ex
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_pct"]], 2)`
percent of the data.

```{r only correct inducers}
#| include: FALSE
d_ex |>
  mutate( 
    valid_trials = case_when( 
      trial_info=="inducer trial" & correct_response==1 ~ 1,
      trial_info=="inducer trial" & correct_response==0 ~ 0,
      trial_info=="inducer trial" & is.na(correct_response) ~ 0,
      # non-responses count as a wrong response
      T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d_ex

sum(d_ex$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d_ex$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_pct"]]

d_ex |> 
  filter( valid_trials == 1 ) -> d_ex
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_pct"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials` trials were lost. Representing a loss of
`r round(loss$rt_sd_pct + loss$inducer_fail_pct, 2)`percent of the data.

# Summary

```{r }
#| include: FALSE
# data summary
d_ex |> 
  ungroup() |>
  filter(trial_info=="diagnostic trial") |>
  summarize(
    .by = c(id, post_cue, congruent), 
    rt = mean(rt),
    pe = 1 - mean(correct_response)
  ) -> d_ex_test
```

## Table
```{r RT tables}
#| echo: false

# Freq:
## response times
d_ex_test |>
  aov_car(rt ~ post_cue*congruent + Error(id/(post_cue*congruent)), data=_) -> test

d_ex_test |> 
  rbind(d_ex_test |> 
          mutate(id = "waht")) |> 
  mutate(post_cue = factor(post_cue), 
         congruent = factor(congruent),
         id = factor(id)) -> testing2

anovaBF(rt ~post_cue*congruent + id, data= testing2, whichRandom = "id")
brms::brm(rt ~ post_cue*congruent + id, data = testing2)

d2 |>
  summarise(
    name             = "PE",
    m_incongruent    = fmt_APA_numbers( mean(pe_FALSE) ),
    sd_incongruent   = fmt_APA_numbers( sd(pe_FALSE) ),
    m_congruent      = fmt_APA_numbers( mean(pe_TRUE) ),
    sd_congruent     = fmt_APA_numbers( sd(pe_TRUE) ),
    Mdiff            = fmt_APA_numbers( mean(pe_FALSE - pe_TRUE) ),
    t                = fmt_APA_numbers( pe_test$statistic ),
    df               = pe_test$parameter,
    p                = pe_test$p.value,
    ps               = set_p_star(p),
    Mdiff            = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est            = fmt_APA_numbers( mean(pe_test_b2[,"mu"]) ),
    hdi              = paste0("[",fmt_APA_numbers(pe_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(pe_test_hdi$CI_high[1]),"]"),
    bf               = fmt_APA_numbers( extractBF(pe_test_b)$bf ),
    d                = fmt_APA_numbers( cohensD(pe_FALSE, pe_TRUE, method = "paired") ),
  ) -> d_pe

```

Table XX \n
*Test statistics for the experimental conditions*
```{r stat table}
#| echo: false
rbind(d_rt, d_pe) -> b
b |> summarize( m = mean(df) ) |> pull() -> d2_df
b |> pull(p) |> min() -> p_min

if(d2_df != floor(d2_df)){ warning("NOT SIMILAR, CHECK DF") }
  # degrees of freedom

mean(b$df) -> b_df_m
exp1_table_simple <- 
  b |>
  # add bayes row? 
  mutate(em1 = "", em2="", em3="",
         p = fmt_APA_numbers(p, .p=T),
         across(contains(c("con","b")), ~ fmt_APA_numbers(.x, .chr=T) ) ) |>
  gt() |>
  cols_hide(    c(df, ps, Mdiff) ) |>
  tab_spanner(  "Incongruent", c(m_incongruent, sd_incongruent) ) |>
  cols_label(   m_incongruent = md("*M*"), sd_incongruent = md("*SD*" ) ) |>
  tab_spanner(  "Congruent", c(m_congruent, sd_congruent) ) |>
  cols_label(   m_congruent = md("*M*"),  sd_congruent = md("*SD*") ) |>
  tab_spanner(  "Bayes", c(b.est, bf, hdi)) |>
  cols_label(   b.est = md("*M*~est~"), bf = md("BF~10~"), hdi = "HDI", ) |> 
  #fmt_markdown() |>
  #cols_move(    "ps", Mdiff ) |> 
  cols_move(    "em1", sd_incongruent ) |>
  cols_move(    "em2", ps ) |>
  cols_label(   em1 = "", em2 = "", name = "", d = md("Cohen's *d*"), em3 = "", 
                t = md( paste0("*t*(",b_df_m,")")), p = md("*p*") ) |>
  cols_align(   "center", c(2:15)) |> 
  cols_move(    "em3", hdi) 
exp1_table_simple

if(save_outputs){ gtsave(exp1_table_simple, filename = "../outputs/tables/exp2_table_simple.docx") }
```
*Note.* <br/>
`r fmt_APA_p_table_fig(p_min)` <br/>


## Figures
### Linerange
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

p1 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con2, y = rt, group=id, col = factor(con2)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(450, 960))+
                        # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Response time", x = "", y = "Response time (ms)")

p2 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(pct = mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pct, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(.65, 1.01))+
                      # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Proportion of correct trials", x = "", y = "Proportion")

p1+p2
if(save_outputs){ ggsave("../outputs/figs/exp2_rt-pe_line.jpeg", p1+p2, width=8, height=5) }
```

### Bar plot
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

p1 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = rt,fill = factor(con)))+
  stat_summary(fun = mean, geom = "col")+
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .4, size = 1, alpha = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,25), minor_breaks = NULL)+
  coord_cartesian(ylim = c(600, 750))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")+
  annotate("segment", x=-0.1, xend=1.1, y=696, yend=696, size=1)+
  annotate(geom = "text", x = .5, y=700, label="**", size=5)

p2 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(pe = 1 - mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, fill = factor(con2)))+
  stat_summary(fun=mean, geom="col")+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.4, size = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error")+
  annotate("segment", x=-0.1, xend=1.1, y=.13, yend=.13, size=1)+
  annotate(geom = "text", x = .5, y=.137, label="**", size=5)
    
p1 + p2

if(save_outputs){ ggsave("../outputs/figs/exp2_rt-pe_bar.jpeg", p1+p2, width=8, height=5) }
```



