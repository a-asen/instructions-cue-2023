---
title: "Experiment 2 - Preregistered Analysis"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries and load data, include=FALSE, warning=FALSE}
library(tidyverse)    # 
library(broom)        # tidying
library(afex)         # ANOVA
library(lme4)         # Mixed 
library(gt)
library(BayesFactor)  # Bayesian model
library(rstatix)      # Outliers (other?)

library(brms)   # bayesian regressionn
# ??? 
# library(bayestestR)
# library(patchwork)
# library(ggpp)
# library(lsr)

source("../lib/helper_functions.R")
```

```{r , include=FALSE}
bayes_plot <- function( data_list, rm_vars = NULL, par_match = TRUE){
  #' @param rm_vars   Vector string. Remove variables from coefficient plot 
  #' @param par_match Partial matching of rm_vars
  
  if(par_match){
    map(rm_vars, \(var){
       variables(data_list)[str_detect(variables(data_list), var)]
    }) |> unlist() -> remove_variables
  } else {
    remove_variables <- rm_vars
  }
  
  int <- variables(data_list)[str_detect(variables(data_list), "Intercept")]
  remove_list <- c(c("disc","lp__", "lprior"), remove_variables, int)
  gpars <- setdiff(variables(data_list), remove_list)
  brms::rhat(data_list) -> b
  
  if(max(b, na.rm=T) > 1.01){
    print(paste("max:", max(b, na.rm=T), " <- High, check model"))
  } else {
    print(paste("max:", max(b, na.rm=T)))
  }
  print(paste("mean:", mean(b, na.rm=T)))
  print(paste("median:", median(b, na.rm=T)))
  
  bayesplot::mcmc_intervals(as.matrix(data_list), pars=gpars, prob_outer = 0.95) + 
    geom_vline(xintercept = 0, linetype = "dashed", )+
    labs(title = colnames(data_list$data)[1])
}
```

```{r load data, include=FALSE, message=FALSE}
# demographics:
read_csv("../data/raw/experiment2/exp2_demo.csv") -> demo

# Behaviour data
# list.files("../data/raw/experiment2/pilots/", full.names = T)  -> fnames
list.files("../data/raw/experiment2/task/", full.names = T)  -> fnames
map_df(fnames, \(x){
  read_csv(x)
}) -> exp2_d
```

# Demographics

```{r , include=FALSE}
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    male = sum(s==1),
    female = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem

# demo |> mutate(n = 1:length(demo$Age)) -> ddemo
# 
# map(1:length(ddemo$Age), \(x){
#   l2 <- ddemo[-x,]
#   map(1:length(l2$Age), \(y){
#     l3 <- ddemo[-y,]
#     
#   }) |> list_rbind()
# }) |> list_rbind()
```

We recruited `r length(demo$Age)+4`, participants from the
United Kingdom via Prolific. Due to a coding mistake, four
participants did not generate any data. This left us with a
mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$females`
females) from the United Kingdom via Prolific. Note that two
participants were excluded from the data analysis, but cannot
be removed from the demographics due to non-connections
between data points and demographics variables.

# Data preparation

```{r prep base data, echo=FALSE}
d <- d_ex <- 
  exp2_d |> 
  select(id, trial_info, inducer_run, diagnostic_run, post_cue, congruent, rt, correct_response) |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  mutate(rt = as.integer(ifelse(rt=="null", NA,rt)),
         inducer_run = as.integer(inducer_run))
```

## Exclusion

```{r exclusion start - accuracy, include=FALSE}
loss <- list()
loss$raw_data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d_ex |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d_ex <- d_ex |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d_ex |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d_ex <- d_ex |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded,
representing `r loss[["inducer_practice_prop"]]` percent of
the data.

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (\> 30% error).

```{r due to high SD & NA responses, include=TRUE}
# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d_ex <- d_ex |>
  left_join(
    by = c("id","inducer_run","diagnostic_run"),
    d_ex |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id,
        rt_crit_low   = mean(rt, na.rm=T) - sd(rt, na.rm=T) * 2.5,
        rt_crit_high  = mean(rt, na.rm=T) + sd(rt, na.rm=T) * 2.5,
        rt_crit = ifelse( ( (rt >= rt_crit_high) | (rt <= rt_crit_low) ), 1, NA ),
        rt_na = ifelse(is.na(rt), 1, NA)
      ) |>
      select(id,inducer_run, diagnostic_run, rt_crit, rt_na)
  )

# lost trials
loss$rt_sd_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(rt_crit == 1 | rt_na==1) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100

# Exclude
d_ex <- d_ex |>
  filter( is.na(rt_crit) & is.na(rt_na) ) |>
  select(-rt_crit, -rt_na)
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.

```{r only correct inducers, include=TRUE}
d_ex <- d_ex |>
  mutate( valid_trials = case_when( 
    trial_info=="Inducer trial" & correct_response==1 ~ 1,
    trial_info=="Inducer trial" & correct_response==0 ~ 0,
    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
      # non-responses count as a wrong response
    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d_ex |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()

loss$inducer_fail_prop <-
  loss$inducer_fail_trials / loss$data_trials * 100


loss$total_lost_trials <- loss$inducer_practice_trials + loss$rt_sd_trials + loss$inducer_fail_trials
loss$total_lost_prop <- loss$inducer_practice_prop + loss$rt_sd_prop + loss$inducer_fail_prop

d_ex <-
  d_ex |>
  filter( valid_trials == 1 ) |>
  select(-valid_trials)
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials`
trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)`
percent of the data.

### Paragraph

The exclusion criteria resulted in the removal of
`r fmt_APA_numbers(loss$total_lost_prop)` %
(`r loss$total_lost_trials` trials) of the data. The first
round was considered practice and resulted in the loss of
`r fmt_APA_numbers(loss$inducer_practice_prop)` %
(`r loss$inducer_practice_trials` trials), while highly
deviating response times and non-responses accounted for
`r fmt_APA_numbers(loss$rt_sd_prop)` % (`r loss$rt_sd_trials`
trials), and a wrong response on the inducer trial resulted in
a loss of `r fmt_APA_numbers(loss$inducer_fail_prop)` %
(`r loss$inducer_fail_trials` trials).

# Analysis

```{r calculate BIS and LISAS, echo=TRUE}
# Liesefeld, H. R., & Janczyk, M. (2023). Same same but different: Subtle but consequential differences between two measures to linearly integrate speed and accuracy (LISAS vs. BIS). Behavior Research Methods, 55(3), 1175â€“1192. https://doi.org/10.3758/s13428-022-01843-2

# Grand:
grand <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    g_rt    = mean(rt),
    g_rt_sd = sd(rt),
    g_pc    = mean(correct_response),
    g_pe    = 1 - g_pc,
    g_pc_sd = sd(correct_response) 
  )
  
# LISAS: 
lisas <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    .by = id,
    l_rt_sd = sd(rt),
    l_pe_s  = sqrt( mean(correct_response) * (1 - mean(correct_response)) )
  )  

# Calculation
d_ex_test <- d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarise(
    .by = c(id, post_cue, congruent), 
    rt_sd   = sd(rt),
    rt      = mean(rt),
    pe_sd   = sd(correct_response),
    pe      = 1 - mean(correct_response),
    pc      = mean(correct_response),
  ) |> 
  left_join(lisas, by="id") |> 
  bind_cols(grand) |>
  mutate(
    lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe), 
    bis    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ),
    inv_bis = bis*-1,
  ) |> 
  select(id, post_cue, congruent, rt, rt_sd, pe, pe_sd, lisas, bis, inv_bis)
```

```{r why we have one more than expected, echo=FALSE}
# Why do we have 35? 
d_ex |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 

d |> 
  filter(inducer_run==max(inducer_run)) |> 
  summarise(id = unique(id) ) 
  
table(d_ex$inducer_run)
d_ex |> 
  group_by(id, inducer_run) |>
  summarise(n()) 
```

## Statistical test

### Normality

```{r calculate residual distribution, echo=T}
residual_norm <- 
  d_ex_test |> 
  pivot_longer(c(rt,pe,lisas,bis)) |>
  reframe(
    .by = name, 
    id = id,
    residuals = resid( lmer( value ~ post_cue + congruent + post_cue:congruent + (1|id) ) )
  ) 
```

```{r residual qqplot, echo=TRUE}
residual_norm |>
  ggplot(aes(sample = residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_qq() +
  geom_qq_line()
```

```{r residual histogram, echo=TRUE}
residual_norm |>
  ggplot(aes(residuals)) +
  facet_wrap(~ name, scales="free") +
  geom_histogram()
```

Generally, the residual errors seems to be normally distributed around 0. There are a couple of outliers, but they are also uniform (i.e., as much on both sides), albeit for the Errors with a slight skew. 

```{r raw distribution, include=FALSE}
d_ex_test |> 
  mutate(Cue = ifelse(post_cue==T, "Post", "Pre"),
         Congruency = fct_relevel(ifelse(congruent==T, "Congruent", "Incongruent"), "Congruent", after=1)) |>
  pivot_longer(c(rt,pe,lisas,inv_bis)) |>
  ggplot(aes(value, col = Congruency)) + 
  facet_wrap(name ~ Cue, scales="free", ncol=2) +
  geom_density()
```

### Outliers
```{r difference distribution, echo=TRUE}
d_ex_test |> 
  mutate(cue = ifelse(post_cue==T, "post","pre"),
         congruent = ifelse(congruent==T, "Congruent", "Incongruent")) |>
  select(-rt_sd,-pe_sd, -inv_bis,-post_cue) |>
  pivot_longer(c(rt,pe,bis,lisas)) |> 
  pivot_wider(
    names_from=c(cue, congruent), 
    values_from=c(value) 
  ) |>
  mutate(
    pre_diff   = pre_Incongruent - pre_Congruent,
    post_diff  = post_Incongruent - post_Congruent,
  ) -> d_ex_test_diff

d_ex_test_diff |>
  pivot_longer(c(pre_diff,post_diff),names_to="name2") |>
  ggplot(aes(y=value, col=name2))+
  facet_wrap(~name, scales="free")+
  geom_boxplot()+
  labs(col="Cue")
```

```{r finding outliers and extreme outliers, echo=TRUE}
# Exclude outliers
outlier_values <-
  d_ex_test_diff |> 
  pivot_longer(c(pre_diff, post_diff), names_to="name2") |>
  group_by(name)  |>
  identify_outliers(value)

id_is_outlier <- outlier_values |> filter(is.outlier==T) |> pull(id) |> unique()
id_is_extreme <- outlier_values |> filter(is.extreme==T) |> pull(id) |> unique()
```

Some outliers, check without. 

### Frequentist analyses
Statistical test of all 35 participants:

#### Table

```{r transform data object output, include=FALSE}
trns_mod <- function(data){
  d <- data$anova_table
  
  Fname <- paste0(
    "F (", unique(d$`num Df`), ",",
     unique(d$`den Df`),")" )
  
  d |> 
    mutate(names = c("Congrunecy","Cue", "Congruency_X_Cue")) |> 
    rename(!!Fname := `F`, p = `Pr(>F)`) |>
    select(names, all_of(Fname), p, pes) |> 
    mutate(across(2, ~fmt_APA_numbers(.x, .chr=T)),
           p = fmt_APA_numbers(p, .p=T),
           pes = fmt_APA_numbers(pes, .low_val=T))
}
```

```{r frequent rmanova and table, echo=TRUE}
pe_aov <- aov_car(pe ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
rt_aov <- aov_car(rt ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
lisas_aov <- aov_car(lisas ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))
bis_aov <- aov_car(bis ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
                     anova_table = list(es="pes"))

trns_mod(pe_aov) |> 
  mutate(group="Error rate") |>
  bind_rows(
    trns_mod(rt_aov) |> 
      mutate(group="Response time") ) |>
  bind_rows(
    trns_mod(lisas_aov) |>
      mutate(group="LISAS") ) |>
  bind_rows(
    trns_mod(bis_aov) |>
      mutate(group="BIS") ) |>
  pivot_wider(names_from = group, values_from = c(`F (1,34)`, p, pes)) |>
  select(names, ends_with("Error rate"), ends_with("Response time"), ends_with("LISAS"), ends_with("BIS")) |>
  gt() |>
  tab_spanner("Error rate", 
              c(`F (1,34)_Error rate`, `p_Error rate`, `pes_Error rate`)) |>
  tab_spanner("Response time", 
              c(`F (1,34)_Response time`, `p_Response time`, `pes_Response time`)) |>
  tab_spanner("LISAS", 
              c(`F (1,34)_LISAS`, `p_LISAS`, `pes_LISAS`)) |>
  tab_spanner("BIS", 
              c(`F (1,34)_BIS`, `p_BIS`, `pes_BIS`)) |>
  cols_label(`F (1,34)_BIS` = md("*F*(1,34)"), `F (1,34)_LISAS` = md("*F*(1,34)"), `F (1,34)_Response time` = md("*F*(1,34)"),
             `F (1,34)_Error rate` = md("*F*(1,34)"), p_LISAS = md("*p*"), p_BIS = md("*p*"), `p_Error rate`= md("*p*"), 
             `p_Response time` = md("*p*"), `pes_Error rate` =  )

```

#### Paragarph

The rmANOVA for error revealed a significant effect of
Congruency (*F*\~`r pe_aov$anova_table[["num Df"]][1]`,
`r pe_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(pe_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r pe_aov$anova_table[["num Df"]][2]`,
`r pe_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(pe_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r pe_aov$anova_table[["num Df"]][3]`,
`r pe_aov$anova_table[["den Df"]][3]`\~ =
`r pe_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(pe_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(pe_aov$anova_table[["pes"]][3], .low_val=T)`).

The rmANOVA for the LISAS revealed a significant effect of
Congruency (*F*\~`r lisas_aov$anova_table[["num Df"]][1]`,
`r lisas_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(lisas_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r lisas_aov$anova_table[["num Df"]][2]`,
`r lisas_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(lisas_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r lisas_aov$anova_table[["num Df"]][3]`,
`r lisas_aov$anova_table[["den Df"]][3]`\~ =
`r lisas_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(lisas_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(lisas_aov$anova_table[["pes"]][3], .low_val=T)`).

The rmANOVA for the LISAS revealed a significant effect of
Congruency (*F*\~`r bis_aov$anova_table[["num Df"]][1]`,
`r bis_aov$anova_table[["den Df"]][1]`\~ =
`r fmt_APA_numbers(bis_aov$anova_table$F[1])`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][1], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][1], .low_val=T)`),
suggesting lower errors for congruent trials. As for the cue,
the analysis did not reveal a significant effect of the Cue
(*F*\~`r bis_aov$anova_table[["num Df"]][2]`,
`r bis_aov$anova_table[["den Df"]][2]`\~ =
`r fmt_APA_numbers(bis_aov$anova_table$F[2])`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][2], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][2], .low_val=T)`),
nor an interaction effect
(*F*\~`r bis_aov$anova_table[["num Df"]][3]`,
`r bis_aov$anova_table[["den Df"]][3]`\~ =
`r bis_aov$anova_table$F[3]`, *p*
`r fmt_APA_numbers(bis_aov$anova_table[["Pr(>F)"]][3], .psym=T)`,
$\eta_p^2$ =
`r fmt_APA_numbers(bis_aov$anova_table[["pes"]][3], .low_val=T)`).

#### 34 partic tests

Since we preregistered a sample of 34, but do not know which
participant to remove, we include tests of all data with n-1.
We then report the minimum and maximum F and p value for the
conditions and interaction.

```{r anova with one participant removed, echo=FALSE, warning=FALSE}
d_ex_test |> 
  pull(id) |> unique() -> id_list
map_df(1:35, \(x){
  ez::ezANOVA(
    d_ex_test |> filter(!(id == id_list[x])), pe, id,
    within = c(post_cue, congruent), detailed = T)[["ANOVA"]] |>
    mutate(
      .before=1,
      rm_id = id_list[x]
    )
}) -> test_one_less
test_one_less |> 
  filter(Effect != "(Intercept)") |>
  summarise(
    .by = Effect,
    minF = min(`F`),
    maxF = max(`F`),
    maxP = max(p),
    minP = min(p),
  )
```

#### Robustness check

```{r remove outliers and test, echo=FALSE}
# is_extreme # there is no extreme outliers! 
is_outlier

# rt_aov <- aov_car(rt ~ Error(id/(congruent*post_cue)), d_ex_test, detailed=T, 
#                      anova_table = list(es="pes"))

o_pe_aov <- aov_car(pe ~ Error(id/(congruent*post_cue)), 
                  d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                  anova_table = list(es="pes"))

o_lisas_aov <- aov_car(lisas ~ Error(id/(congruent*post_cue)), 
                     d_ex_test |> 
                       filter(!(id %in% id_is_outlier)), detailed=T, 
                     anova_table = list(es="pes"))

o_bis_aov <- aov_car(bis ~ Error(id/(congruent*post_cue)), 
                   d_ex_test |> 
                    filter(!(id %in% id_is_outlier)), detailed=T, 
                   anova_table = list(es="pes"))

trns_mod(o_pe_aov) |> 
  mutate(group = "Error") |> 
  bind_rows(
    trns_mod(o_lisas_aov) |>
      mutate(group="LISAS")
  ) |>
  bind_rows(
    trns_mod(o_bis_aov) |>
      mutate(group="BIS")
  ) |> 
  pivot_wider(names_from=group, values_from = c(`F (1,25)`, p, pes)  )


tibble(names = "Error", `F (1,25)`=NA, p=NA, pes=NA) |>
  bind_rows(
    trns_mod(o_pe_aov) ) |> 
  # bind_rows(
  #   tibble(names = "Response time") ) |> 
  # bind_rows(
  #   trns_mod(rt_aov) ) |>
  bind_rows(
    tibble(names = "LISAS") ) |> 
  bind_rows(
    trns_mod(o_lisas_aov) ) |>
  bind_rows(
    tibble(names = "BIS") ) |> 
  bind_rows(
    trns_mod(o_bis_aov) ) |>
  gt()
```




### Bayesian Analyses 

```{r bayesian rmanova, echo=FALSE}
# Bayesian rmANOAV
pe_bay <- anovaBF(pe ~ post_cue * congruent + id, 
                  whichRandom = "id", 
                  d_ex_test |> mutate(id=factor(id),
                                      post_cue=factor(post_cue),
                                      congruent=factor(congruent))) 
pe_bay # only model with congruency 

lisas_bay <- anovaBF(lisas ~ post_cue * congruent + id,
                     whichRandom = "id", 
                     d_ex_test |> mutate(id=factor(id),
                                         post_cue=factor(post_cue),
                                         congruent=factor(congruent))) 
lisas_bay # Congruency + Cue  ---  secondary congruency+cue+interaction

bis_bay <- anovaBF(bis ~ post_cue * congruent + id, 
                   whichRandom = "id", 
                   d_ex_test |> mutate(id=factor(id),
                                       post_cue=factor(post_cue),
                                       congruent=factor(congruent))) 
bis_bay # Congruency + Cue  ---  secondary  congruency+cue+interaction
```

For errors, the model containing only congruency is favoured (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[2])`) compared to a model with only the Cue (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[1])`), Congruency and Cue (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[3])`), and Congruency, Cue and their interaction (BF~10~ = `r fmt_APA_numbers(pe_bay@bayesFactor$bf[4])`). 

For the LISAS, the model containing both the Congruency and Cue is favoured (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[2])`), but in close succession of the model with the Congruency, Cue and their interaction (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[4])`), followed by the model with only Congruency (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[2])`), and only the Cue (BF~10~ = `r fmt_APA_numbers(lisas_bay@bayesFactor$bf[1])`). 

A similar picture is found for the BIS model comparison: The model containing both Congruency and Cue is more favoured (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[3])`), but followed by the model including the interaciton term (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[4])`), only Congruency (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[2])`), and lastly, only the Cue (BF~10~ = `r fmt_APA_numbers(bis_bay@bayesFactor$bf[1])`). 

```{r n-1 repeated bayesian tests, echo=FALSE}
rep_test <- function(dep){
  map(1:35, \(x){
    anovaBF(as.formula(glue::glue("{dep} ~ post_cue * congruent + id")), 
            whichRandom = "id", 
            d_ex_test |>
              mutate(id=factor(id),
                    post_cue=factor(post_cue),
                    congruent=factor(congruent)) |>
              filter(!(id == id_list[x])) ) -> bres
    
    tibble(
      names = rownames(extractBF(bres)),
      bf = extractBF(bres)$bf,
      rm_id = id_list[x]
    )
  }) |> list_rbind() -> test_one_less
  
  test_one_less |> 
    summarise(
      .by = names,
      minBF = min(bf),
      maxBF = max(bf),
    )
}

rep <- list()
rep$pe_34 <- rep_test("pe")
rep$lisas_34 <- rep_test("lisas")
rep$bis_34 <- rep_test("bis")

rep$pe_34 |> 
  mutate(group = "Error") |> 
  bind_rows(
    rep$lisas_34 |> 
      mutate(group="LISAS")
  ) |> 
  bind_rows(
    rep$bis_34 |>
      mutate(group="BIS")
  ) |>
  mutate(across(where(is.double), ~fmt_APA_numbers(.x, .chr=T)),
         names = str_remove(names,"\\+ id$")) |>
  pivot_wider(names_from=group, values_from=c(minBF, maxBF)) |>
  gt()
```

The pattern of results found for the 35 participants is reflected in all 34 sampled tests (n-1), per the preregistered sample size. 



```{r bayesian rmanova, echo=FALSE}
posterior(bay_res, 2, iterations = 10000) -> test
test
colnames(test)

library(brms)
library(cmdstanr)
library(bayesplot)
library(bayestestR)

bay_res2 <- brm(pe ~ congruent + post_cue + congruent:post_cue + (1|id), 
                d_ex_test, save_pars = save_pars(all=T),
                iter = 6000, chains = 6, backend = "cmdstanr", cores = 6, init=0)

variables(bay_res2) -> vars
vars[str_detect(vars, "b_")] -> vars
mcmc_acf(as.array(bay_res2), pars=vars)   # autocorrelation
mcmc_trace(as.array(bay_res2), pars=vars) # mcmc draws
bayes_plot(bay_res2, c("z_", "sigma"))    # coefficient plot

summary(bay_res2)

fixef(bay_res2) |> 
  as_tibble() |> 
  mutate(.before=1, names = rownames(fixef(bay_res2)), 
         across(where(is.double), ~fmt_APA_numbers(.x, .low_val=T)), 
         Est.Error=NULL)

```

**SPHERISITY?**

## Figures

```{r data vis calculation, include=FALSE}
data_vis <- 
  d_ex_test |> 
  mutate(
    Cue = ifelse(post_cue==T, 1,0),
    Congruency = fct_relevel( ifelse(congruent==F, "Incongruent", "Congruent"), "Incongruent"),
    bis_inv = -1 * bis,
    con = ifelse(congruent==T, 1,0),
  ) |>
  rename(`Response time` = rt, `Error rate` = pe, LISAS = lisas, BIS = bis_inv) |>
  pivot_longer(c(`Response time`,`Error rate`, LISAS, BIS)) |>
  mutate(name = fct_relevel(name, "Response time", "Error rate", "LISAS", "BIS"))
```

```{r visualize across all, echo=TRUE}
data_vis |>
  ggplot(aes(Cue, value, col = Congruency)) +
  facet_wrap(~name, scales="free") + 
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25))+
  labs(x=NULL, y="Error rate")
```

```{r indiv vis, echo=TRUE}
data_vis |>
  filter(name =="Error rate") |>
  ggplot(aes(Cue, value, col = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25), ylim=c(0,.1))+
  labs(x=NULL, y="Error rate")

data_vis |>
  filter(name =="BIS") |>
  ggplot(aes(Cue, value, col = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.1)) +
  stat_summary(fun.data = mean_se, geom="line", 
               position=position_dodge(.1), ) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  # coord_cartesian(xlim=c(-.25,1.25), ylim=c(0,.1))+
  labs(x=NULL, y="BIS")



```

```{r bar plot, echo=FALSE}
data_vis |>   
  filter(name == "Response time") |>
  ggplot(aes(Cue, value, fill = Congruency)) +
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="col", width=.75)+
  stat_summary(fun.data = mean_se, position=position_dodge(.75), geom="errorbar", width=.5) +
  scale_x_continuous(breaks=c(0,1),labels = c("Pre-cue", "Post-cue"))+
  coord_cartesian(xlim=c(-.25,1.25), ylim=c(550, 750))+
  labs(x = NULL, y="Response time")
```

## Table

```{r finished table}
#| echo: false


exp2_statistic_table
```

*Note.* <br/>
`r fmt_APA_p_table_fig(exp2_statistic_table$p[2])` <br/>
<!--- This function could be improved by finding the lowest value in a p vector --->

## ELSE

### Feedback

```{r}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["response"]]) |>
    as_tibble() |>
    mutate(id = x)
}) -> exp2_feedback

exp2_feedback |>
  mutate(loss = id %in% loss$exclude_par) |> 
  view()
```

### Interactive

```{r}
map_df(unique(exp2_d$id),\(x){
  exp2_d[exp2_d$trial_info=="End of experiment feedback" & 
           !is.na(exp2_d$trial_info) & 
           exp2_d$id==x,] -> d
  jsonlite::fromJSON(d[["interactive"]]) |> as_tibble() |>
    mutate( id = x)
}) -> exp2_interactive
exp2_interactive |> 
  arrange(trial) 
```

