---
title: "How many diagnostic pairs do we need?"
subtitle: "Slicing from experiment 1"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

# Start

```{r params}
#| include: false

run_simulations <- FALSE
save_simulation_data <- FALSE
load_simulation_data <- TRUE
```

```{r libraries}
#| include: false

library(tidyverse)
library(arrow)     # load parquet files 
library(parallel)  # Parallel processing
library(pbapply)   # Progression bar + parallel processing
library(broom)

# ? 
# library(lsr)
# library(afex)
```

```{r create cluster}
#| include: false
if(run_simulations){
  cl <- makeCluster(detectCores()*.95)
  clusterEvalQ(cl, {
    library(tidyverse)
    library(tidymodels)
  })
  clusterExport(cl, "d_ex")
} else { cl <- NULL }
```

# data

```{r load data}
#| include: false
load("../data/processed/exp1_data.rdata")
load("../data/simulations/diag_simu_sum.rdata")

if(load_simulation_data){
  # Random slicing: 
  ## Random slicing of the 27 participants: 
  rnd_slice_diag_exclu <- read_parquet("../data/simulations/exp2_diagnostic_length_sampling_from_exp1_raw.parquet")
  sum_rnd_slice_diag_exclu <- read_parquet("../data/simulations/exp2_diagnostic_length_sampling_from_exp1_sum.parquet")
  ## Random slicing over increasing sample size (fake ids)
  rnd_extended_slice_diag_exclu <- read_parquet("../data/simulations/exp1_rnd_sampling_inc_samp_size.parquet")
  sum_rnd_extended_slice_diag_exclu <- read_parquet("../data/simulations/exp1_sum_rnd_sampling_inc_samp_size.parquet")
 
  ## Random slicing over increasing sample size and integrated score calculations
  rnd_int_scores_extended_slice_diag_exclu <- read_parquet( "../data/simulations/exp1_rnd_sampling_inc_samp_size_integrated_scores.parquet")
  sum_rnd_int_scores_extended_slice_diag_exclu <- read_parquet( "../data/simulations/exp1_sum_rnd_sampling_inc_samp_size_integrated_scores.parquet") 
  #    write_parquet(diag_lens_over_samp_sizes, "../data/simulations/diag_lens_over_sample_sizes.parquet")
    #write_parquet(sum_diag_lens_over_samp_sizes, "../data/simulations/diag_lens_over_sample_sizes_sum.parquet")
}
```

```{r preprocess}
#| include: false
# preprocess 
source("rep_munge/exp1_preprocess.R")
```

# Experiment 1:

## Estimating the expected loss of data (trials)

```{r}
#| include: false
d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id) |>
  count() |> 
  pull(n) |>
  mean() -> exp1_remaining_trials
```

After the exclusion criteria, we are left with
`r exp1_remaining_trials` trials.

This corresponds to a loss of `r exp1_remaining_trials/240`
(or `r exp1_remaining_trials/240*100` percent). 

In other words, whatever post-cue run we decide, we need to
estimate an expected loss of about `r exp1_remaining_trials/240`.


## Experiment 1 outcome values

### t.test

Calculate the standardized means and standard deviations, and
effect sizes from experiment 1.

(note. this is for the *excluded* data)

```{r exp1 outcomes}
#| echo: false

d_ex |> 
  ungroup() |>
  filter(!is.na(con)) |>
  summarise(
    rt = mean(rt), 
    pe = 1 - mean(correct_response),
    .by = c(id, con)
  ) |> 
  mutate(
    rt = scale(rt),
    pe = scale(pe)
  ) |>
  pivot_wider(names_from = con, values_from = c(rt,pe)) |>
  summarise(
    rt_d_m = mean(rt_FALSE-rt_TRUE),
    rt_d_sd = sd(rt_FALSE-rt_TRUE),
    rt_d = rt_d_m / rt_d_sd,
    pe_d_m = mean(pe_FALSE-pe_TRUE),
    pe_d_sd = sd(pe_FALSE-pe_TRUE),
    pe_d = pe_d_m / pe_d_sd,
  ) -> exp1_outcome
exp1_outcome
```

# Slicing from experiment 1:
Parameters:

```{r echo: F}
loss_trials  <- exp1_remaining_trials/240
n_diag_pairs <- 36 #pairs
```

## Slice from the START

```{r}
#| echo: false
pblapply(2:90, \(pairs){
  d_ex |>
    filter(inducer_run>0) |>
    slice_head(n = pairs, by = c(id, con)) |>
    summarise(
      .by = c(id, con),
      rt = mean(rt),
      pe = 1 - mean(correct_response)
    ) -> test
  
  test |>
    t.test(rt ~ con, data=_, paired = T) |> 
    tidy() |> mutate(.before=1, n = "rt") |>
    rbind(
      test |> 
        t.test(pe ~ con, data=_, paired=T) |> 
        tidy() |> mutate(.before=1, n="pe")
    ) |> 
    mutate(.before=1, pairs=pairs)
}, cl = cl) |> 
  map_df(~.x) -> 
  head_slice_diag_exclu
```

```{r slice from start}
#| echo: false
head_slice_diag_exclu |>
  #pivot_wider(names_from=n, values_from = 3:10) |>
  ggplot(aes(pairs, p.value, col = n)) + 
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_vline(xintercept=n_diag_pairs, linetype="dashed")+
  geom_vline(xintercept=n_diag_pairs*loss_trials, linetype="dashed", col="red")
```

Slicing from the **start** (!) suggest that we need around 20
pairs (i.e., 40 trials) to a achieve a significance result.

## Slice from the END

```{r slice from end}
#| include: false
pblapply(2:90, \(pairs){
  d_ex |>
    filter(inducer_run>0) |>
    slice_tail(n = pairs, by = c(id, con)) |>
    summarise(
      .by = c(id, con),
      rt = mean(rt),
      pe = 1 - mean(correct_response)
    ) -> test
  
  test |>
    t.test(rt ~ con, data=_, paired = T) |> 
    tidy() |> mutate(.before=1, n = "rt") |>
    rbind(
      test |> 
        t.test(pe ~ con, data=_, paired=T) |> 
        tidy() |> mutate(.before=1, n="pe")
    ) |> 
    mutate(.before=1, pairs=pairs)
}, cl = cl) |> 
  map_df(~.x) -> 
  tail_slice_diag_exclu
```

```{r end slice vis }
#| echo: false
tail_slice_diag_exclu |>
  #pivot_wider(names_from=n, values_from = 3:10) |>
  ggplot(aes(pairs, p.value, col = n)) + 
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_vline(xintercept=n_diag_pairs, linetype="dashed")+
  geom_vline(xintercept=n_diag_pairs*loss_trials, linetype="dashed", col="red")
```

Slicing from the **end** reveal a similar pattern, but would
require more trials - around 25 trials for PE, but even more
for RT.

## Randomly slicing

Instead of slicing from the start/end, we can randomly slice.

```{r rnd sampling}
#| echo: false
if(run_simulations){
  pblapply(2:100, \(pairs){
    map_df(1:900, \(itr){
      d_ex |>
        filter(!is.na(con)) |>
        slice_sample(n = pairs, by = c(id, con)) |>
        summarise(
          .by = c(id, con),
          rt_sd = sd(rt),
          rt = mean(rt),
          pe_sd = sd(correct_response),
          pe = 1 - mean(correct_response)
        ) -> test
      
      test |>
        select(-rt_sd, -pe_sd) |>
        mutate(rt = scale(rt), pe = scale(pe)) |>
        pivot_longer(c(rt,pe)) |>
        pivot_wider(names_from = con, values_from = value) |>
        summarise(
          .by = name,
          m_d   = mean(`FALSE` - `TRUE`),
          sd_d  =   sd(`FALSE` - `TRUE`) ) |>
        left_join(
          by = join_by(name == n),
          test |>
            t.test(rt ~ con, data=_, paired = T) |> 
            tidy() |> 
            mutate(.before=1, n = "rt") |>
            bind_rows(
              test |> 
                t.test(pe ~ con, data=_, paired=T) |> 
                tidy() |> 
                mutate( .before=1, n="pe" ) )
        ) |>
        mutate(.before = 1, 
               pairs   = pairs,
               itr     = itr )
    })
  }, cl=cl) |> 
      map_df(~.x) -> 
    rnd_slice_diag_exclu
  
  # Summarise
  rnd_slice_diag_exclu |>
    summarise(
      .by = c(pairs,n),
      power = mean(p.value<.05), 
      across(where(is.double), mean)
    ) -> sum_rnd_slice_diag_exclu

  # Save
  if(save_simulation_data){
    write_parquet(rnd_slice_diag_exclu, "../data/simulations/exp2_diagnostic_length_sampling_from_exp1_raw.parquet")
    write_parquet(sum_rnd_slice_diag_exclu,"../data/simulations/exp2_diagnostic_length_sampling_from_exp1_sum.parquet")
  }
}
```

```{r vis power}
#| echo: false
#| warning: false

sum_rnd_slice_diag_exclu |>
  ggplot(aes(pairs, power, col = n)) + 
  geom_line()+
  geom_hline(yintercept=.8)+
  scale_y_continuous(breaks=seq(0,1,.1))+
  geom_vline(xintercept=n_diag_pairs, linetype="dashed")+
  geom_vline(xintercept=n_diag_pairs*loss_trials, linetype="dashed", col="red")
```

For 27 participants we will have less than 50% power for RT
for the set diagnostic trials `r n_diag_pairs` and even less
for after the exepcted loss `r n_diag_pairs*loss_trials`.

Only PE will be marginally close to 80% power with the
expected available trials `r n_diag_pairs*loss_trials` with
the set post-cue diagnostic length or `r n_diag_pairs`


### Changes in mean differences by increasing the number of pairs

How the mean differences for PE and RT change with increase pairs of the diagnostic trial. 
```{r}
#| echo: false
rnd_slice_diag_exclu |> 
  ggplot(aes(pairs, m_d, col=name))+
  stat_summary(geom="line")
```

## Randomly slicing congruency & and increase sample size

Here I slice only on congruency, and create "hypothetical
persons", by giving them an ID. This means that some "persons"
can contain congruent outcomes from one ID while incongruent
from another ID.

```{r rnd sample and increase}
#| echo: false
if(run_simulations){
  pblapply(27:60, \(samp_s){
    map_df(10:90, \(pairs){
      map_df(1:500, \(itr){
        # We create random "ids" by randomly sampling "samp_s" times,
        # And create a fake id "rnd_id_" 
        map_df(1:samp_s, \(rnd_samp){
          d_ex |>
            filter(!is.na(con)) |>
            slice_sample(n = pairs, by = con) |> 
            mutate(id = paste0("rnd_id_", rnd_samp))
        }) |>
          summarise(
            .by = c(id, con),
            rt = mean(rt),
            pe = 1 - mean(correct_response)
          ) -> test
      
        test |>
          t.test(rt ~ con, data=_, paired = T) |> 
          tidy() |> mutate(.before=1, n = "rt") |>
          rbind(
            test |> 
              t.test(pe ~ con, data=_, paired=T) |> 
              tidy() |> mutate(.before=1, n="pe")
          ) |> 
          mutate(
            .before=1, 
            samp  = samp_s,
            pairs = pairs,
            itr   = itr,
          )
      })
    })
  }, cl=cl) |> 
    map_df(~.x) -> 
    rnd_extended_slice_diag_exclu
  
  rnd_extended_slice_diag_exclu |>
    na.omit() |> # omit nas
    summarise(
      .by = c(samp,pairs,n),
      power = mean(p.value<.05), 
      across(where(is.double), mean)
    ) -> sum_rnd_extended_slice_diag_exclu
  
  if(save_simulation_data){
    write_parquet(rnd_extended_slice_diag_exclu, "../data/simulations/exp1_rnd_sampling_inc_samp_size.parquet")
    write_parquet(sum_rnd_extended_slice_diag_exclu, "../data/simulations/exp1_sum_rnd_sampling_inc_samp_size.parquet")
  }
}
```

Power increase over pairs, split by sample size.

```{r}
#| echo: false
sum_rnd_extended_slice_diag_exclu |> 
  ggplot(aes(pairs, power, col=samp,group=samp))+
  facet_wrap(~n)+
  geom_line()+
  geom_hline(yintercept=.8)+
  scale_y_continuous(breaks=seq(0,1,.1))+
  geom_vline(xintercept=n_diag_pairs, linetype="dashed")+
  geom_vline(xintercept=n_diag_pairs*loss_trials, linetype="dashed", col="red")
```

Power over sample size split by pairs.

```{r summarise}
#| echo: false
#| warning: false
sum_rnd_extended_slice_diag_exclu |>
  ggplot(aes(samp, power, col=pairs,group=pairs))+
  facet_wrap(~n)+
  geom_hline(yintercept=.8)+
  geom_line()
```

Power over sample size split by 36 and 26 pairs of
observations.

```{r}
#| echo: false
sum_rnd_extended_slice_diag_exclu |> 
  filter(pairs %in% c(n_diag_pairs, round(n_diag_pairs*loss_trials))) |>
  ggplot(aes(samp, power, col=factor(pairs),group=factor(pairs)))+
  facet_wrap(~n)+
  geom_line()+ 
  geom_hline(yintercept=.8)+
  geom_hline(yintercept=.9, linetype="dashed", col="darkblue")+
  geom_vline(xintercept=34)
```

Random slicing from the first experiment suggests that we
would need slightly more than 30 participants (34) to achieve
80% power for PE. RT, on the other hand, remains below 50% for
after the expected loss. In other words, increasing the sample
size will not remedy the problem for RT.

One way to remedy this problem is by investigating the utility
of the integrated scores.

## Randomly slicing w/integrated score

```{r}
#| echo: false
if(run_simulations){
  pblapply(27:56, \(samp_s){
    map_df(10:80, \(pairs){
      map_df(1:500, \(itr){
        # We create random "ids" by randomly sampling "samp_s" times,
        # And create a fake id "rnd_id_" 
        map_df(1:samp_s, \(rnd_samp){
          d_ex |>
            filter(inducer_run>0) |>
            filter(!is.na(con)) |>
            slice_sample(n = pairs, by = con) |> 
            rename(original_id = id) |>
            mutate(id = paste0("rnd_id_", rnd_samp))
        }) -> test

        # Grand:
        grand <- 
          test |>
          summarize(
            g_rt = mean(rt),
            g_rt_sd = sd(rt),
            g_pc = mean(correct_response),
            g_pe = 1 - g_pc,
            g_pc_sd =  sd(correct_response) )
        
        # LISAS:
        lisas <- 
          test |>
          summarize(
            .by = id,
            l_rt = mean(rt),
            l_rt_sd = sd(rt),
            l_pe = 1 - mean(correct_response), 
            l_pe_sd =  sd(correct_response) )
          
        # Calculation
        res <-
          test |>
          summarise(
            .by = c(id, con), 
            rt_sd = sd(rt),
            rt = mean(rt),
            pe_sd = sd(correct_response),
            pe = 1 - mean(correct_response),
            pc = mean(correct_response),
          ) |> 
          left_join(lisas, by="id") |> 
          cbind(grand) |>
          as_tibble() |>
          mutate(
            lisas  = ifelse(is.infinite(l_rt_sd/l_pe_sd), rt, rt + (l_rt_sd/l_pe_sd) * pe), 
            BIS    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ) )
          
        res |>
          t.test(lisas ~ con, data=_, paired = T) |> 
          tidy() |> 
          mutate(.before=1, n = "LISAS") |>
          rbind(
            res |> 
              t.test(BIS ~ con, data=_, paired=T) |> 
              tidy() |> 
              mutate(.before=1, n="BIS")
          ) |> 
          mutate(
            .before=1, 
            samp  = samp_s,
            pairs = pairs,
            itr   = itr,
          )
      })
    })
  }, cl = cl) |> 
    map_df(~.x) -> 
    rnd_int_scores_extended_slice_diag_exclu
  
  rnd_int_scores_extended_slice_diag_exclu |>
    summarise(
      .by = c(samp,pairs,n),
      power = mean(p.value<.05), 
      across(where(is.double), mean)
    ) -> sum_rnd_int_scores_extended_slice_diag_exclu
  
  if(save_simulation_data){
    write_parquet(rnd_int_scores_extended_slice_diag_exclu, "../data/simulations/exp1_rnd_sampling_inc_samp_size_integrated_scores.parquet")
    write_parquet(sum_rnd_int_scores_extended_slice_diag_exclu, "../data/simulations/exp1_sum_rnd_sampling_inc_samp_size_integrated_scores.parquet")
  }
}
```

```{r summarise integrated score}
#| echo: false
#| warning: false
sum_rnd_int_scores_extended_slice_diag_exclu |>
  ggplot(aes(samp, power, col=pairs,group=pairs))+
  facet_wrap(~n)+
  geom_hline(yintercept=.8)+
  geom_line()
```

```{r integrated scores summary of relevant pairs}
#| echo: false
sum_rnd_int_scores_extended_slice_diag_exclu |> 
  filter(pairs %in% c(n_diag_pairs, round(n_diag_pairs*loss_trials))) |>
  ggplot(aes(samp, power, col=factor(pairs),group=factor(pairs)))+
  facet_wrap(~n)+
  geom_line()+ 
  geom_hline(yintercept=.8)+
  geom_hline(yintercept=.9, linetype="dashed", col="darkblue")+
  geom_vline(xintercept=34)
```

Relying on the BIS or LISAS will give us at least 80% power
with 30 participants, but around 90% power with 34
participants.

--------------------------------------------------------------

~Generated generated `r Sys.time()`~
