---
title: "Experiment 1 - Exploratory"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r param}
#| include: false
save_outputs <- FALSE
```

```{r libraries }
#| include: FALSE
library(tidyverse)
library(patchwork)
library(gt)
library(BayesFactor)
library(bayestestR)
library(lsr)
library(lme4)
library(jsonlite)
source("../lib/helper_functions.R")
```

```{r citation}
#| include: false

citation("tidyverse")
citation("patchwork")
citation("gt")
citation("BayesFactor")
citation("bayestestR")
citation("lsr")
citation("lme4")
citation("jsonlite")
```

# Data prep

```{r load data }
#| include: FALSE
list.files("../data/raw/experiment1/task", pattern = "*.csv", full.names = T) -> fnames

map_df(fnames, \(x){
  read_csv(x)
}) -> data

read_csv("../data/raw/experiment1/exp1_demo.csv") -> demo
```

```{r transformation}
#| include: FALSE
# Pre-transformation
data |>
  mutate(rt = as.integer(ifelse( rt == "null", NA, rt ))) -> data
```

```{r base data }
#| include: false
# Select the relevant columns & rows
# Remove the first inducer_run (i.e., 0th)
data |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, congruent) |>
    # note. Congruent has a conding error. Recalculating congruency is done below
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial") -> d
```

```{r recalculating the congruency effect}
#| include: false

#' Due to a typo in the task script, the congruency output would (for some participants)
#' be the opposite. 

raw_d <- 
  data |> 
  dplyr::select(id, trial_info, diagnostic_run, italic, inducer_run, stimulus, congruent, correct_diag_response_side, response, correct_response,rt) |>
  filter(trial_info=="Diagnostic trial" | trial_info=="Inducer instructions" | trial_info =="Diagnostic instructions") |>
  mutate(inducer_run = as.numeric(inducer_run),
         italic = ifelse(italic=="true", TRUE, FALSE)) |>
  fill(inducer_run, .direction = "up") |>
  group_by(id) |>
  mutate( 
    diag_ins = stimulus[trial_info=="Diagnostic instructions"],
    if_italic = str_split(diag_ins, " ") |> map_chr(4) ) |> 
  ungroup() |>
  group_by(id, inducer_run) |> 
  # reframe(ins = stimulus[trial_info=="Inducer instructions"] ) 
  mutate(
    response_side = ifelse(response=="j", "RIGHT", "LEFT"),
    #
    indu_ins = stimulus[trial_info=="Inducer instructions"], 
    ins_left = str_split(indu_ins, " | ") |> map_chr(2),
    ins_right = str_split(indu_ins, " | ") |> map_chr(7),
    ins_resp = str_split(indu_ins, " | ") |> map_chr(4),
    #
    inducer_tap  = ifelse(stimulus==ins_left, ins_resp, ifelse(ins_resp=="LEFT", "RIGHT", "LEFT")),
    diag_tap     = ifelse(italic, if_italic, ifelse(if_italic=="LEFT", "RIGHT","LEFT") ) ) |>
  filter(trial_info=="Diagnostic trial") |> 
  ungroup() |>
  mutate(con = ifelse(inducer_tap==diag_tap, T,F)) |>
  dplyr::select(id, inducer_run, diagnostic_run, con)

d <- 
  d |> 
  mutate(inducer_run = as.numeric(inducer_run)) |>
  left_join(raw_d, by=c("id","inducer_run", "diagnostic_run"))
# trials: 7656
```

# Exclusion
```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$raw_data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# Exclude: 
d <- d |> 
  filter(!(id %in% loss$exclude_par))

# RELEVANT DATA START HERE
loss$data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

# Inducer practice
loss$inducer_practice_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# Exclude: 
d <- d |> 
  filter(inducer_run > 0)
```

```{r due to high SD & NA responses }
#| include: FALSE

# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d <- d |> 
  left_join( 
    by = c("id","inducer_run","diagnostic_run"),
    d |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id, 
        rt_crit_low   = mean(rt) - sd(rt) * 2.5,
        rt_crit_high  = mean(rt) + sd(rt) * 2.5,
        retain_trials = ifelse(
          ( ( rt >= rt_crit_high) | (rt <= rt_crit_low) & (is.na(rt)) ),
            0, 1) 
      ) |>
      select(id,inducer_run, diagnostic_run, retain_trials) 
  )

# IMPORTANT NOTE: 
  #' Removing null RT responses are, in all theory, not preregistered. 
  #' While there is a solution to "non-responses" for error (count them as wrong), 
  #' there is no stated solution to response time. Generally, this leads to problems 
  #' because a trial can be considered wrong under error conditions, while the accompanied 
  #' "error" for response time is not obvious. Should the RT be 2000ms (max trial length)? 
  #' Or should it be closer to infinity? 
  #' 
  #' Assuming a max trial length of 2000ms would highly likely yield exclusion based on 
  #' the max rt * 2.5 SD (but that is not a given). 
  #' 
  #' It is not obvious what to do in such a case, and the simplest solution will 
  #' be to exclude (remove) these trials). Even though this may be assumed from
  #' the preregistration, it is *not* preregistered.


# lost trials
loss$rt_sd_trials <- d |> 
  filter(diagnostic_run >= 0) |> 
  filter(retain_trials == 0) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100


# Exclude
d <- d |>
  filter(retain_trials == 1 | is.na(retain_trials) ) 
```

```{r only correct inducers}
#| include: FALSE
d <- d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |> 
  nrow()
  
loss$inducer_fail_prop <- 
  loss$inducer_fail_trials / loss$data_trials * 100

d <- d |> filter( valid_trials == 1 )
```
# Integrated measures:

## LISAS

```{r lisas calculation}
#| echo: false
#| warning: false
#| message: false

# Linear integrated speed-accuracy score (LISAS) 
# See Vandierendonck 2017 @ https://doi.org/10.3758/s13428-016-0721-5
# Calculation according to: Liesefeld & Janczyk 2023 @ https://doi.org/10.3758/s13428-022-01843-2

lisas_grand <- d |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id) |>
  summarize(
    l_rt_sd = sd(rt),
    l_pe_s  = sqrt( mean(correct_response) * (1 - mean(correct_response)) ) 
  )

lisas_ind <- d |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id, con) |>
  summarize(rt = mean(rt, na.rm = TRUE),
            pe = 1 - mean(correct_response) )
  #pivot_wider( names_from = con, values_from = c(rt, pe) ) -> lisas_ind

lisas <- 
  lisas_ind |>
  left_join(lisas_grand, by="id") |> ungroup() |>
  # group_by(id, con) |>
  mutate(lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe)) 


w_lisas <- 
  lisas |> 
  pivot_wider(names_from=con, values_from=c(everything(), -con,-id)) 

t_lisas  <- t.test( w_lisas$lisas_FALSE, w_lisas$lisas_TRUE, paired=T)
b_lisas  <- ttestBF(w_lisas$lisas_FALSE, w_lisas$lisas_TRUE, paired=T)
b_lisas2 <- ttestBF(w_lisas$lisas_FALSE, w_lisas$lisas_TRUE, paired=T, posterior = T, iterations = 10000)

w_lisas |>
  rowwise() |>
  mutate(l_diff = lisas_FALSE - lisas_TRUE) |> 
  ungroup() |> 
  summarize(
    m_incongruent   = fmt_APA_numbers( mean(lisas_FALSE) ),
    sd_incongruent   = fmt_APA_numbers( sd(lisas_FALSE) ),
    m_congruent     = fmt_APA_numbers( mean(lisas_TRUE) ),
    sd_congruent     = fmt_APA_numbers( sd(lisas_TRUE) ),
    p               = t_lisas$p.value,
    ps              = set_p_star(p),
    t               = t_lisas$statistic,
    df              = t_lisas$parameter,
    Mdiff           = paste0( fmt_APA_numbers( mean(l_diff) ), ps),
    b.est           = fmt_APA_numbers( mean( b_lisas2[,"mu"] ) ), 
    bf              = fmt_APA_numbers( extractBF(b_lisas)$bf ), 
    hdi             = paste0("[", fmt_APA_numbers( hdi(b_lisas)[3] ), ", ", 
                                  fmt_APA_numbers( hdi(b_lisas)[4] ), "]" ), 
    d               = fmt_APA_numbers( cohensD(lisas_FALSE, lisas_TRUE, method="paired") )
    ) -> lisas_t

```

## BIS

```{r  BIS calc}
#| echo: false

# Balanced integration score (BIS) 

# Calculation: 
# See Liesefeld & Janczyk 2019 @ https://doi.org/10.3758/s13428-018-1076-x
# See Liesefeld & Janczyk 2023 @ https://doi.org/10.3758/s13428-022-01843-2
# 
g_bis <- 
  d |>
  filter(trial_info=="Diagnostic trial") |>
  ungroup() |>
  summarize(g_rt = mean(rt, na.rm = TRUE),
            g_rt_sd = sd(rt),
            g_pc = mean(correct_response),
            g_pc_sd =  sd(correct_response),)

d |>
  filter(trial_info=="Diagnostic trial") |>
  ungroup() |>
  summarize(g_rt = mean(rt, na.rm = TRUE),
            g_rt_sd = sd(rt),
            g_pc = mean(correct_response),
            g_pc_sd =  sd(correct_response),)

ind_bis <- 
  d |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id, con) |>
  summarize(rt = mean(rt, na.rm = TRUE),
            pc = mean(correct_response) )

BIS <- 
  ind_bis  |>
  cbind(g_bis) |> 
  mutate(con = ifelse(con==FALSE, "Incongruent", "Congruent")) |>
  group_by(id, con) |>
  mutate(BIS  = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ) )

bis__lisas <- 
  lisas |> 
  ungroup() |>
  mutate(con = ifelse(con==FALSE, "Incongruent", "Congruent"), 
            # item values 
         # lisas_s = scale( lisas ) ) #|>
            # standardize: would have to be done at calculation to yield informative output? 
  ) |>
  left_join(BIS, by=c("id", "con")) |>
  mutate(BIS_inv = -1*BIS,
          # inverse
         BIS_lisas = (-1*BIS) * g_rt_sd + g_rt ,
          # Inverse & RT correct
         ) |>
  rename(rt = rt.x) |>
  dplyr::select(id, con, rt, pe, lisas, BIS_lisas, BIS) 
```

## Table: LISAS+BIS

```{r}
#| echo: false

tab <- 
  bis__lisas |> 
  pivot_longer(c(rt,pe,lisas,BIS,BIS_lisas))  |>
  pivot_wider(names_from=con, values_from=value ) |>
  mutate(diff = Incongruent - Congruent) |>
  rowwise() |>
  group_by(name) |>
  reframe(
    m_incon   = mean(Incongruent),
    sd_incon  = sd(Incongruent),
    m_con     = mean(Congruent),
    sd_con    = sd(Congruent),
    mdiff     = mean(Incongruent-Congruent),
    t.val     = t.test(Incongruent, Congruent, paired=T, alternative = "greater")$statistic,
    df        = t.test(Incongruent, Congruent, paired=T, alternative = "greater")$parameter,
    p.val     = t.test(Incongruent, Congruent, paired=T, alternative = "greater")$p.value |> fmt_APA_numbers(.p = T), 
    b.est     = mean( ttestBF(Incongruent, Congruent, paired=T, posterior=T, iterations=5000)[,"mu"] ),
    b         = extractBF( ttestBF(Incongruent, Congruent, paired=T) )$bf,
    hdi       = paste0("[",
      hdi( ttestBF(Incongruent, Congruent, paired=T, posterior=T, iterations=5000) )[1,3:4] |> 
            map(fmt_APA_numbers)  |> 
            paste0(collapse=", "), 
      "]", sep="" ),
    d         = cohensD(Incongruent, Congruent, method = "paired"),
  ) |>
  mutate( across( where(is.numeric), fmt_APA_numbers) ) 
  
mean(tab$df) -> tab_df
tab |> 
  mutate(name = factor(name, levels=c("rt","pe","lisas","BIS_lisas","BIS") ), 
         e1="",e2="",e3="", e4="",
         p.val = fmt_APA_numbers(p.val, .p=T),
         across(contains(c("con", "b")), ~ fmt_APA_numbers(num=.x, .chr=T) )
         ) |>
  arrange(name) |>
  gt() |>
  cols_move(e1, sd_incon) |>
  cols_move(e2, sd_con) |>
  cols_move(e3, p.val) |>
  cols_move(e4, hdi) |>
  tab_spanner("Incongruent", c(m_incon, sd_incon) ) |>
  tab_spanner("Bayesian", c(b.est, b,hdi)) |>
  #tab_spanner("Congruent", C(m_con, sd_con) )
    # why u not wrk? 
  cols_label(m_incon = md("*M*"), sd_incon = md("*SD*"), m_con = md("*M*"), sd_con = md("*SD*"),
             p.val = md("*p*"), b = md("BF~10~"), b.est = md("*M*~est~"), 
             hdi = "HDI", d = md("*d*"), e1="",e2="",e3="", e4="", t.val = md( paste0("*t*(", tab_df,")") ) ) |>
  tab_spanner("Congruent", c(m_con, sd_con) ) |>
  cols_hide( c(df, mdiff)) |>
  cols_align("center" )  -> exp1_table_complex
exp1_table_complex

if(save_outputs){ gtsave(exp1_table_complex, filename = "../outputs/tables/exp1_table_complex.docx") }
```

The paired-sample t-test for the LISAS, revealed a significant difference (*M* = `r tab$mdiff[3]`, t(`r tab$df[3]`) = `r tab$t.val[3]`, `r fmt_APA_numbers(tab$p.val[3], .psym=T)`, BF~10~ = `r tab$b.est[3]`, Cohen's *d* = `r tab$d[3]`) between the incongruent (*M* = `r tab$m_incon[3]`, *SD* = `r tab$sd_incon[3]`) and the congruent (*M* = `r tab$m_con[3]`, *SD* = `r tab$sd_con[3]`) condition. The respective test for the proportion of error revealed a significant difference (*M* = `r tab$mdiff[1]`, t(`r tab$df[1]`) = `r tab$t.val[1]`, `r fmt_APA_numbers(tab$p.val[1], .psym=T)`, BF10 = `r tab$b.est[1]`, Cohen's *d* = `r tab$d[1]`) between the incongruent (*M* = `r tab$m_incon[1]`, *SD* = `r tab$sd_incon[1]`) and the congruent (*M* = `r tab$m_con[1]`, *SD* = `r tab$sd_con[1]`) condition (see Appendix B).

# Feedback

```{r}
#| echo: false
data |> 
  filter(stimulus == "feedback") |> 
  dplyr::select(id, response) |>
  mutate(
    strat = map(response, fromJSON) |> map_chr(1),
    open  = map(response, fromJSON) |> map_chr(2), ) |>
  dplyr::select(-response) |>
  mutate(
    exclu = ifelse(id %in% loss$exclude_par, TRUE,FALSE)
  ) |> 
  dplyr::select(id, exclu, everything()) |>
  gt()
```

# Encoding and congruency

ANCOVA related \## Correlation Grand correlation, encoding
time (ms) and response time (ms) for the inducer task

```{r total table}
#| echo: false
d_ind <- 
  data |> 
  dplyr::filter(!(id %in% loss$exclude_par)) |>
  select(id, trial_info, inducer_run, correct_response, rt) |>
  filter(trial_info == "Inducer trial" | trial_info=="Inducer instructions" ) |>
  filter(inducer_run > 0) |>
  pivot_wider(names_from = trial_info, values_from = c(correct_response, rt)) |> 
  mutate(
    `rt_Inducer instructions` = as.integer( ifelse(`rt_Inducer instructions`=="null", NA, `rt_Inducer instructions`) ),
    `rt_Inducer trial` = as.integer( ifelse(`rt_Inducer trial`=="null", NA, `rt_Inducer trial`) ),
    instructions = ifelse(is.na(`rt_Inducer instructions`), 20000, `rt_Inducer instructions`),
    trial        = ifelse(is.na(`rt_Inducer trial`), 2000, `rt_Inducer trial` ),
     # In this case we can set the values of instruction and trial to their max, 
     # because that is the end of the trial (a non-response does count as a wrong response).
     # None of this is preregistered and should be interpreted carefully. 
   inducer_run  = as.numeric(inducer_run))
d_ind |> 
  summarize(
    name = "Corrected",
    cor = cor(instructions, trial),
    encoding =  mean(instructions),
    encoding_sd =  sd(instructions),
    skew = moments::skewness(instructions),
    trial = mean(trial),
    trial_sd = sd(trial, na.rm = TRUE) ) |>
  rbind(
    d_ind |> 
      filter(!is.na(`rt_Inducer instructions`)) |> 
      filter(!is.na(`rt_Inducer trial`)) |> 
      summarise(
        name = "Removed",
        cor = cor(instructions, trial),
        encoding =  mean(instructions),
        encoding_sd =  sd(instructions),
        skew = moments::skewness(instructions),
        trial = mean(trial),
        trial_sd = sd(trial, na.rm = TRUE) )
  ) |> gt()
```

Positive correlation indicate that more time spent on reading
the instructions increased response times on the diagnostic
trials.

### Figure: RT and Instructions

```{r total plot}
#| fig-dpi: 300
#| echo: false
#| error: false
#| warning: false
#| fig-width: 12

p1 <-
  d_ind |> 
  ggplot(aes(instructions, trial)) +
  geom_point(alpha=.1) +
  geom_smooth(method=lm, col="indianred2", linewidth=1) +
  scale_x_continuous(breaks=seq(0,20000,2000)) +
  scale_y_continuous(breaks=seq(0,2000,250)) +
  labs(y = "Trial Response Time (ms)", x = "Instruction Response Time (ms)")+
  theme(legend.position = "none")+
  coord_cartesian(ylim=c(0,2000))+
  labs(title="Corrected")+
  theme_minimal()

p2 <- 
  d_ind |> 
  filter( !is.na(`rt_Inducer trial`) ) |>
  filter( !is.na(`rt_Inducer instructions`) ) |>
  ggplot(aes(instructions, trial)) +
  geom_point(alpha=.1) +
  geom_smooth(method=lm, col="indianred2", linewidth=1) +
  scale_x_continuous(breaks=seq(0,20000,2000)) +
  scale_y_continuous(breaks=seq(0,2000,250)) +
  labs(y = "Trial Response Time (ms)", x = "Instruction Response Time (ms)")+
  theme(legend.position = "none")+
  coord_cartesian(ylim=c(0,2000))+
  labs(title="Removed")+
  theme_minimal()

p1 
p2
```

### Figure: Shared

Individual correlation, encoding time (ms) and response time
(ms)

```{r within table}
#| echo: false

d |>
  left_join(d_ind |> 
              dplyr::select(id, inducer_run, instructions,trial),
            by= c("id", "inducer_run")) ->
  an_d

an_d |>
  filter( trial_info=="Diagnostic trial" ) |>
  ggplot(aes(instructions, rt, col=con))+
  geom_point(alpha=.1)+
  geom_smooth(method="lm")
```

```{r}
#| echo: false
an_d |> 
  filter(!is.na(con) & trial_info=="Diagnostic trial") |>
  ggplot(aes(instructions, trial, col=con, group=con)) +
  geom_smooth(method=lm, linewidth=1, alpha = .2)+
  geom_point(alpha=.1)+ 
  scale_x_continuous(breaks=seq(0,20000,2000)) +
  scale_y_continuous(breaks=seq(0,2000,250)) +
  labs(y = "Trial Response Time (ms)", x = "Instruction Response Time (ms)")+
  theme(legend.position = "none")+
  coord_cartesian(ylim=c(0,2000))+
  theme_minimal()
```

Here we log transform the response time variable due to
non-normality.

```{r}
#| echo: false
#| message: false
reg_d <- 
  an_d |>
  filter( trial_info=="Diagnostic trial" ) |>
  group_by(id, inducer_run, con) |>
  summarise(rt = mean(rt), instructions = unique(instructions), prop = mean(correct_response)) |>
  mutate( instructions = log(instructions),
          rt = log(rt),)
```

## Impact of Encoding on RT

### rmANOVA:

Controlling for encoding by using an analysis of covariates.

```{r}
#| echo: false
#| message: false

# one-way rmANOVA - for each block
aov(rt ~ con + Error(id), reg_d) -> 
  rmanova

# rmANCOVA - for each block
aov(rt ~ con + instructions + Error(id), reg_d) -> 
  ancova_test1

# rmANCOVA interaction
aov(rt ~ con * instructions + Error(id), reg_d) -> 
  ancova_test2

anova(rmanova$Within, ancova_test1$Within, ancova_test2$Within)
summary(ancova_test1$Within)
```

Note that this is a comparison of ANOVAs, not linear
mixed-models, which might be preferred.

### Linear mixed-model:

We can do a linear mixed model to investigate whether encoding
interacted with congruency. I.e., more time encoding the
instructions lead to stronger congruency effect.

Here we only include a random intercept for each participant:

```{r}
#| echo: false
r_mod1 <-
  reg_d |> 
  lmer(rt ~ con + (1 | id), data = _, REML=F)

r_mod2 <-
  reg_d |>
  lmer(rt ~ con + instructions + (1 | id) , data = _, REML=F)

r_mod3 <-
  reg_d |>
  lmer(rt ~ con * instructions + (1 | id), data = _, REML=F)

anova(r_mod1, r_mod2, r_mod3)
summary(r_mod3)
exp(fixef(r_mod3))
#glht()
```

Results suggest that only the model that include encoding, but
no the interaction, is a significant improvement compared to
the former model.

This suggest that encoding time did not influence the
congruency effect.

#### Random block effect

Is it necessary to include a random effect of block (inducer
run) per subject?

In general, we do not expect block to have a unique effect on
RT, although a general decrease with increasing practice.

We can start by visualizing:

```{r}
#| echo: false
#| message: false
#| warning: false
an_d |> 
  #dplyr::filter(id=="8frhzxqs" & trial_info=="Diagnostic trial" & !is.na(con)) |>
  filter(trial_info=="Diagnostic trial" & !is.na(con)) |>
  ggplot(aes(con, rt, group=interaction(factor(inducer_run), id))) +
  stat_summary(position = position_dodge(.4), alpha =.05)+
  stat_summary(geom="line", position = position_dodge(.4), alpha =.05)+
  stat_summary(aes(group=factor(inducer_run), col = inducer_run), position = position_dodge(.4))+
  stat_summary(aes(group=factor(inducer_run), col = inducer_run), geom="line", position = position_dodge(.4))+
  coord_cartesian(ylim=c(500,900))
```

There does indeed appear to be a general decrease in RT
following block. Including a random intercept would probably
fit the data better.

Include a random intercept for each block for each subject.

```{r}
#| echo: false
r_mod1.1 <- 
  reg_d |> 
  lmer(rt ~ con + (1 | id) + (1 | id:inducer_run), data = _, REML=F)

r_mod2.1 <- 
  reg_d |>
  lmer(rt ~ con + instructions + (1 | id) + (1 | id:inducer_run), data = _, REML=F)

r_mod3.1 <- 
  reg_d |>
  lmer(rt ~ con * instructions + (1 | id) + (1 | id:inducer_run), data = _, REML=F)

anova(r_mod1.1, r_mod2.1, r_mod3.1)
cat("\n --- --- ---  \n include random intercept for each block? \n\n")
anova(r_mod2, r_mod2.1)
```

The model does account for more variance, but does not change
the general pattern.

Generally, we believe that the effect of block stem from
time-on-task / practice, and does not really change the
outcome.

Regardless, non of the selected models include the interaction
between congruency and encoding. This suggest that congruency
does not interact with encoding. This should not be
interpreted as a major finding. Our main investigation did not
encompass the interaction between encoding and congruency, but
is meant as exploratory.

### Vis: Trend in congruency across block

Change in RT over blocks split by congruency.

```{r}
#| echo: false
#| message: false
#| warning: false
an_d |>
  filter(trial_info=="Diagnostic trial" & !is.na(con) & diagnostic_run>=0) |>
  ggplot(aes(inducer_run, rt, col= con))+
  stat_summary(aes(group=interaction(con, id)), position = position_dodge(.4), alpha =.05)+
  stat_summary(aes(group=interaction(con, id)), position = position_dodge(.4), geom="line", alpha=.05)+
  stat_summary()+
  stat_summary(geom="line")
```

In this way, including a random intercept for each block
explains more variance.

## Impact of Encoding on err

### Linear mixed model

```{r}
#| echo: false
# 
# reg_d |> 
#   ggplot(aes(err))+
#   geom_histogram()
# 
# reg_d |> 
#   betareg::betareg(err ~ con | id, data = _)
# p_mod1 <- 
#   reg_d |>
#   glmer(err ~ con + (1 | id), data = _,
#         family = binomial(link="logit"))
# 
# p_mod2 <- 
#   an_d |>
#   filter(trial_info=="Diagnostic trial") |>
#   mutate(instructions = log(instructions),
#          correct_response = factor(correct_response)) |>
#   glmer(correct_response ~ con + instructions + (1|id), data = _,
#         family = binomial(link="logit"))
# 
# anova(p_mod1, p_mod2)
#   # n.s. 
# 
# summary( p_mod1 )
# 
# exp( getME(p_mod1, "fixef")[1:2] )

```

## Instruction appearance & congruency

```{r}

```

--------------------------------------------------------------

~Document generated: `r Sys.time()`~
