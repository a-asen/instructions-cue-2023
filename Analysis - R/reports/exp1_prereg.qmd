---
title: "Experiment 1 - Preregistered"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries }
#| include: FALSE
library(tidyverse)
library(patchwork)
library(gt)
library(BayesFactor)
library(bayestestR)
library(lsr)
source("../lib/helper_functions.R")

save_outputs <- FALSE
```

```{r citation}
#| include: false

library(NCmisc)

citation("tidyverse") 
citation("patchwork")
citation("BayesFactor") 
citation("bayestestR")
citation("gt")
citation("lsr")

```

```{r load data }
#| include: FALSE

list.files("../data/raw/experiment1/task", pattern = "*.csv", full.names = T) -> fnames

map_df(fnames, \(x){
  read_csv(x)
}) -> data

read_csv("../data/raw/experiment1/exp1_demo.csv") -> demo
```

```{r transformation}
#| include: FALSE
# Pre-transformation
data |>
  mutate(rt = as.integer(ifelse( rt == "null", NA, rt ))) -> data
```

# Demographics

```{r}
#| include: false
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    maleS = sum(s==1),
    femaleS = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem
dem$age
```

We recruited `r length(demo$Age)+4`, participants from the
United Kingdom via Prolific. Due to a coding mistake, four
participants did not generate any data. This left us with a
mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$femaleS`
females) from the United Kingdom via Prolific. Note that two
participants were excluded from the data analysis, but cannot
be removed from the demographics due to non-connections
between data points and demographics variables.

# Data

## Data prep

```{r base data }
#| include: false
# Select the relevant columns & rows
# Remove the first inducer_run (i.e., 0th)
d_t <- 
  data |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, congruent) |>
    # note. Congruent has a conding error. Recalculating congruency is done below
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial")
```

```{r recalculating the congruency effect}
#| include: false

#' Due to a typo in the task script, the congruency output would (for some participants)
#' be the opposite. 

raw_d <- 
  data |> 
  dplyr::select(id, trial_info, diagnostic_run, italic, inducer_run, stimulus, congruent, correct_diag_response_side, response, correct_response,rt) |>
  filter(trial_info=="Diagnostic trial" | trial_info=="Inducer instructions" | trial_info =="Diagnostic instructions") |>
  mutate(inducer_run = as.numeric(inducer_run),
         italic = ifelse(italic=="true", TRUE, FALSE)) |>
  fill(inducer_run, .direction = "up") |>
  group_by(id) |>
  mutate( 
    diag_ins = stimulus[trial_info=="Diagnostic instructions"],
    if_italic = str_split(diag_ins, " ") |> map_chr(4) ) |> 
  ungroup() |>
  group_by(id, inducer_run) |> 
  # reframe(ins = stimulus[trial_info=="Inducer instructions"] ) 
  mutate(
    response_side = ifelse(response=="j", "RIGHT", "LEFT"),
    #
    indu_ins = stimulus[trial_info=="Inducer instructions"], 
    ins_left = str_split(indu_ins, " | ") |> map_chr(2),
    ins_right = str_split(indu_ins, " | ") |> map_chr(7),
    ins_resp = str_split(indu_ins, " | ") |> map_chr(4),
    #
    inducer_tap  = ifelse(stimulus==ins_left, ins_resp, ifelse(ins_resp=="LEFT", "RIGHT", "LEFT")),
    diag_tap     = ifelse(italic, if_italic, ifelse(if_italic=="LEFT", "RIGHT","LEFT") ) ) |>
  filter(trial_info=="Diagnostic trial") |> 
  ungroup() |>
  mutate(con = ifelse(inducer_tap==diag_tap, T,F)) |>
  dplyr::select(id, inducer_run, diagnostic_run, con)

d <- 
  d_t |> 
  mutate(inducer_run = as.numeric(inducer_run)) |>
  left_join(raw_d, by=c("id","inducer_run", "diagnostic_run"))
```

## Exclusion

```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$raw_data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  nrow()

### participants excluding - accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

# Count
loss$exclude_par_trials <- d |> 
  filter(id %in% loss$exclude_par) |>
  filter(diagnostic_run >= 0) |>
  nrow()

# REMOVE excluded: 
d <- d |> 
  filter(!(id %in% loss$exclude_par))

loss$data_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |> 
  nrow()

loss$inducer_practice_trials <- 
  d |> 
  filter(diagnostic_run >= 0) |>
  filter(inducer_run == 0) |>
  nrow()

loss$inducer_practice_prop <- 
  loss$inducer_practice_trials / loss$data_trials * 100

# REMOVE practice round
d <- d |> 
  filter(inducer_run > 0)
```

The first inducer block was considered practice and excluded,
representing `r loss[["inducer_practice_prop"]]` percent of
the data.

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (\> 30% error).

```{r due to high SD & NA responses }
#| include: FALSE

# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d <- d |>
  left_join(
    by = c("id","inducer_run","diagnostic_run"),
    d |>
      filter(trial_info == "Diagnostic trial") |>
      mutate(
        .by = id,
        rt_crit_low   = mean(rt, na.rm=T) - sd(rt, na.rm=T) * 2.5,
        rt_crit_high  = mean(rt, na.rm=T) + sd(rt, na.rm=T) * 2.5,
        rt_crit = ifelse( ( (rt >= rt_crit_high) | (rt <= rt_crit_low) ), 1, NA ),
        rt_na = ifelse(is.na(rt), 1, NA)
      ) |>
      select(id,inducer_run, diagnostic_run, rt_crit, rt_na)
  )

# IMPORTANT NOTE: 
  #' Removing null RT responses are, in all theory, not preregistered. 
  #' While there is a solution to "non-responses" for error (count them as wrong), 
  #' there is no stated solution to response time. Generally, this leads to problems 
  #' because a trial can be considered wrong under error conditions, while the accompanied 
  #' "error" for response time is not obvious. Should the RT be 2000ms (max trial length)? 
  #' Or should it be closer to infinity? 
  #' 
  #' Assuming a max trial length of 2000ms would highly likely yield exclusion based on 
  #' the max rt * 2.5 SD (but that is not a given). 
  #' 
  #' It is not obvious what to do in such a case, and the simplest solution will 
  #' be to exclude (remove) these trials). Even though this may be assumed from
  #' the preregistration, it is *not* preregistered.


# lost trials
loss$rt_sd_trials <- d |>
  filter(diagnostic_run >= 0) |>
  filter(rt_crit == 1 | rt_na==1) |>
  nrow()

loss$rt_sd_prop <- 
  loss$rt_sd_trials / loss$data_trials * 100

# Exclude
d <- d |>
  filter( is.na(rt_crit) & is.na(rt_na) ) |>
  select(-rt_crit, -rt_na)
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.

```{r only correct inducers}
#| include: FALSE
d <- d |>
  mutate( valid_trials = case_when( 
    trial_info=="Inducer trial" & correct_response==1 ~ 1,
    trial_info=="Inducer trial" & correct_response==0 ~ 0,
    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
    # non-responses count as a wrong response
    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up")

loss$inducer_fail_trials <- d |>
  filter(diagnostic_run >= 0) |>
  filter(valid_trials == 0) |>
  nrow()

loss$inducer_fail_prop <-
  loss$inducer_fail_trials / loss$data_trials * 100


loss$total_lost_trials <- loss$inducer_practice_trials + loss$rt_sd_trials + loss$inducer_fail_trials
loss$total_lost_prop <- loss$inducer_practice_prop + loss$rt_sd_prop + loss$inducer_fail_prop

d <-
  d |>
  filter( valid_trials == 1 ) |>
  select(-valid_trials)
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials`
trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)`
percent of the data.

### Paragraph:

The exclusion criteria resulted in the removal of
`r fmt_APA_numbers(loss$total_lost_prop)` %
(`r loss$total_lost_trials` trials) of the data. The first
round was considered practice and resulted in the loss of
`r fmt_APA_numbers(loss$inducer_practice_prop)` %
(`r loss$inducer_practice_trials` trials), while highly
deviating response times and non-responses accounted for
`r fmt_APA_numbers(loss$rt_sd_prop)` % (`r loss$rt_sd_trials`
trials), and a wrong response on the inducer trial resulted in
a loss of `r fmt_APA_numbers(loss$inducer_fail_prop)` %
(`r loss$inducer_fail_trials` trials).

## Summary

```{r}
#| include: FALSE
# data summary
d |> 
  filter( trial_info=="Diagnostic trial" ) |>
  summarize(
    .by = c(id, con),
    rt = mean(rt),
    pe = 1 - mean(correct_response) ) |>
  # mutate(rt = scale(rt), pe = scale(pe)) |>
    #' na.rm is not necessary, because problems related to missing trials 
    #' should be handled by the above criteria.
  pivot_wider( names_from = con, values_from = c(rt, pe) ) |>
  ungroup() -> d2
```

### Table

```{r RT tables}
#| echo: false

# Freq:
## response times
rt_test      <- t.test(  d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, alternative = "greater")
rt_test_b    <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, iterations = 10000, posterior = F )
rt_test_b2   <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, iterations = 10000, posterior = T )
rt_test_hdi  <- hdi(rt_test_b2)
  # weird if this is how you have to do it

d2 |>
  summarise(
    name            = "RT",
    m_incongruent   = fmt_APA_numbers( mean(rt_FALSE) ),
                      # fmt here, b/c fmt_numbers() [gt func] is to general
    sd_incongruent  = fmt_APA_numbers( sd(rt_FALSE) ), 
    m_congruent     = fmt_APA_numbers( mean(rt_TRUE) ) ,
    sd_congruent    = fmt_APA_numbers( sd(rt_TRUE) ),
    Mdiff           = fmt_APA_numbers( mean(rt_FALSE - rt_TRUE) ),
    t               = fmt_APA_numbers( rt_test$statistic ),
    df              = rt_test$parameter,
    p               = rt_test$p.value,
    ps              = set_p_star(p),
    Mdiff           = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est           = fmt_APA_numbers( mean(rt_test_b2[,"mu"]) ),
    hdi             = paste0("[", fmt_APA_numbers(rt_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(rt_test_hdi$CI_high[1]),"]"),
    bf              = fmt_APA_numbers( extractBF(rt_test_b)$bf ),
    d               = fmt_APA_numbers( cohensD( rt_FALSE, rt_TRUE, method = "paired" ) ),
    )  -> d_rt

## proportion correct trials
pe_test      <- t.test(  d2$pe_FALSE, d2$pe_TRUE, paired = TRUE, alternative = "greater" )
pe_test_b    <- ttestBF( d2$pe_FALSE, d2$pe_TRUE, paired = T, iterations = 10000, posterior = F )
pe_test_b2   <- ttestBF( d2$pe_FALSE, d2$pe_TRUE, paired = T, iterations = 10000, posterior = T )
pe_test_hdi  <- hdi(pe_test_b2)
  # weird if this is how you have to do it

d2 |>
  summarise(
    name             = "PE",
    m_incongruent    = fmt_APA_numbers( mean(pe_FALSE) ),
    sd_incongruent   = fmt_APA_numbers( sd(pe_FALSE) ),
    m_congruent      = fmt_APA_numbers( mean(pe_TRUE) ),
    sd_congruent     = fmt_APA_numbers( sd(pe_TRUE) ),
    Mdiff            = fmt_APA_numbers( mean(pe_FALSE - pe_TRUE) ),
    t                = fmt_APA_numbers( pe_test$statistic ),
    df               = pe_test$parameter,
    p                = pe_test$p.value,
    ps               = set_p_star(p),
    Mdiff            = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est            = fmt_APA_numbers( mean(pe_test_b2[,"mu"]) ),
    hdi              = paste0("[",fmt_APA_numbers(pe_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(pe_test_hdi$CI_high[1]),"]"),
    bf               = fmt_APA_numbers( extractBF(pe_test_b)$bf ),
    d                = fmt_APA_numbers( cohensD(pe_FALSE, pe_TRUE, method = "paired") ),
  ) -> d_pe

```

**Table XX** \n*Test Statistic for Response Time and Error
Rate\*

```{r stat table}
#| echo: false
rbind(d_rt, d_pe) -> b
b |> summarize( m = mean(df) ) |> pull() -> d2_df
b |> pull(p) |> min() -> p_min

if(d2_df != floor(d2_df)){ warning("NOT SIMILAR, CHECK DF") }
  # degrees of freedom

mean(b$df) -> b_df_m
exp1_table_simple <- 
  b |>
  # add bayes row? 
  mutate(em1 = "", em2="", em3="", 
         p = fmt_APA_numbers(p, .p=T),
         across(contains(c("con","b")), ~ fmt_APA_numbers(.x, .chr=T) )  ) |>
  gt() |>
  cols_hide(    c(df, ps, Mdiff) ) |>
  tab_spanner(  "Incongruent", c(m_incongruent, sd_incongruent) ) |>
  cols_label(   m_incongruent = md("*M*"), sd_incongruent = md("*SD*" ) ) |>
  tab_spanner(  "Congruent", c(m_congruent, sd_congruent) ) |>
  cols_label(   m_congruent = md("*M*"),  sd_congruent = md("*SD*") ) |>
  tab_spanner(  "Bayes", c(b.est, bf, hdi)) |>
  cols_label(   b.est = md("*M*~est~"), bf = md("BF~10~"), hdi = "HDI", ) |> 
  #fmt_markdown() |>
  #cols_move(    "ps", Mdiff ) |> 
  cols_move(    "em1", sd_incongruent ) |>
  cols_move(    "em2", ps ) |>
  cols_label(   em1 = "", em2 = "", name = "", d = md("Cohen's *d*"), em3 = "", 
                t = md( paste0("*t*(",b_df_m,")")), p = md("*p*") ) |>
  cols_align(   "center", c(2:15)) |> 
  cols_move(    "em3", hdi) 
exp1_table_simple

if(save_outputs){ gtsave(exp1_table_simple, filename = "../outputs/tables/exp1_table_simple.docx") }
```

*Note.* </br>
`r fmt_APA_p_table_fig(p_min)`

#### Paragraph

The paired-sample t-test for response time, revealed a
significant difference (*M* = `r b$Mdiff[b$name=="RT"]`, *t*(`r b$df[b$name=="RT"]`)
= `r b$t[b$name=="RT"]`, *p* `r fmt_APA_numbers(b$p[b$name=="RT"], .psym=T)`, BF~10~ =
`r b$bf[b$name=="RT"]`, Cohen's *d* = `r b$d[b$name=="RT"]`) between the
incongruent (*M* = `r b$m_incongruent[b$name=="RT"]`, *SD* =
`r b$sd_incongruent[b$name=="RT"]`) and the congruent (*M* =
`r b$m_congruent[b$name=="RT"]`, *SD* = `r b$sd_congruent[b$name=="RT"]`) condition.
The respective test for the proportion of error revealed a
significant difference (*M* = `r b$Mdiff[b$name=="PE"]`, *t*(`r b$df[b$name=="PE"]`)
= `r b$t[b$name=="PE"]`, *p* `r fmt_APA_numbers(b$p[b$name=="PE"], .psym=T)`, BF~10~ =
`r b$bf[b$name=="PE"]`, Cohen's *d* = `r b$d[b$name=="PE"]`) between the
incongruent (*M* = `r b$m_incongruent[b$name=="PE"]`, *SD* =
`r b$sd_incongruent[b$name=="PE"]`) and the congruent (*M* =
`r b$m_congruent[b$name=="PE"]`, *SD* = `r b$sd_congruent[b$name=="PE"]`) condition
(see Appendix B).

### Figures

#### Linerange

```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 3

# This way of visualizing is not necessarily the best -- it can illustate each
# change in data (congruent/incongruent), but summary score should not be used with it

p1 <- 
  d |>
  filter(!is.na(con)) |>
  summarize(.by = c(id, con), 
            rt = mean(rt), 
            pe = 1 - mean(correct_response)) |>
    # Summarize the proportion of correct per block
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = rt, group=id, col = factor(con2)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(500, 850))+
                        # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")


p2 <-
  d |>
  filter(!is.na(con)) |>
  summarize(
    .by = c(id, con), 
    rt = mean(rt), 
    pe = 1 - mean(correct_response)) |>
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                      # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error") 

p1 
p2

if(save_outputs){ ggsave("../outputs/figs/exp1_rt-pe_line.jpeg", p1+p2, width=8, height=5) }
```

#### Bar plot

```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 3

p1 <- d |>
  filter(!is.na(con)) |>
  summarize(.by = c(id, con), 
            rt = mean(rt), 
            pe = 1 - mean(correct_response)) |>
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = rt,fill = factor(con)))+
  stat_summary(fun = mean, geom = "col")+
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .4, size = 1, alpha = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,25), minor_breaks = NULL)+
  coord_cartesian(ylim = c(600, 750))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")+
  annotate("segment", x=-0.1, xend=1.1, y=696, yend=696, size=1)+
  annotate(geom = "text", x = .5, y=700, label="**", size=5)

p2 <- d |>
  filter(!is.na(con)) |>
  summarize(.by = c(id, con), 
            rt = mean(rt), 
            pe = 1 - mean(correct_response)) |>
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, fill = factor(con2)))+
  stat_summary(fun=mean, geom="col")+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.4, size = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error")+
  annotate("segment", x=-0.1, xend=1.1, y=.13, yend=.13, size=1)+
  annotate(geom = "text", x = .5, y=.137, label="**", size=5)
    
p1
p2
if(save_outputs){ ggsave("../outputs/figs/exp1_rt-pe_bar.jpeg", p1+p2, width=8, height=5) }
```

--------------------------------------------------------------

~Document generated: `r Sys.time()`~
