---
title: "Experiment 1 - Preregistered"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries }
#| include: FALSE
library(tidyverse)
library(patchwork)
library(gt)
library(BayesFactor)
library(bayestestR)
library(lsr)
source("../lib/helper_functions.R")

save_outputs <- FALSE
```

```{r citation}
#| include: false

library(NCmisc)

citation("tidyverse")
citation("patchwork")
citation("gt")
citation("BayesFactor")
citation("bayestestR")
citation("lsr")

citation("dplyr")
citation("ggplot2")
```


```{r load data }
#| include: FALSE

list.files("../data/raw/experiment1/task", pattern = "*.csv", full.names = T) -> fnames

map_df(fnames, \(x){
  read_csv(x)
}) -> data

read_csv("../data/raw/experiment1/exp1_demo.csv") -> demo
```

```{r transformation}
#| include: FALSE
# Pre-transformation
data |>
  mutate(rt = as.integer(ifelse( rt == "null", NA, rt ))) -> data
```

# Demographics
```{r}
#| include: false
demo |> 
  mutate(s = ifelse(Sex=="Male", 1,0)) |> 
  summarize(
    n = length(Age),
    age = mean(Age),
    age_sd = sd(Age),
    maleS = sum(s==1),
    femaleS = sum(s==0),
    sex = mean(s),
    sex_s = sd(s)
  ) |> round(2) -> dem
dem$age
```

We recruited `r length(demo$Age)+4`, participants from the United Kingdom via Prolific. Due to a coding mistake, four participants did not generate any data. This left us with a mean age of `r dem$age` (SD = `r dem$age_sd`; `r dem$femaleS` females) from the United Kingdom via Prolific. Note that two participants were excluded from the data analysis, but cannot be removed from the demographics due to non-connections between data points and demographics variables. 



# Data 
```{r base data }
#| include: false
# Select the relevant columns & rows
# Remove the first inducer_run (i.e., 0th)
d <- 
  data |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, congruent) |>
    # note. Congruent has a conding error. Recalculating congruency is done below
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial")
```


```{r recalculating the congruency effect}
#| include: false

#' Due to a typo in the task script, the congruency output would (for some participants)
#' be the opposite. 

raw_d <- 
  data |> 
  dplyr::select(id, trial_info, diagnostic_run, italic, inducer_run, stimulus, congruent, correct_diag_response_side, response, correct_response,rt) |>
  filter(trial_info=="Diagnostic trial" | trial_info=="Inducer instructions" | trial_info =="Diagnostic instructions") |>
  mutate(inducer_run = as.numeric(inducer_run),
         italic = ifelse(italic=="true", TRUE, FALSE)) |>
  fill(inducer_run, .direction = "up") |>
  group_by(id) |>
  mutate( 
    diag_ins = stimulus[trial_info=="Diagnostic instructions"],
    if_italic = str_split(diag_ins, " ") |> map_chr(4) ) |> 
  ungroup() |>
  group_by(id, inducer_run) |> 
  # reframe(ins = stimulus[trial_info=="Inducer instructions"] ) 
  mutate(
    response_side = ifelse(response=="j", "RIGHT", "LEFT"),
    #
    indu_ins = stimulus[trial_info=="Inducer instructions"], 
    ins_left = str_split(indu_ins, " | ") |> map_chr(2),
    ins_right = str_split(indu_ins, " | ") |> map_chr(7),
    ins_resp = str_split(indu_ins, " | ") |> map_chr(4),
    #
    inducer_tap  = ifelse(stimulus==ins_left, ins_resp, ifelse(ins_resp=="LEFT", "RIGHT", "LEFT")),
    diag_tap     = ifelse(italic, if_italic, ifelse(if_italic=="LEFT", "RIGHT","LEFT") ) ) |>
  filter(trial_info=="Diagnostic trial") |> 
  ungroup() |>
  mutate(con = ifelse(inducer_tap==diag_tap, T,F)) |>
  dplyr::select(id, inducer_run, diagnostic_run, con)


d <- 
  d |> 
  mutate(inducer_run = as.numeric(inducer_run)) |>
  left_join(raw_d, by=c("id","inducer_run", "diagnostic_run"))
```

## Exclusion
```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$data_trials <- nrow(d)

loss[["inducer_practice_prop"]] <- (1 - (nrow(d |> filter(inducer_run > 0)) / nrow(d))) * 100
loss[["inducer_practice_trials"]] <- nrow(d) - nrow(d |> filter(inducer_run > 0))

d <- 
  d |> 
  filter(inducer_run > 0)

### Overall accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = 1 - mean(correct_response, na.rm = TRUE) ) |>
  filter( acc > .3 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( d$rt[d$id == loss$exclude_par] )
loss[["exclude_par_prop"]]    <- length( d$rt[d$id == loss$exclude_par] ) / loss$data_trials * 100

d |> filter( !(id %in% loss$exclude_par) ) -> d
```

The first inducer block was considered practice and excluded, representing `r loss[["inducer_practice_prop"]]` percent of the data. 

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (> 30% error). 

<!-- Does not result in any loss of data, since they are replaced --> 

```{r due to high SD & NA responses }
#| include: FALSE

# Removing trials deviating more than 2.5 SD from each participants mean. 
# Also remove NA responses
d |>
  group_by(id) |>
  mutate(
    # Calculate: rt + SD * 2.5
    rt_crit = ifelse( 
      trial_info == "Diagnostic trial",
      mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5,
      NA ),
      # Trials to retain/remove: 
      retain_trials = ifelse(
        # Remove trials deviating **more** than 2.5 SD
        (rt > rt_crit & trial_info == "Diagnostic trial") | # **OR**
          # Remove slow (i.e., NA) responses
          (is.na(rt) & trial_info == "Diagnostic trial"),
        # !! Supposed to be *not* missing !! 
        0, 1 ) 
    ) -> d

# IMPORTANT NOTE: 
  #' Removing null RT responses are, in all theory, not preregistered. 
  #' While there is a solution to "non-responses" for error (count them as wrong), 
  #' there is no stated solution to response time. Generally, this leads to problems 
  #' because a trial can be considered wrong under error conditions, while the accompanied 
  #' "error" for response time is not obvious. Should the RT be 2000ms (max trial length)? 
  #' Or should it be closer to infinity? 
  #' 
  #' Assuming a max trial length of 2000ms would highly likely yield exclusion based on 
  #' the max rt * 2.5 SD (but that is not a given). 
  #' 
  #' It is not obvious what to do in such a case, and the simplest solution will 
  #' be to exclude (remove) these trials). Even though this may be assumed from
  #' the preregistration, it is *not* preregistered.

sum(d$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_prop"]]

d |> 
  filter( retain_trials == 1 ) -> d
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_prop"]], 2)`
percent of the data.


```{r only correct inducers}
#| include: FALSE
d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d

sum(d$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_prop"]]

d |> filter( valid_trials == 1 ) -> d
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_prop"]], 2)` percent of the data.

A total of
`r loss$rt_sd_trials + loss$inducer_fail_trials + loss$inducer_practice_trials` trials were lost. Representing a loss of
`r round(loss$rt_sd_prop + loss$inducer_fail_prop + loss$inducer_practice_prop, 2)` percent of the data.

## Summary

```{r}
#| include: FALSE
# data summary
d |> 
  ungroup() |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id, con) |>
  summarize(rt = mean(rt),
            pe = 1 - mean(correct_response)) |>
  ungroup() |>
    #' na.rm is not necessary, because problems related to missing trials 
    #' should be handled by the above criteria.
  pivot_wider( names_from = con, values_from = c(rt, pe) ) |>
  ungroup() -> d2
```

### Table
```{r RT tables}
#| echo: false

# Freq:
## response times
rt_test      <- t.test(  d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, alternative = "greater" )
rt_test_b    <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, iterations = 10000, posterior = F )
rt_test_b2   <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, iterations = 10000, posterior = T )
rt_test_hdi  <- hdi(rt_test_b2)
  # weird if this is how you have to do it

d2 |>
  summarise(
    name            = "RT",
    m_incongruent   = fmt_APA_numbers( mean(rt_FALSE) ),
                      # fmt here, b/c fmt_numbers() [gt func] is to general
    sd_incongruent  = fmt_APA_numbers( sd(rt_FALSE) ), 
    m_congruent     = fmt_APA_numbers( mean(rt_TRUE) ) ,
    sd_congruent    = fmt_APA_numbers( sd(rt_TRUE) ),
    Mdiff           = fmt_APA_numbers( mean(rt_FALSE - rt_TRUE) ),
    t               = fmt_APA_numbers( rt_test$statistic ),
    df              = rt_test$parameter,
    p               = rt_test$p.value,
    ps              = set_p_star(p),
    Mdiff           = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est           = fmt_APA_numbers( mean(rt_test_b2[,"mu"]) ),
    hdi             = paste0("[", fmt_APA_numbers(rt_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(rt_test_hdi$CI_high[1]),"]"),
    bf              = fmt_APA_numbers( extractBF(rt_test_b)$bf ),
    d               = fmt_APA_numbers( cohensD( rt_FALSE, rt_TRUE, method = "paired" ) ),
    )  -> d_rt

## proportion correct trials
pe_test      <- t.test(  d2$pe_FALSE, d2$pe_TRUE, paired = TRUE, alternative = "greater" )
pe_test_b    <- ttestBF( d2$pe_FALSE, d2$pe_TRUE, paired = T, iterations = 10000, posterior = F )
pe_test_b2   <- ttestBF( d2$pe_FALSE, d2$pe_TRUE, paired = T, iterations = 10000, posterior = T )
pe_test_hdi  <- hdi(pe_test_b2)
  # weird if this is how you have to do it

d2 |>
  summarise(
    name             = "PE",
    m_incongruent    = fmt_APA_numbers( mean(pe_FALSE) ),
    sd_incongruent   = fmt_APA_numbers( sd(pe_FALSE) ),
    m_congruent      = fmt_APA_numbers( mean(pe_TRUE) ),
    sd_congruent     = fmt_APA_numbers( sd(pe_TRUE) ),
    Mdiff            = fmt_APA_numbers( mean(pe_FALSE - pe_TRUE) ),
    t                = fmt_APA_numbers( pe_test$statistic ),
    df               = pe_test$parameter,
    p                = pe_test$p.value,
    ps               = set_p_star(p),
    Mdiff            = paste0( fmt_APA_numbers(Mdiff), ps ),
    b.est            = fmt_APA_numbers( mean(pe_test_b2[,"mu"]) ),
    hdi              = paste0("[",fmt_APA_numbers(pe_test_hdi$CI_low[1]),", ", 
                                  fmt_APA_numbers(pe_test_hdi$CI_high[1]),"]"),
    bf               = fmt_APA_numbers( extractBF(pe_test_b)$bf ),
    d                = fmt_APA_numbers( cohensD(pe_FALSE, pe_TRUE, method = "paired") ),
  ) -> d_pe

```


Table XX \n
*Test statistics for the experimental conditions*
```{r stat table}
#| echo: false
rbind(d_rt, d_pe) -> b
b |> summarize( m = mean(df) ) |> pull() -> d2_df
b |> pull(p) |> min() -> p_min

if(d2_df != floor(d2_df)){ warning("NOT SIMILAR, CHECK DF") }
  # degrees of freedom

mean(b$df) -> b_df_m
exp1_table_simple <- 
  b |>
  # add bayes row? 
  mutate(em1 = "", em2="", em3="", 
         p = fmt_APA_numbers(p, .p=T),
         across(contains(c("con","b")), ~ fmt_APA_numbers(.x, .chr=T) )  ) |>
  gt() |>
  cols_hide(    c(df, ps, Mdiff) ) |>
  tab_spanner(  "Incongruent", c(m_incongruent, sd_incongruent) ) |>
  cols_label(   m_incongruent = md("*M*"), sd_incongruent = md("*SD*" ) ) |>
  tab_spanner(  "Congruent", c(m_congruent, sd_congruent) ) |>
  cols_label(   m_congruent = md("*M*"),  sd_congruent = md("*SD*") ) |>
  tab_spanner(  "Bayes", c(b.est, bf, hdi)) |>
  cols_label(   b.est = md("*M*~est~"), bf = md("BF~10~"), hdi = "HDI", ) |> 
  #fmt_markdown() |>
  #cols_move(    "ps", Mdiff ) |> 
  cols_move(    "em1", sd_incongruent ) |>
  cols_move(    "em2", ps ) |>
  cols_label(   em1 = "", em2 = "", name = "", d = md("Cohen's *d*"), em3 = "", 
                t = md( paste0("*t*(",b_df_m,")")), p = md("*p*") ) |>
  cols_align(   "center", c(2:15)) |> 
  cols_move(    "em3", hdi) 
exp1_table_simple

if(save_outputs){ gtsave(exp1_table_simple, filename = "../outputs/tables/exp1_table_simple.docx") }
```
*Note.* <br/>
`r fmt_APA_p_table_fig(p_min)` <br/>


### Figures
#### Linerange
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

# This way of visualizing is not necessarily the best -- it can illustate each
# change in data (congruent/incongruent), but summary score should not be used with it

p1 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con2, y = rt, group=id, col = factor(con2)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(500, 850))+
                        # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")


p2 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(pe = 1 - mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .1)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .1)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .8)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                      # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error") 

p1+p2

if(save_outputs){ ggsave("../outputs/figs/exp1_rt-pe_line.jpeg", p1+p2, width=8, height=5) }
```


#### Bar plot
```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 300
#| fig-width: 6

p1 <-
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = rt,fill = factor(con)))+
  stat_summary(fun = mean, geom = "col")+
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .4, size = 1, alpha = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,25), minor_breaks = NULL)+
  coord_cartesian(ylim = c(600, 750))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Response Time (ms)")+
  annotate("segment", x=-0.1, xend=1.1, y=696, yend=696, size=1)+
  annotate(geom = "text", x = .5, y=700, label="**", size=5)

p2 <- 
  d |>
  filter(!is.na(con)) |>
  group_by(id, con) |>
    # ????????????????  inducer_run
  summarize(pe = 1 - mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con2 = ifelse(con==T,1,0)) |>
  ggplot(aes(x = con2, y = pe, fill = factor(con2)))+
  stat_summary(fun=mean, geom="col")+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.4, size = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(0, .3))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(x = "", y = "Proportion of Error")+
  annotate("segment", x=-0.1, xend=1.1, y=.13, yend=.13, size=1)+
  annotate(geom = "text", x = .5, y=.137, label="**", size=5)
    
p1+p2

if(save_outputs){ ggsave("../outputs/figs/exp1_rt-pe_bar.jpeg", p1+p2, width=8, height=5) }
```



