---
title: "exp2_design_simulation"
format: html
lang: en-GB
editor: 
  markdown:
    wrap: 62
---

```{r}
#| echo: false
save_animations <- FALSE
run_simulations <- FALSE
load_big_data <- TRUE
```


```{r}
#| include: false
library(tidyverse)
library(lsr)
library(pbapply)
library(afex)
library(gt)
library(parallel)
library(gifski)
library(av)
library(gganimate)

```

```{r}
#| include: false
load("../data/processed/exp1_data.rdata")
load("../data/simulations/exp2_estimate_effect_500.rdata")
load("../data/simulations/exp2_gpower_effect_500.rdata")

load("../data/simulations/exp2_simulation_over_effect_sizes_and_sample_sizes.rdata")
```


## Exclusion
```{r exclusion start - accuracy}
#| include: FALSE

d <-
  exp1_d |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, con) |>
  mutate(rt = as.numeric( ifelse(rt=="null", NA, rt)) ) |>
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial") |>
  filter(!is.na(correct_response))

loss <- list()
loss$data_trials <- nrow(d)

# Remove practice
loss[["inducer_practice_pct"]] <- (1 - (nrow(d |> filter(inducer_run > 0)) / nrow(d))) * 100
loss[["inducer_practice_trials"]] <- nrow(d) - nrow(d |> filter(inducer_run > 0))

d <- 
  d |> 
  filter(inducer_run > 0)

### Overall accuracy      ====
exp1_d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
  summarize( acc = sum(correct_response, na.rm = TRUE) / length( !is.na(correct_response) ) ) |>
  filter( acc < .7 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( d$rt[d$id == loss$exclude_par] )
loss[["exclude_par_pct"]]    <- length( d$rt[d$id == loss$exclude_par] ) / loss$data_trials * 100

d |> filter( !(id %in% loss$exclude_par) ) -> d
#id
d |>
  group_by(id) |>
  mutate(
    rt_crit = ifelse( 
      trial_info == "Diagnostic trial",
      mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5,
      NA ),
      retain_trials = ifelse(
        (rt > rt_crit & trial_info == "Diagnostic trial") | # **OR**
          (is.na(rt) & trial_info == "Diagnostic trial"),
        0, 1 ) 
    ) -> d

sum(d$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_pct"]]

d |> 
  filter( retain_trials == 1 ) -> d
d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d

sum(d$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_pct"]]

d |> filter( valid_trials == 1 ) -> d
```


# Estimating effect size for ANOVA: 
```{r}
#| echo: false
#| message: false
d |>
  filter(!is.na(con)) |>
  group_by(id, con) |> 
  summarise(rt = mean(rt)) |>
  aov(rt ~ con + Error(id/con), data=_ ) |>
  DescTools::EtaSq(x=_, type=1)
```
Partial eta square of .21 (Lakens, 2013)

According to gpower, an effect size of .14 correspond to an effect size of .4:
```{r}
con_eff <- .21
gpow_eff <- .14
```


# Simulation 2x2 rmANOVA (Congruency X cue)

We can simulate the tests for the experiment by adding an additional factor (cue).
We have two main effects, congruency and cue, including an interaction congruency*cue.
We hypothesize an interaction between the cue and the congruency, while the main effect of congruency will remain weak if existent. 
We do not hypothesize an effect of the cue, but we expect it to interact with the congruency. 
In this way, we expect a congruency effect ONLY for trials AFTER the cue.

In the function below we can generate the experimental setup: 
```{r}
exp2_sim2x2 <- function(N, blocks, block.len, post.cue.len, eff.con.pre, eff.con.post, eff.con.cue.intr){
  #' @param N                 Number of subjects
  #' @param blocks            Number of blocks 
  #' @param block.len         Length of each block -- this is split, half the trials are pre and half are post
  #' @param post.cue.len      N of observation after the cue. 
  #' @param eff.con.pre       Effect size of the congruency effect
  #' @param eff.cue.post      Effect size of the pre-post cue
  #' @param eff.con.cue.intr  Effect size of the interaction

  tibble(
    id     = rep(1:N, each = blocks * block.len),
    block  = rep.int( rep(1:blocks, each = block.len), N),
    cue    = rep.int( rep(c("pre", "post"), each = block.len/2), blocks * N),
    con    = rep.int( c("con", "incon"), N * blocks * block.len/2),
    rt     = rnorm(N * blocks * block.len, 
                   0 + 
                     - as.integer(con=="con") * eff.con.pre + 
                     + as.integer(cue=="post") * eff.con.post + 
                     - as.integer(con=="con" & cue=="post") * eff.con.cue.intr,
                   1)
  ) -> d
  
  # Here we remove some post trials equal to half 
  # First we take all the pre trials: 
  d |> 
    filter(cue=="pre") |>
  # Then we combine the filtered post trials: 
  rbind(
    d |> 
      # We filter in such a way that we slice the first trials for each id in each trial:
      filter(cue=="post") |>
      group_by(id, block) |>
      slice_head(n = post.cue.len)
  ) |> view()
}
```

### Effect based on estimate
Here we assume the effect as calculated by the one-way ANOVA (.21 post-cue , and .07 pre-cue)

```{r simulate experiment 2}
#| echo: false

if(create_animations){
  
}
# Generalized eta squared (effect sizes)
effect_size_range <- seq(0.04,0.70, 0.02)
# detectCores()
proportion_of_cores <- .95 

# Create a "cluster" to simulate faster
# Take half the computers cores 
makeCluster( floor(detectCores() * proportion_of_cores) ) -> cl
# Export the local function
clusterExport(cl, varlist = c("exp2_sim2x2", "effect_size_range"))
# Initiate libraries in clusters
clusterEvalQ(cl, {
  library(tidyverse)
  library(pbapply)
  library(afex)
})

# Apply function across "cl"
map_df(10:100, \(sample_size){
  # For each sample size....
  
  pblapply(effect_size_range,\(effect_size){
    # Test all effect sizes... 
    
    map(c(3, 4, 5), \(post_prop){ 
      # Across various post-cue proportions....
      
      map_df(1:300, \(itr_v){
        # And repeat each 300 times ....
          
        d <- 
          exp2_sim2x2(sample_size, 24, 20, .5, effect_size/3, .008, effect_size)
        
        res <-
          d |> 
          aov_car(rt ~ con*cue + Error(id/(con*cue)), data = _, fun_aggregate=mean)
        
        tibble(
          eff     = effect_size,
          size    = sample_size,
          post_prop = post_prop,
          itr     = itr_v,
          name    = c(names(res$Anova$SSP[2]),names(res$Anova$SSP[3]), names(res$Anova$SSP[4])),
          ges     = res[["anova_table"]][["ges"]],
          p       = res[["anova_table"]][["Pr(>F)"]],
        ) |> pivot_wider(names_from = name, values_from = c(ges, p))
        
      })
      
    })
    
  }, cl = cl) |> map_df(~.x)
  
})  -> exp2_simu_raw_with_postprop

#save(exp2_simu_raw_with_postprop, file="../data/simulations/exp2_simulation_over_effect_sizes_and_sample_sizes.rdata")

#save(exp2_simu_raw, file="../data/simulations/exp2_simulation_over_effect_sizes_and_sample_sizes.rdata")

# stop cluster
stopCluster(cl)
#save(est.eff_sim500, file="../data/simulations/exp2_estimate_effect_500.rdata")
```

```{r summarise simulation}
#| echo: false

exp2_simu_raw_with_postprop |> 
  summarise(
    pow_con = mean(p_con<.05),
    pow_cue = mean(p_cue<.05),
    pow_con.cue = mean(`p_con:cue`<.05),
    across(c(everything(), -itr), mean),
    .by = c(eff, size, post_prop)
  ) -> exp2_simu_w_post_sum
```


```{r power}
#| echo: false

exp2_simu_w_post_sum |> 
  filter(post_prop == 4) |>
  filter(eff < .36 & eff > .1) |>
  pivot_longer(c(pow_con, pow_cue, pow_con.cue)) |>
  ggplot(aes(size, value, col=factor(eff)))+
  facet_wrap(~name) +
  geom_line(alpha = .4) +
  geom_smooth(alpha = .1) +
  coord_cartesian(ylim=c(.7,1)) + 
  geom_hline(yintercept = .90) +
  geom_vline(xintercept = 36)

```

```{r}
#| echo: false

if(save_animations){
  eff_range <- seq(.04, .24, .02)
  
  walk(seq(.04, .7, .02), \(eff_size){
    
    exp2_simu_w_post_sum |>
      filter( eff %in% eff_size ) |>
      pivot_longer(c(pow_con, pow_cue, pow_con.cue)) |>
      ggplot(aes(size, value, col = factor(post_prop))) +
      facet_wrap(~ name) +
      geom_line(alpha = .4) + 
      geom_smooth(alpha = .1) +
      geom_vline(xintercept = 36) +
      geom_hline(yintercept = .9) +
      coord_cartesian(ylim = c(.7, 1)) +
      labs(col = "post cue", 
           subtitle = paste("Effect size:", eff_size)) -> p
    
    ggsave(paste0("../outputs/animations/exp2_design_2x2/png_over_effs/exp2_design_2x2_eff-", eff_size,".png"), 
           p, 
           width = 10, 
           height = 4)
  })
    
  fignames <- list.files("../outputs/animations/exp2_design_2x2/png_over_effs", full.names = T)
  # create gif
  gifski(fignames, "../outputs/animations/exp2_design_2x2/size_over_time_exp2_2x2.gif", delay = .25)
  # create video format
  av_encode_video(fignames, "../outputs/animations/exp2_design_2x2/size_over_time_exp2_2x2.mkv", framerate = 4)
  
}
```

```{r}
#| echo: false

if(save_animations){
  walk(10:100, \(samp_size){
    print(samp_size)
    p <-
      exp2_simu_w_post_sum |>
      filter(size == samp_size) |>
      # filter( eff %in% eff_size ) |>
      pivot_longer(c(pow_con, pow_cue, pow_con.cue)) |>
      ggplot(aes(eff, value, col = factor(post_prop))) +
      facet_wrap(~ name) +
      geom_line(alpha = .4) + 
      geom_smooth(alpha = .0) +
      geom_hline(yintercept = .9) +
      coord_cartesian(ylim = c(.7, 1)) + 
      labs(col = "post cue", 
           subtitle = paste("Sample size:", samp_size)) 
    
    ggsave(paste0("../outputs/animations/exp2_design_2x2/png_over_samp_size/exp2_design_2x2_eff-", samp_size,".png"), 
           p, 
           width = 10, 
           height = 4)
  })
    
  fignames <- list.files("../outputs/animations/exp2_design_2x2/png_over_samp_size", full.names = T)
  # create gif
  gifski(fignames, "../outputs/animations/exp2_design_2x2/pngize_over_time_exp2_2x2.gif", delay = .25)
  # create video format
  av_encode_video(fignames, "../outputs/animations/exp2_design_2x2/size_over_time_exp2_2x2.mkv", framerate = 4)
  
}
```



```{r }
exp2_simu_w_post_sum |>
  pivot_longer(c(pow_con, pow_cue, pow_con.cue)) |>
  filter(eff >.13, eff < .22) |>
  ggplot(aes(size, value, col=factor(eff)))+
  geom_smooth(alpha = .1)+
  geom_hline(yintercept=.90)
  geom_line()
  stat_summary()
  geom_line()+
  geom_hline(yintercept=.9)+
  scale_x_continuous(breaks=seq(0,200,10))

est.eff_sim500 |>
  pivot_longer(c(pow.con, pow.cue, `pow.con.cue`)) |>
  ggplot(aes(size, value, col=name))+
  geom_line()+
  geom_hline(yintercept=.9)+
  scale_x_continuous(breaks=seq(0,200,10))
```


```{r}
#| echo: false
est.eff_sim500 |> 
  pivot_longer(c(p_con, p_cue, `p_con:cue`)) |>
  ggplot(aes(size, value, col=name, group=name))+
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_vline(xintercept=12)+
  scale_x_continuous(breaks=seq(0,200,10))+
  annotate("text",x = 24, y=.09, label = "12 participants")+
  labs(y="p value", x="Sample size", col = "Effects")
```

Generally, recruiting around 25 participants seems to suffice to find a significant effect.
#### Power
```{r}
#| echo: false

est.eff_sim500 |> 
  pivot_longer(c(pow.cue, pow.con, pow.con.cue)) |>
  mutate(name = str_replace_all(name, "pow.", "")) |>
  ggplot(aes(size, value, col=name)) +
  labs(y="Power", x="Sample size", col="Effect")+
  coord_cartesian(ylim=c(.6, 1), xlim=c(10, 50))+
  scale_x_continuous(breaks=seq(0,200,10))+
  geom_line()+
  geom_hline(yintercept=.95, col ="darkblue", linetype="dashed")+
  geom_vline(xintercept = 20, col = "darkblue", linetype="dashed")+
  annotate("text",x = 25, y=.92, label = "30 participants", col="darkblue")
```

With an partial eta squared of .21, we can a power of 95% for the Congruency*CUE interaction with 20 participants.

```{r}
#| echo: false
#| message: false
est.eff_sim500 |> 
  pivot_longer(c(ges_con, ges_cue, `ges_con:cue`)) |> 
  mutate(name = str_replace_all(name, "ges_", "")) |>
  ggplot(aes(size, value, col=name, group=name))+
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_smooth(method="lm",  linewidth=.5, alpha=.2)+
  scale_y_continuous(breaks=seq(0,1,.05))+
  labs(y="ges", x="Sample size", col="Effect")
```

The effect size seems to slightly decrease with increasing sample size.

#### Visualize the expected difference
```{r}
#| echo: false
#| message: false

pblapply(1:30, \(i) exp2_sim2x2(30,24,12, .05, .008, .17) |> mutate(v=i) ) |> 
  map_df(~.x) -> par30

par30 |>
  ggplot(aes(con, rt, col=cue, group=interaction(v,cue)))+
  stat_summary(aes(col=NULL), alpha=.2, position=position_dodge(.1))+
  stat_summary(aes(col=NULL), alpha=.2, geom="line", position=position_dodge(.1))+
  stat_summary(aes(group=cue), geom="line", linewidth=1.5, position=position_dodge(.1))+
  stat_summary(aes(group=cue), linewidth=1.5, position=position_dodge(.1))
```
The plot illustrates the interaction, simulated 30 times.



## Effect based on GPower
Here we assume the effect as calculated by GPower .14 ~ .4 d: (.14 post-cue , and .046 pre-cue)

```{r}
#| echo: false
#| message: false
#| warning: false

if(run_simulations)
# Create a "cluster" to simulate faster
# Take half the computers cores 
makeCluster( floor(detectCores() - detectCores() * 1/2) ) -> cl
# Export the local function
clusterExport(cl, varlist = c("exp2_sim2x2", "gpow_eff"))
# Initiate libraries in clusters
clusterEvalQ(cl, {
  library(tidyverse)
  library(pbapply)
  library(afex)
})

# Apply function across "cl"
pblapply(10:100, \(x){
  # apply *x* participants...
  purrr::map_df(1:500, \(y){
    # repeat each par-size 100 times
    exp2_sim2x2(x, 24, 20, gpow_eff/3, .008, gpow_eff) -> d
    d |> 
      aov_car(rt ~ con*cue + Error(id/(con*cue)), data = _, fun_aggregate=mean) -> 
      res
    tibble(
      size = x,
      itr = y,
      name = c(names(res$Anova$SSP[2]),names(res$Anova$SSP[3]), names(res$Anova$SSP[4])),
      ges = res[["anova_table"]][["ges"]],
      p = res[["anova_table"]][["Pr(>F)"]],
    ) |> pivot_wider(names_from = name, values_from =c(ges, p))
  }) |> summarise(size = unique(size),
                  itr = max(itr),
                  pow.con = mean(p_con<.05),
                  pow.cue = mean(p_cue<.05),
                  pow.con.cue = mean(`p_con:cue`<.05),
                  across(contains("_"), mean))
}, cl = cl) |>
  map_df(~.x) -> gpow.eff_sim500

# stop cluster
stopCluster(cl)
#save(gpow.eff_sim500, file="../data/simulations/exp2_gpower_effect_500.rdata")
```


### Power
```{r}
#| echo: false

gpow.eff_sim500 |> 
  pivot_longer(c(pow.cue, pow.con, pow.con.cue)) |>
  mutate(name = str_replace_all(name, "pow.", "")) |>
  ggplot(aes(size, value, col=name)) +
  labs(y="Power", x="Sample size", col="Effect")+
  coord_cartesian(ylim=c(.6, 1), xlim=c(10, 50))+
  scale_x_continuous(breaks=seq(0,200,10))+
  geom_line()+
  geom_hline(yintercept=.95, col ="darkblue", linetype="dashed")+
  geom_vline(xintercept = 36, col = "darkblue", linetype="dashed")+
  annotate("text",x = 41, y=.88, label = "36 participants", col="darkblue")+
  geom_hline(yintercept=.90, col ="indianred")+
  geom_vline(xintercept = 30, col = "indianred")+
  annotate("text", x = 22, y=.88, label = "30 participants", col="indianred")
```

To have 95% power for the interaction between congruency and cue with the gpower estimate (.14), we require about 36 participants.
Alternatively, we can have 90% power with 30 participants.


