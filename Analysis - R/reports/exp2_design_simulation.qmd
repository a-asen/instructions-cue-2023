---
title: "exp2_design_simulation"
format: html
lang: en-GB
editor: 
  markdown:
    wrap: 62
---

```{r}
#| include: false

load("../data/trans/exp1_data.rdata")

library(tidyverse)
library(lsr)
library(pbapply)
library(afex)
library(gt)

```

## Exclusion
```{r exclusion start - accuracy}
#| include: FALSE

d <-
  exp1_d |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, con) |>
  mutate(rt = as.numeric( ifelse(rt=="null", NA, rt)) ) |>
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial") |>
  filter(!is.na(correct_response))

loss <- list()
loss$data_trials <- nrow(d)

### Overall accuracy      ====
exp1_d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
  summarize( acc = sum(correct_response, na.rm = TRUE) / length( !is.na(correct_response) ) ) |>
  filter( acc < .7 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( d$rt[d$id == loss$exclude_par] )
loss[["exclude_par_pct"]]    <- length( d$rt[d$id == loss$exclude_par] ) / loss$data_trials * 100

d |> filter( !(id %in% loss$exclude_par) ) -> d
#id
d |>
  group_by(id) |>
  mutate(
    rt_crit = ifelse( 
      trial_info == "Diagnostic trial",
      mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5,
      NA ),
      retain_trials = ifelse(
        (rt > rt_crit & trial_info == "Diagnostic trial") | # **OR**
          (is.na(rt) & trial_info == "Diagnostic trial"),
        0, 1 ) 
    ) -> d

sum(d$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_pct"]]

d |> 
  filter( retain_trials == 1 ) -> d
d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d

sum(d$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_pct"]]

d |> filter( valid_trials == 1 ) -> d
```


# Estimating effect size for ANOVA: 
```{r}
#| message: false
d |>
  filter(!is.na(con)) |>
  group_by(id, con) |> 
  summarise(rt = mean(rt)) |>
  aov(rt ~ con + Error(id/con), data=_ ) |>
  EtaSq(x=_, type=1)
```
Partial eta square of .21 (Lakens, 2013)

According to gpower, an effect size of .14 correspond to an effect size of .4:
```{r}
con_eff <- .21
gpow_eff <- .14
```


# Simulation 2x2 rmANOVA (Congruency X cue)

We can simulate the tests for the experiment by adding an additional factor (cue).
We have two main effects, congruency and cue, including an interaction congruency*cue.
We hypothesize an interaction between the cue and the congruency, while the main effect of congruency will remain weak if existent. 
We do not hypothesize an effect of the cue, but we expect it to interact with the congruency. 
In this way, we expect a congruency effect ONLY for trials AFTER the cue.

In the function below we can generate the experimental setup: 
```{r}
exp2_sim2x2 <- function(N, blocks, block.len, eff.con.pre, eff.con.post, eff.con.cue.intr){
  #' @param N Number of subjects
  #' @param blocks Number of blocks 
  #' @param block.len Length of each block -- this is split, half the trials are pre and half are post
  #' @param eff.con.pre Effect size of the congruency effect
  #' @param eff.cue.post Effect size of the pre-post cue
  #' @param eff.con.cue.intr Effect size of the interaction

  tibble(
    id     = rep(1:N, each = blocks * block.len),
    block  = rep.int( rep(1:blocks, each = block.len), N),
    cue    = rep.int( rep(c("pre", "post"), each = block.len/2), blocks * N),
    con    = rep.int( c("con", "incon"), N * blocks * block.len/2),
    rt     = rnorm(N * blocks * block.len, 
                   0 + 
                     - as.integer(con=="con") * eff.con.pre + 
                     + as.integer(cue=="post") * eff.con.post + 
                     - as.integer(con=="con" & cue=="post") * eff.con.cue.intr,
                   1)
  ) -> d
  
  # Here we remove some post trials equal to half 
  # First we take all the pre trials: 
  d |> 
    filter(cue=="pre") |>
  # Then we combine the filtered post trials: 
  rbind(
    d |> 
      # We filter in such a way that we slice the first trials for each id in each trial:
      filter(cue=="post") |>
      group_by(id, block) |>
      slice_head(n = floor( block.len/2/2 ) )
  )
}
```


## Effect based on estimate
Here we assume the effect as calculated by the one-way ANOVA (.21 post-cue , and .07 pre-cue)

```{r simulate experiment 2}
#| echo: false

# Create a "cluster" to simulate faster
# Take half the computers cores 
makeCluster( floor(detectCores() - detectCores() * 1/2) ) -> cl
# Export the local function
clusterExport(cl, varlist = c("exp2_sim2x2", "con_eff"))
# Initiate libraries in clusters
clusterEvalQ(cl, {
  library(tidyverse)
  library(pbapply)
  library(afex)
})

# Apply function across "cl"
pblapply(10:100, \(x){
  # apply *x* participants...
  purrr::map_df(1:500, \(y){
    # repeat each par-size 100 times
    exp2_sim2x2(x, 24, 20, con_eff/3, .008, con_eff) -> d
    d |> 
      aov_car(rt ~ con*cue + Error(id/(con*cue)), data = _, fun_aggregate=mean) -> 
      res
    tibble(
      size = x,
      itr = y,
      name = c(names(res$Anova$SSP[2]),names(res$Anova$SSP[3]), names(res$Anova$SSP[4])),
      ges = res[["anova_table"]][["ges"]],
      p = res[["anova_table"]][["Pr(>F)"]],
    ) |> pivot_wider(names_from = name, values_from =c(ges, p))
  }) |> summarise(size = unique(size),
                  itr = max(itr),
                  pow.con = mean(p_con<.05),
                  pow.cue = mean(p_cue<.05),
                  pow.con.cue = mean(`p_con:cue`<.05),
                  across(contains("_"), mean))
}, cl = cl) |>
  map_df(~.x) -> est.eff_sim500

# stop cluster
stopCluster(cl)
```

```{r}
#| echo: false
est.eff_sim500 |> 
  pivot_longer(c(p_con, p_cue, `p_con:cue`)) |>
  ggplot(aes(size, value, col=name, group=name))+
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_vline(xintercept=12)+
  scale_x_continuous(breaks=seq(0,200,10))+
  annotate("text",x = 24, y=.09, label = "12 participants")+
  labs(y="p value", x="Sample size", col = "Effects")
```

Generally, recruiting around 25 participants seems to suffice to find a significant effect.
### Power
```{r}
#| echo: false

est.eff_sim500 |> 
  pivot_longer(c(pow.cue, pow.con, pow.con.cue)) |>
  mutate(name = str_replace_all(name, "pow.", "")) |>
  ggplot(aes(size, value, col=name)) +
  labs(y="Power", x="Sample size", col="Effect")+
  coord_cartesian(ylim=c(.6, 1), xlim=c(10, 50))+
  scale_x_continuous(breaks=seq(0,200,10))+
  geom_line()+
  geom_hline(yintercept=.95, col ="darkblue", linetype="dashed")+
  geom_vline(xintercept = 20, col = "darkblue", linetype="dashed")+
  annotate("text",x = 25, y=.92, label = "30 participants", col="darkblue")
```

With an partial eta squared of .21, we can a power of 95% for the Congruency*CUE interaction with 20 participants.

```{r}
#| echo: false
#| message: false
est.eff_sim500 |> 
  pivot_longer(c(ges_con, ges_cue, `ges_con:cue`)) |> 
  mutate(name = str_replace_all(name, "ges_", "")) |>
  ggplot(aes(size, value, col=name, group=name))+
  geom_line()+
  geom_hline(yintercept=.05)+
  geom_smooth(method="lm",  linewidth=.5, alpha=.2)+
  scale_y_continuous(breaks=seq(0,1,.05))+
  labs(y="ges", x="Sample size", col="Effect")
```

The effect size seems to slightly decrease with increasing sample size.

### Visualize the expected difference
```{r}
#| echo: false
#| message: false

pblapply(1:30, \(i) exp2_sim2x2(30,24,12, .05, .008, .17) |> mutate(v=i) ) |> 
  map_df(~.x) -> par30

par30 |>
  ggplot(aes(con, rt, col=cue, group=interaction(v,cue)))+
  stat_summary(aes(col=NULL), alpha=.2, position=position_dodge(.1))+
  stat_summary(aes(col=NULL), alpha=.2, geom="line", position=position_dodge(.1))+
  stat_summary(aes(group=cue), geom="line", linewidth=1.5, position=position_dodge(.1))+
  stat_summary(aes(group=cue), linewidth=1.5, position=position_dodge(.1))
```
The plot illustrates the interaction, simulated 30 times.



## Effect based on estimate
Here we assume the effect as calculated by GPower .14 ~ .4 d: (.14 post-cue , and .046 pre-cue)

```{r}
#| echo: false
#| message: false
#| warning: false

# Create a "cluster" to simulate faster
# Take half the computers cores 
makeCluster( floor(detectCores() - detectCores() * 1/2) ) -> cl
# Export the local function
clusterExport(cl, varlist = c("exp2_sim2x2", "gpow_eff"))
# Initiate libraries in clusters
clusterEvalQ(cl, {
  library(tidyverse)
  library(pbapply)
  library(afex)
})

# Apply function across "cl"
pblapply(10:100, \(x){
  # apply *x* participants...
  purrr::map_df(1:500, \(y){
    # repeat each par-size 100 times
    exp2_sim2x2(x, 24, 20, gpow_eff/3, .008, gpow_eff) -> d
    d |> 
      aov_car(rt ~ con*cue + Error(id/(con*cue)), data = _, fun_aggregate=mean) -> 
      res
    tibble(
      size = x,
      itr = y,
      name = c(names(res$Anova$SSP[2]),names(res$Anova$SSP[3]), names(res$Anova$SSP[4])),
      ges = res[["anova_table"]][["ges"]],
      p = res[["anova_table"]][["Pr(>F)"]],
    ) |> pivot_wider(names_from = name, values_from =c(ges, p))
  }) |> summarise(size = unique(size),
                  itr = max(itr),
                  pow.con = mean(p_con<.05),
                  pow.cue = mean(p_cue<.05),
                  pow.con.cue = mean(`p_con:cue`<.05),
                  across(contains("_"), mean))
}, cl = cl) |>
  map_df(~.x) -> gpow.eff_sim500

# stop cluster
stopCluster(cl)
""
```


### Power
```{r}
#| echo: false

gpow.eff_sim500 |> 
  pivot_longer(c(pow.cue, pow.con, pow.con.cue)) |>
  mutate(name = str_replace_all(name, "pow.", "")) |>
  ggplot(aes(size, value, col=name)) +
  labs(y="Power", x="Sample size", col="Effect")+
  coord_cartesian(ylim=c(.6, 1), xlim=c(10, 50))+
  scale_x_continuous(breaks=seq(0,200,10))+
  geom_line()+
  geom_hline(yintercept=.95, col ="darkblue", linetype="dashed")+
  geom_vline(xintercept = 36, col = "darkblue", linetype="dashed")+
  annotate("text",x = 41, y=.88, label = "36 participants", col="darkblue")+
  geom_hline(yintercept=.90, col ="indianred")+
  geom_vline(xintercept = 30, col = "indianred")+
  annotate("text", x = 22, y=.88, label = "30 participants", col="indianred")
```

To have 95% power for the interaction between congruency and cue with the gpower estimate (.14), we require about 36 participants.
Alternatively, we can have 90% power with 30 participants.


# Simulation 2x2x2 rmANOVA (congruency X cue X CSI ) 

We believe that...
- ... (1) Congruent trials benefit from reduced RT (during short-csi + pre-cue)
- ... (2) that post-cue interact with congruency reducing RT (due to preparation signals) (during short CSI)
- ... (3) that long-csi interact with post-cue and congruency to further reduce RT (due to further improved preparation)

We are looking for a congruency during post-cue (2-way interaction) and during long-csi & post-cue (3-way interaction)

```{r}
exp2_sim2x2x2 <- function(N, blocks, block.len, e.con, short.post.con, long.post.con){
  #' @param N              Number of subjects
  #' @param blocks         Number of blocks 
  #' @param block.len      Length of each block
  #' @param e.con          What is the effect on RT before the *cue* during the *short CSI*?
  #' @param short.post.con What is the effect on congruency after the *cue* for the *short CSI*?
  #' @param long.post.con  What is the effect on congruency after the *cue* for the *short CSI*?
  
  cue_rep = 2 
  tibble(
    id     = rep(1:N, each = blocks * block.len * cue_rep),
    csi    = rep.int( rep(c("short", "long"), each = (blocks * block.len * cue_rep)/2), N),
    block  = rep.int( rep(1:blocks, each = block.len * cue_rep), N),
    cue    = rep.int( rep(c("pre", "post"), each = block.len), blocks * N),
    con    = rep.int( c("incon", "con"), N * blocks * block.len),
    rt     = rnorm(   N * blocks * block.len * cue_rep, 
                      0 +
                        # 1:
                        - as.integer(con=="con") * e.con +
                        # 2: 
                        - as.integer(csi=="short" & cue=="post" & con=="con") * short.post.con + 
                        # 3:                         
                        - as.integer(csi=="long" & cue=="post" & con=="con") * long.post.con
    )) -> d
  
  # Here we remove some post trials equal to half 
  # First we take all the pre trials: 
  d |> 
    filter(cue=="pre") |>
    # Then we combine the filtered post trials: 
    rbind(
      d |> 
        # We filter in such a way that we slice the first trials for each id in each trial:
        filter(cue=="post") |>
        group_by(id, block) |>
        slice_head(n = floor( block.len/2/2 ) )
    )
}
```

First let us test whether the function simulates the data in the expected directions: 

(For this we stick with GPower effect size to be conservative)
```{r}
#| echo: false
#| message: false
exp2_sim2x2x2(30, 24, 20, gpow_eff/5, gpow_eff/2, gpow_eff) -> test_sim

test_sim |>
  ggplot(aes(con, rt, col=interaction(csi,cue), group=interaction(csi,cue)))+
  stat_summary(alpha=.2, position=position_dodge(.1))+
  stat_summary(alpha=.2, geom="line", position=position_dodge(.1))+
  stat_summary(geom="line", position=position_dodge(.1))+
  stat_summary(position=position_dodge(.1))+
  scale_color_manual(values=c("indianred1", "indianred4", "deepskyblue1", "deepskyblue4"))
```

```{r}
#| echo: false
#| message: false

test_sim |>
  mutate(condition = factor( case_when(
    csi=="short" & cue=="pre" ~ "short-pre",
    csi=="short" & cue=="post" ~ "short-post",
    csi=="long" & cue=="pre" ~ "long-pre",
    csi=="long" & cue=="post" ~ "long-post",
    ), levels = c("short-pre", "short-post", "long-pre", "long-post"))) |>
  ggplot(aes(condition, rt, col = con, group = con))+
  stat_summary(alpha=.2, position=position_dodge(.1))+
  stat_summary(alpha=.2, geom="line", position=position_dodge(.1))+
  stat_summary(geom="line", position=position_dodge(.1))+
  stat_summary(position=position_dodge(.1))+
  scale_color_manual(values=c("indianred2", "deepskyblue"))+
  theme_minimal()
```

This generally seems to be correct.


### Test Sim: 30 repeat
```{r generate 2x2x2 data}
#| echo: false
pblapply(1:30, \(i) exp2_sim2x2x2(30, 24, 20, gpow_eff/5, gpow_eff/2, gpow_eff) |> mutate(simulation=i) ) |> 
  map_df(~.x) -> par30_2x2x2
```

```{r anova table}
#| echo: false
par30_2x2x2 |> 
  filter(simulation==1) |> 
  aov_car(rt ~ csi*cue*con + Error(id/(csi*cue*con)), data = _,fun_aggregate = mean) |> 
  summary()
```

```{r single vis}  
#| echo: false

par30_2x2x2 |> 
  filter(simulation==1) |>
  ggplot(aes(con, rt, col = interaction(csi, cue), group=interaction(csi, cue)))+
  stat_summary(geom="line")+
  stat_summary()
```

```{r}
par30_2x2x2 |>
  ggplot(aes(con, rt, col=interaction(csi,cue), group=interaction(simulation,csi,cue)))+
  stat_summary(alpha=.05, position=position_dodge(.4))+
  stat_summary(alpha=.05, geom="line", position=position_dodge(.4))+
  stat_summary(aes(group=interaction(csi,cue)), geom="line", position=position_dodge(.2))+
  stat_summary(aes(group=interaction(csi,cue)), position=position_dodge(.2))+
  scale_color_manual(values=c("indianred1", "indianred4", "deepskyblue1", "deepskyblue4"))+
  labs(col="CSI * CUE")+
  theme_minimal()
```

```{r}
#| echo: false
#| message: false
par30_2x2x2 |>
  mutate(condition = factor( case_when(
    csi=="short" & cue=="pre" ~ "SHORT--pre",
    csi=="short" & cue=="post" ~ "SHORT--post",
    csi=="long" & cue=="pre" ~ "LONG--pre",
    csi=="long" & cue=="post" ~ "LONG--post",
    ), levels = c("SHORT--pre", "SHORT--post", "LONG--pre", "LONG--post"))) |>
  ggplot(aes(condition, rt, col = con, group = interaction(simulation,con)))+
  stat_summary(aes(col=NULL), alpha=.07, position=position_dodge(.2))+
  stat_summary(aes(col=NULL), alpha=.07, geom="line", position=position_dodge(.2))+
  stat_summary(aes(group=con), geom="line", position=position_dodge(.2))+
  stat_summary(aes(group=con), position=position_dodge(.2))+
  scale_color_manual(values=c("indianred2", "deepskyblue"))+
  theme_minimal()+
  labs(col="Congruency")
```


### Big Sim: 10:100 participants each 500 
With that, we can calculate the power needed to detect a three-way and a two way interaction: 
```{r simulate experiment 2}
#| echo: false
#| warning: false
#| message: false

# Create a "cluster" to simulate faster
# Take half the computers cores 
makeCluster( floor(detectCores() - detectCores() * 1/2) ) -> cl
# Export the local function
clusterExport(cl, varlist = c("exp2_sim2x2x2", "gpow_eff"))
# Initiate libraries in clusters
clusterEvalQ(cl, {
  library(tidyverse)
  library(pbapply)
  library(afex)
})

# Apply function across "cl"
pblapply(10:100, \(x){
  # apply *x* participants...
  purrr::map_df(1:500, \(y){
    # repeat each par-size 100 times
    exp2_sim2x2x2(x, 24, 20, gpow_eff/5, gpow_eff/2, gpow_eff) -> d
    d |> 
      aov_car(rt ~ csi*cue*con + Error(id/(csi*cue*con)), data = _, fun_aggregate=mean) -> res
    
    tibble(
      size = x,
      itr = y,
      name = res[["Anova"]][["terms"]][-1],
      ges = res[["anova_table"]][["ges"]],
      p = res[["anova_table"]][["Pr(>F)"]],
    ) |> pivot_wider(names_from = name, values_from =c(ges, p))
  }) |> summarise(size = unique(size),
                  itr = max(itr),
                  p.cs.cu = mean(`p_csi:cue`<.05),
                  p.cs.co = mean(`p_csi:con`<.05),
                  p.cu.co = mean(`p_cue:con`<.05),
                  p.co.cu.cs = mean(`p_csi:cue:con`<.05),
                  across(contains("_"), mean))
}, cl = cl) |>
  map_df(~.x) -> g.eff_2x2x2_sim500

# stop cluster
stopCluster(cl)
```


```{r}
g.eff_2x2x2_sim500 |> 
  pivot_longer(c(`p_csi:cue:con`, `p_cue:con`)) |>
  ggplot(aes(size, value, col=name, group=interaction(itr, name)))+
  geom_line()+
  geom_hline(yintercept=.05)
```

