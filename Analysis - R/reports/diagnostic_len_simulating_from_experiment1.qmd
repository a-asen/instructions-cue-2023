---
title: "How many diagnostic pairs do we need?"
subtitle: "Simulating from experiment 1 parameters"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

# Start

```{r params}
#| include: false
run_simulations <- FALSE

make_cluster <- TRUE
save_simulation_data <- FALSE
load_simulation_data <- FALSE
```

```{r libraries}
#| include: false
library(tidyverse) 
library(arrow)     # load parquet files 
library(parallel)  # parallel processing
library(pbapply)   # parallel processing w/ progression bar
library(lsr)       # Stats
library(afex)      # Stats
library(broom)     # tidying
```

```{r start cluster. if simulating data}
#| include: false
if(make_cluster){
  cl <- makeCluster(detectCores()*.95)
  clusterEvalQ(cl, {
    library(tidyverse)
    library(afex)
    library(broom)
    library(lsr)
  })
} else {cl <- NULL}

```

# Data

```{r load data}
#| include: false
load("../data/processed/exp1_data.rdata")

mult_test <- read_parquet("../data/simulations/sample_based_on_exp1_parames_by_congruency.parquet")
```

```{r preprocessing}
# preprocess 
source("rep_munge/exp1_preprocess.R")
```

```{r exp1 outcomes}
#| echo: false
d_ex |> 
  filter(!is.na(con)) |>
  summarise(
    .by = c(id, con),
    rt = mean(rt), 
    pe = 1 - mean(correct_response),
  ) |>
  mutate(
    rt = scale(rt),
    pe = scale(pe)
  ) -> exp1_intermediate_step
  
# raw (only con)
exp1_intermediate_step |>
  summarise(
    .by=con,
    rt_sd = sd(rt), 
    pe_sd = sd(pe), 
    across(where(is.double), mean)
  ) -> exp1_outcome_raw

# by id and con
exp1_intermediate_step |>
  pivot_wider(names_from = con, values_from = c(rt,pe)) |>
  summarise(
    rt_d_m = mean(rt_FALSE-rt_TRUE),
    rt_d_sd = sd(rt_FALSE-rt_TRUE),
    rt_eff = rt_d_m / rt_d_sd,
    pe_d_m = mean(pe_FALSE-pe_TRUE),
    pe_d_sd = sd(pe_FALSE-pe_TRUE),
    pe_eff = pe_d_m / pe_d_sd,
  ) -> exp1_outcome
exp1_outcome
```

```{r integrated score outcome}
#| echo: false
# Grand:
grand <- 
  d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    g_rt = mean(rt),
    g_rt_sd = sd(rt),
    g_pc = mean(correct_response),
    g_pe = 1 - g_pc,
    g_pc_sd =  sd(correct_response) )

# LISAS:
lisas <- 
  d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  summarize(
    .by = id,
    l_rt_sd = sd(rt),
    l_pe_s = sqrt( mean(correct_response) * (1 - mean(correct_response)) ))
  
# Calculation
res <-
  d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  filter(!is.na(con)) |>
  summarise(
    .by = c(id, con), 
    rt_sd = sd(rt),
    rt = mean(rt),
    pe_sd = sd(correct_response),
    pe = 1 - mean(correct_response),
    pc = mean(correct_response),
  ) |>
  left_join(lisas, by="id") |> 
  bind_cols(grand) |>
  mutate(
    lisas  = ifelse(is.infinite(l_rt_sd/l_pe_s), rt, rt + (l_rt_sd/l_pe_s) * pe), 
    BIS    = ( (pc - g_pc) / g_pc_sd ) - ( (rt - g_rt) / g_rt_sd ) )
  
res |>
  t.test(lisas ~ con, data=_, paired = T, alternative="greater") |> 
  tidy() |> 
  mutate(.before=1, n = "LISAS") |>
  rbind(
    res |> 
      t.test(BIS ~ con, data=_, paired=T, alternative="greater") |> 
      tidy() |> 
      mutate(.before=1, n="BIS")
  ) |> 
  bind_cols(
    res |>
      summarise(
        .by = con, 
        lisas_sd = sd(lisas),
        lisas = mean(lisas),
        bis_sd = sd(BIS),
        bis = mean(BIS),
      )
  ) -> exp1_outcome_int_score

res |> 
  select(con, BIS, lisas, id) |> 
  pivot_longer(c(BIS, lisas)) |>
  pivot_wider(names_from=con, values_from=value) |>
  rename(Incongruent = `FALSE`, Congruent = `TRUE`) |>
  summarise(
    .by=name,
    mdiff = mean(Incongruent - Congruent),
    sd    = sd(Incongruent - Congruent),
    d = cohensD(Incongruent, Congruent, method="paired") ,
    d2 = cohensD(Incongruent, Congruent, method="paired") 
  ) -> 
exp1_outcome_int_score
```

# Simulate from slicing parameter calculation:

```{r}
#| echo: false
sim_pe_rt_parameters 


sim_exp2_from_exp1_params <- function(size, difference){
  tibble(
    id = seq(1,size,1),
    pre_cue = rnorm(
      size,
      sim_pe_rt_parameters |> filter(pairs==100, name=="pe") |> pull(m_d) * difference,
      sim_pe_rt_parameters |> filter(pairs==100, name=="pe") |> pull(sd_d)
    ),
    post_cue = rnorm(
      size,
      sim_pe_rt_parameters |> filter(pairs==26, name=="pe") |> pull(m_d),
      sim_pe_rt_parameters |> filter(pairs==26, name=="pe") |> pull(sd_d)
    )
  )
}


clusterExport(cl, "sim_exp2_from_exp1_params")
exp2_cue_diff_sim <- 
pblapply(1:500, \(rep){
  map_df(27:50, \(samp){
    map_df(seq(.1,.5,.025), \(diff){
      sim_exp2_from_exp1_params(samp, diff) |>
        mutate(diff = pre_cue-post_cue) |> 
        pull(diff) |>
        t.test(x = _, mu=0) |> 
        tidy() |> 
        mutate(
          .before=1, 
          size = samp,
          diff = diff,
          itr  = rep, 
        )
    })
  })
}) |> map_df(~.x)

test |> 
  ggplot(aes(itr, p.value, col=size))+
  geom_line()

test |> 
  summarise(
    .by = size, 
    pow  = mean(p.value < .05),
    across(where(is.double), mean),
  )
```



# Simulate experiment 1

```{r}
#| echO: false
rnd_slice_diag_exclu

test |> 
  summarise(
    .by = c(pairs,n),
    pow = mean(p.value<.05),
    across(everything(), mean)
  ) |>
  ggplot(aes(pairs, pow, col=n))+
  geom_line()
  


tibble(
  id       = seq(1,27),
  pre_cue  = rnorm(27, exp1_outcome$rt_d_m, exp1_outcome$rt_d_sd),
  post_cue = rnorm(27, exp1_outcome$rt_d_m, exp1_outcome$rt_d_sd)
)
test


exp1_outcome 
```
```{r}
#| echo: false
clusterExport(cl, "exp1_outcome")
pblapply(27:50, \(size){
  map_df(1:900,\(x){
    rnorm(size, exp1_outcome$pe_d_m-.4, exp1_outcome$pe_d_sd) -> pre_cue_run
    rnorm(size, exp1_outcome$pe_d_m, exp1_outcome$pe_d_sd-.8) -> post_cue_run
    t.test(pre_cue_run, post_cue_run, paired=T) |> 
      tidy()
  }) |> mutate(size = size)
}, cl = cl) |> 
  map_df(~.x) -> 
  pre_post_rep_sim

pre_post_rep_sim |> 
  summarise(
    .by = size,
    pow = mean(p.value<.05),
    across(everything(), mean)
  ) |> 
  ggplot(aes(size, pow))+
  geom_line() + 
  geom_hline(yintercept=.8)
```

```{r Raw score data sim func}
gen_data_raw <- function(N, obs){
  #' @param N Number of subjects
  #' @param OBS Number of observation per N

  tibble(
    id  = rep(1:N, each = obs),
    pairs = rep.int(1:obs, N),
    rt_con  = rnorm(N * obs, 
                    exp1_outcome_raw$rt[exp1_outcome_raw$con==T],
                    exp1_outcome_raw$rt_sd[exp1_outcome_raw$con==T]),
    rt_incon = rnorm(N * obs,
                    exp1_outcome_raw$rt[exp1_outcome_raw$con==F],
                    exp1_outcome_raw$rt_sd[exp1_outcome_raw$con==F]),
    pe_con = rnorm(N * obs, 
                    exp1_outcome_raw$pe[exp1_outcome_raw$con==T],
                    exp1_outcome_raw$pe_sd[exp1_outcome_raw$con==T]),
    pe_incon = rnorm(N * obs, 
                    exp1_outcome_raw$pe[exp1_outcome_raw$con==F],
                    exp1_outcome_raw$pe_sd[exp1_outcome_raw$con==F])
    )
}
```


## Simulate via raw difference (not like this)

### RT

```{r}
#| echo: false
clusterExport(cl, "exp1_outcome")
pblapply(27:50, \(size){
  map_df(1:900,\(x){
    rnorm(size, exp1_outcome$rt_d_m, exp1_outcome$rt_d_sd) -> test
    t.test(test, mu = 0) |> 
      tidy()
  }) |> mutate(size = size) 
}, cl = cl) |> 
  map_df(~.x) -> 
  rt_rep_sim

rt_rep_sim |> 
  summarise(
    .by = size,
    pow = mean(p.value<.05),
    across(everything(), mean)
  ) |> 
  ggplot(aes(size, pow))+
  geom_line() + 
  geom_hline(yintercept=.8)
```

To get 80% on RT, we need 37 participants (or so).

### PE

```{r pe data sim}
#| echo: false
pblapply(27:50, \(size){
  map_df(1:900,\(x){
    rnorm(size, exp1_outcome$pe_d_m, exp1_outcome$pe_d_sd) -> test
    t.test(test, mu = 0) |> 
      tidy() |> 
      mutate(m = mean(test), sd = sd(test))
  }) |> mutate(size = size) 
}, cl = cl) |> 
  map_df(~.x) -> 
  pe_rep_sim

pe_rep_sim |> 
  summarise(
    .by = size,
    pow = mean(p.value<.05),
    across(everything(), mean)
  ) |> 
  ggplot(aes(size, pow))+
  geom_line() + 
  geom_hline(yintercept=.8)
```

### Integrated score?

```{r integrated score outcome calc}
exp1_outcome_int_score

clusterExport(cl, "exp1_outcome_int_score")
pblapply(27:50, \(size){
  map_df(1:900,\(x){
    rnorm(size, 
          exp1_outcome_int_score$mdiff[str_equal(exp1_outcome_int_score$name, "BIS")],
          exp1_outcome_int_score$sd[str_equal(exp1_outcome_int_score$name, "BIS")]) -> test
    rnorm(size, 
          exp1_outcome_int_score$mdiff[str_equal(exp1_outcome_int_score$name, "lisas")],
          exp1_outcome_int_score$sd[str_equal(exp1_outcome_int_score$name, "lisas")]) -> test2
    
    t.test(rep(0,size), test, paired=T) |> 
      tidy() |>
      mutate(n = "BIS") |>
      bind_rows(
        t.test(rep(0,size), test2, paired=T) |>
          tidy() |> 
          mutate(n = "lisas")
      )
  }) |> mutate(size = size) 
}, cl = cl) |> 
  map_df(~.x) -> 
  int_sco_rep_sim

int_sco_rep_sim |> 
  summarise(
    .by = c(n, size),
    pow = mean(p.value<.05),
    across(everything(), mean)
  ) |> 
  ggplot(aes(size, pow, col = n))+
  geom_line() + 
  geom_hline(yintercept=.8)
```

## Simulate conditions (not like this either)
### 27 par varying pairs
```{r Raw score data sim func}
gen_data_raw <- function(N, obs){
  #' @param N Number of subjects
  #' @param OBS Number of observation per N

  tibble(
    id  = rep(1:N, each = obs),
    pairs = rep.int(1:obs, N),
    rt_con  = rnorm(N * obs, 
                    exp1_outcome_raw$rt[exp1_outcome_raw$con==T],
                    exp1_outcome_raw$rt_sd[exp1_outcome_raw$con==T]),
    rt_incon = rnorm(N * obs,
                    exp1_outcome_raw$rt[exp1_outcome_raw$con==F],
                    exp1_outcome_raw$rt_sd[exp1_outcome_raw$con==F]),
    pe_con = rnorm(N * obs, 
                    exp1_outcome_raw$pe[exp1_outcome_raw$con==T],
                    exp1_outcome_raw$pe_sd[exp1_outcome_raw$con==T]),
    pe_incon = rnorm(N * obs, 
                    exp1_outcome_raw$pe[exp1_outcome_raw$con==F],
                    exp1_outcome_raw$pe_sd[exp1_outcome_raw$con==F])
    )
}
```

Simulate data for 27 participants with varying diagnostic
length (varying pairs of observation).

```{r gen data for 27 participants over varying pair lengths}
#| echo: false

clusterExport(cl, c("gen_data_raw", "exp1_outcome_raw"))
pblapply(10:70, \(pairs){
  map(1:300, \(rep){
    gen_data_raw(27,pairs) |> 
      summarise(.by = id, 
                across(where(is.double), mean)) -> test
    t.test(test$pe_con, test$pe_incon, paired=T) |> 
      tidy() |> 
      mutate(.before = 1, 
             pairs = pairs, 
             rep = rep, 
             d = cohensD(test$rt_con, test$rt_incon,method = "paired"))
  })
}, cl = cl) |>
  map_df(~.x) -> 
  rep_27_samp_over_pairs

rep_27_samp_over_pairs |>
  summarise(
    .by = pairs, 
    pow = p.value<.05,
    across(everything(), mean),
  ) |>
  ggplot(aes(pairs, pow)) +
  geom_line()
```

### Varying sample size and pairs

```{r testing over varying sample sizes }
#| echo: false

if(run_simulations){
  clusterExport(cl, c("gen_data_raw", "exp1_outcome_raw"))
  pblapply(27:90, \(samp){
    map_df(1:500, \(rep){
      map_df(1:90, \(pairs){
        gen_data_raw(samp, pairs) -> test
        test |> 
          summarise(.by = id, 
                    across(where(is.double), mean)) -> test
        t.test(test$rt_con, test$rt_incon, paired=T) |> 
          tidy() |> 
          mutate(size = samp, 
                 pair = pairs,
                 rep = rep,
                 d = cohensD(test$rt_con, test$rt_incon,method = "paired"))
      })
    })
  }, cl = cl) |> 
    map_df(~.x) -> 
    mult_test
  
  mult_test |>
    summarise(
      .by = c(x, pair),
      pow = mean(p.value<.05),
      across(everything(), mean)) -> 
  sum_mult_test
  
  if(save_simulation_data){
    write_parquet(mult_test, "../data/simulations/sample_based_on_exp1_parames_by_congruency.parquet")
    write_parquet(sum_mult_test, "../data/simulations/sample_based_on_exp1_parames_by_congruency_sum.parquet")
  }
}
```

```{r}
#| echo: false
sum_mult_test |>
  filter(pair==37 | pair == 26)  |>
  # filter(pair<37, pair > 10) |>
  mutate(pair = factor(pair)) |>
  ggplot(aes(x, pow, col=pair, group=pair))+ 
  geom_line()
```

## Simulate via difference (not like this)

### Function

```{r}
gen_data <- function(N, pair.obs, eff.rt, sd.rt, eff.pe, sd.pe){
  #' @param N Number of subjects
  #' @param OBS Number of observation per N
  #' @param eff.rt  Effect size of congruency on response time
  #' @param eff.pct Effect size of congruency on proportion of correct trials 

  tibble(
    id  = rep(1:N, each = pair.obs*2),
    con = rep.int( c("con","incon"), N * pair.obs),
    rt  = rnorm(N * pair.obs * 2, 
                0 + as.integer(con=="con") * eff.rt, 
                1 - as.integer(con=="con") * sd.rt),
    pe  = rnorm(N * pair.obs * 2, 
                0 + as.integer(con=="con") * eff.pe, 
                1 - as.integer(con=="con") * sd.pe),
  ) 
}
```

### Gen data over sample size and some retests

```{r quick sim}
#| echo: false
if(run_simulations){
  clusterExport(cl, c("gen_data", "exp1_outcome"))
  
  pblapply(20:60, \(samp_size){
    map_df(1:4, \(retest){
      map_df(1:600, \(rep){
        gen_data(samp_size, retest,
          exp1_outcome$rt_d_m,
          exp1_outcome$rt_d_sd,
          exp1_outcome$pe_d_m,
          exp1_outcome$pe_d_sd
        ) -> single_dat_sim
      
        single_dat_sim |> 
          summarise(
            .by = c(id, con),
            rt_m = mean(rt),
            pe_m = mean(pe)
          ) -> single_dat_calc
        
        sim_aov_rt <- aov_car(rt_m~con + Error(id/(con)), data=single_dat_calc)
        sim_t_rt <- t.test(rt_m~con, data=single_dat_calc , paired=T, alterantive="greater") 
        
        sim_aov_pe <- aov_car(pe_m~con + Error(id/(con)), data=single_dat_calc)
        sim_t_pe <- t.test(pe_m~con, data=single_dat_calc , paired=T, alterantive="greater") 
        
        single_dat_calc |>
          pivot_wider(names_from=con, values_from = c(rt_m, pe_m)) |>
          summarise(
            m = mean(rt_m_con - rt_m_incon),
            sd = sd(rt_m_con - rt_m_incon),
            d = m / sd,
            t_p = sim_t_rt$p.value,
            aov_p = sim_aov_rt$anova_table$`Pr(>F)`,
            aov_ges = sim_aov_rt$anova_table$ges,
          ) |> 
          rename_with(~paste0("rt_",.x)) |>
          cbind( 
            single_dat_calc |>
            pivot_wider(names_from=con, values_from = c(rt_m, pe_m)) |>
            summarise(
              m = mean(pe_m_con - pe_m_incon),
              sd = sd(pe_m_con - pe_m_incon),
              d = m / sd,
              t_p = sim_t_pe$p.value,
              aov_p = sim_aov_pe$anova_table$`Pr(>F)`,
              aov_ges = sim_aov_pe$anova_table$ges,
            ) |> 
              rename_with(~paste0("pe_",.x), everything()) 
          ) |> mutate(.before=1, size = samp_size, rep = rep)
      })
    })
  }, cl = cl) |>
    map_df(~.x) -> 
    exp1_simulated_sample_sizes
  
  # write_parquet()
}
```

```{r include=FALSE}
exp1_simulated_sample_sizes
```

```{r}
exp1_simulated_sample_sizes |>
  summarise(
    .by = size, 
    rt_po = mean(rt_t_p<.05),
    pe_po = mean(pe_t_p<.05)
  ) |>
  ggplot(aes(size, pe_po))+
  geom_line()
  stat_summary(geom="line")+
  
```

Increasing the amount of observations merely decreases the SD,
making all results more significant. The only value that is
approximating our results is the simulation with 1 (pair of)
observation(s).

For this reason, we need to simulate the amount of
observations we have (\~ 180 valid trials) and estimate the
experiment parameters that create the results found in
experiment 1.

## Simulate via parameters that (in the end) recreat experiment 1 results (close, but not like this)

Simulate the parameters that create the results (in the long
run).

```{r find exp1 parameters}
#| echo: false
N = 27
OBS = 180/2 # pairs
eff.rt = .17
eff.pe = .68

if(run_simulations){
  clusterExport(cl, varlist = c("N", "OBS", "eff.rt", "eff.pe"))
   # Initiate libraries in clusters
  
  pblapply(seq(1,10,.02), \(x){
    map_df(1:200, \(itr){
      tibble(
        id  = rep(1:N, each = OBS*2),
        con = rep.int( c("con","incon"), N*OBS),
        rt  = rnorm(N*OBS*2, 0 + as.integer(con=="con") * eff.rt, x),
        pe  = rnorm(N*OBS*2, 0 + as.integer(con=="con") * eff.pe, x),
      ) |> 
        summarise( 
          .by = c(id, con),
          rt = mean(rt), 
          pe = mean(pe)
        ) -> trans
        
      trans |>
        pivot_wider(names_from=con, values_from=c(rt,pe)) |>
        summarise( 
          rt = mean(rt_con-rt_incon),
          rt_sd = sd(rt_con-rt_incon),
          rt_d = rt / rt_sd,
          pe = mean(pe_con-pe_incon),
          pe_sd = sd(pe_con-pe_incon),
          pe_d = pe/pe_sd,
        ) -> val
      
      trans |>
        t.test(rt ~ con, data = _, paired = T) |>
        broom::tidy() -> rt_test
      
      names(rt_test) <- paste0("rt_", names(rt_test)) 
      
      trans |>
        t.test(pe~con, data=_, paired=T) |>
        broom::tidy() -> pe_test
      
      rt_test |>
        cbind(pe_test) |>
        cbind(val) |>
        mutate(itr = itr,
               sd = x) 
    })
  }, cl = cl) |> 
    map_df(~.x) -> finding_exp1_parameter_vals
  
  write_parquet(finding_exp1_parameter_vals, sink = "../data/simulations/finding_parameter_values_for_exp1.parquet")
  
}
```

```{r}
#| include: false

finding_exp1_parameter_vals |>
  select(rt:sd, contains("p.value")) |>
  summarise(
    .by = sd, 
    pe_pow = mean(p.value < .05),
    rt_pow = mean(rt_p.value < .05),
    across(everything(), mean)
  )
```

Closest RT parameters: mdiff = .166, sd = 2 (d = .58, pow =
80%). Closest PE parameters: mdiff = .65, sd = 7.6 (d = .59,
pow = 80%).

That is, these parameter values correspond to the results from
experiment 1 *with* 180 trials (or 90 pairs; assuming we have
exactly 90 pairs).

With this, we can simulate data for the experiment *with less
trials*.

Only the these parameter may highlight the problem with
lacking trials (i.e., post-cue trial) for the post-cue
diagnostic run.

### Small simulation with parameter estimates

```{r}
#| echo: false

l <- list( 
  rt_m  = exp1_outcome$rt_d_m,
  rt_sd = 2,
  pe_m  = exp1_outcome$pe_d_m,
  pe_sd = 7.6
)

if(run_simulations){
  clusterExport(cl, c("l", "gen_data"))

  pblapply(seq(1, 90, 1), \(pairs){
    map_df(1:300, \(itr){
      gen_data(27, pairs, l$rt_m, l$rt_sd, l$pe_m, l$pe_sd) |> 
        summarise(
          .by = c(id, con), 
          rt = mean(rt),
          pe = mean(pe)
        ) -> s_d
      
      s_d |>
        pivot_wider(names_from = con, values_from = c(rt,pe)) |>
        summarise(
          rt_m = mean(rt_con-rt_incon),
          rt_sd = sd(rt_con-rt_incon),
          rt_d = rt_m / rt_sd,
          pe_m = mean(pe_con-pe_incon),
          pe_sd = sd(pe_con-pe_incon),
          pe_d = pe_m / pe_sd,
        ) |> 
        cbind(
          t.test(rt ~ con, s_d, paired=T, alternative="greater") |>
            tidy() |> 
            select(2:3) |>
            rename(rt_stat = statistic,
                   rt_p = p.value)
        ) |>
        cbind( 
          t.test(pe ~ con, s_d, paired=T, alternative="greater") |>
            tidy() |> 
            select(2:3) |>
            rename(pe_stat = statistic,
                   pe_p = p.value)
        ) |>
        mutate(
          pairs = pairs,
          itr = itr, 
        ) |>
          select(pairs, itr, starts_with("rt"), starts_with("pe")
        )
    })
    
  }, cl = cl) |> 
    map_df(~.x) -> vary_diagnostic_lengths
  
  if(save_simulation_data){
    write_parquet(vary_diagnostic_lengths, "../data/simulations/vary_diagnostic_length.parquet")
  }
  
} 
```

```{r summary of the above }
#| include: false
vary_diagnostic_lengths |> 
  summarise(
    .by = pairs,
    rt_pow = mean(rt_p<.05),
    pe_pow = mean(pe_p<.05), 
    across(c(starts_with("rt_"), starts_with("pe_")), mean)
  ) -> sum_vary_diag_len
```

The relative power with respect to the simulated data as
calculated from the estimate parameters.

```{r}
#| echo: false

sum_vary_diag_len |> 
  pivot_longer(c(rt_pow, pe_pow)) |>
  ggplot(aes(pairs, value, col=name))+
  geom_line()+
  scale_x_continuous(breaks=seq(0,90,10))+
  scale_y_continuous(breaks=seq(0,1,.1))+
  geom_hline(yintercept = .8)+
  geom_vline(xintercept = 35, linetype="dashed")+
  geom_vline(xintercept = 35 * .75, linetype="dashed", col="red")
```

According to the simulation, it would suffice with 60 pairs
(120 trials) to have 80% power to detect a true effect.

However, assuming we have 70 trials in the post-cue run, we
will have 35 (forced) pairs (black dashed). As we will lose
25% of the trials, we are left with 26.25 pairs (red dashed),
which has a power close to 50%.

We might remedy this problem by increasing the sample size.

### Big simulation with parameter estimates

```{r}
#| echo: false
l <- list( 
    rt_m  = exp1_outcome$rt_d_m,
    rt_sd = 2,
    pe_m  = exp1_outcome$pe_d_m,
    pe_sd = 7.6
  )

if(run_simulations){
  clusterExport(cl, c("l", "gen_data"))
  
  pblapply(20:100, \(size){
    map_df(seq(1, 90, 1), \(pairs){
      map_df(1:300, \(itr){
        gen_data(size, pairs, l$rt_m, l$rt_sd, l$pe_m, l$pe_sd) |> 
          summarise(
            .by = c(id, con), 
            rt = mean(rt),
            pe = mean(pe)
          ) -> s_d
        
        s_d |>
          pivot_wider(names_from = con, values_from = c(rt,pe)) |>
          summarise(
            rt_m = mean(rt_con-rt_incon),
            rt_sd = sd(rt_con-rt_incon),
            rt_d = rt_m / rt_sd,
            pe_m = mean(pe_con-pe_incon),
            pe_sd = sd(pe_con-pe_incon),
            pe_d = pe_m / pe_sd,
          ) |> 
          cbind(
            t.test(rt ~ con, s_d, paired=T, alternative="greater") |>
              tidy() |> 
              select(2:3) |>
              rename(rt_stat = statistic,
                     rt_p = p.value)
          ) |>
          cbind( 
            t.test(pe ~ con, s_d, paired=T, alternative="greater") |>
              tidy() |> 
              select(2:3) |>
              rename(pe_stat = statistic,
                     pe_p = p.value)
          ) |>
          mutate(
            size = size,
            pairs = pairs,
            itr = itr, 
          ) |>
            select(size, pairs, itr, starts_with("rt"), starts_with("pe")
          )
      })
    })
  }, cl = cl) |> 
    map_df(~.x) -> diag_lens_over_samp_sizes

  # summarise  
  diag_lens_over_samp_sizes |>
    summarise(
      .by = c(size, pairs), 
      rt_pow = mean(rt_p<.05), 
      pe_pow = mean(pe_p<.05), 
      across(where(is.double), mean)
    ) -> sum_diag_lens_over_samp_sizes
  
  if(save_simulation_data){
    write_parquet(diag_lens_over_samp_sizes, "../data/simulations/diag_lens_over_sample_sizes.parquet")
    write_parquet(sum_diag_lens_over_samp_sizes, "../data/simulations/diag_lens_over_sample_sizes_sum.parquet")
  }
} 
```

```{r big simu general overview}
#| echo: false
sum_diag_lens_over_samp_sizes |>
  pivot_longer(c(rt_pow, pe_pow)) |>
  # filter(pairs %in% c(27, 36)) |>
  ggplot(aes(size, value, col=pairs, group=pairs))+
  facet_wrap(~name)+
  geom_line()+
  geom_hline(yintercept=.8)
```

Power of RT over sample size and 36 (72 trials) and 27 pairs
(54 trials):

```{r}
#| echo: false

sum_diag_lens_over_samp_sizes |>
  filter(pairs %in% c(27, 36)) |>
  pivot_longer(c(rt_pow, pe_pow)) |>
  ggplot(aes(size, value, col=interaction(pairs, name), group=interaction(pairs,name)))+
  # facet_wrap(~name)+
  geom_line()+
  geom_smooth()+
  geom_hline(yintercept=.8)+
  geom_vline(xintercept=45)
```

By simulating data according to the estimated parameters, we
require around 45 participants to achieve 80% power for PE. RT
would require closer to 55 participants.

### Simulate integrated score

```{r stopp cluster end }
#| include: false
if(run_simulations){ stopCluster(cl) }
```

--------------------------------------------------------------

~Document generated `r Sys.time())`~
