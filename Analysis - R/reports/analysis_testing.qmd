---
title: "exp1_results"
format: docx
lang: en-GB
editor: 
  markdown:
      wrap: 62
---

```{r libraries }
#| include: FALSE
library(tidyverse)
library(ggpp)
library(gt)
library(patchwork)
library(BayesFactor)
library(bayestestR)
library(lsr)
source("../lib/helper_functions.R")
```

```{r load data }
#| include: FALSE
list.files("../data/raw/experiment1/pilots", pattern = "*.csv", full.names = T) -> fnames

fnames2 <- fnames[str_detect(fnames, "2024")][5:6]
map_df(fnames2, \(x){
  read_csv(x)
}) -> data
```

```{r transformation}
#| include: FALSE
# Pre-transformation
data |>
  mutate(rt = as.integer(ifelse( rt == "null", NA, rt ))) -> data

# Select the relevant columns & rows
data |>
  select(id, trial_info, inducer_run, correct_response, rt, congruent) |>
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial") |>
  # Filter the first inducer run (combined practice)
  filter(inducer_run != 0) -> d
```

```{r exclusion start - accuracy}
#| include: FALSE
loss <- list()
loss$data_trials <- nrow(d)

# d |> filter(inducer_run > 0) -> d
  # Pilot removing

### Overall accuracy      ====
d |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  summarize( acc = sum(correct_response, na.rm = TRUE) / length( !is.na(correct_response) ) ) |>
  filter( acc < .7 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( d$rt[d$id == loss$exclude_par] )
loss[["exclude_par_pct"]] <- length( d$rt[d$id == loss$exclude_par] ) / loss$data_trials * 100

d |> filter( !(id %in% loss$exclude_par) ) -> d
```

In total, `r length(loss[["exclude_par"]])`
`r ifelse(length(loss[["data_trials"]]) > 1, "participants", "participant")`
where excluded due to low accuracy (\> 70%). Resulting in a
loss of `r loss[["exclude_par_pct"]]` percent of the data.

```{r due to high SD & NA responses }
#| include: FALSE
# Removing trials more than 2.5 SD (from individual mean) & NA RT 
d |>
  group_by(id) |>
  mutate(rt_crit = ifelse( trial_info == "Diagnostic trial",
                           mean( rt, na.rm = TRUE ) + sd( rt, na.rm = TRUE ) * 2.5,
                           NA ),
         retain_trials = ifelse(
           # Remove deviations more than 2.5 SD
           rt >= rt_crit & trial_info == "Diagnostic trial" |
             # AND remove slow responses
             is.na(rt) & trial_info == "Diagnostic trial",
                             0, 1 ) ) -> d

sum(d$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_pct"]]

d |> 
  filter( retain_trials == 1 ) -> d
```

Furthermore, `r loss[["rt_sd_trials"]]` trials were lost due
to deviating (2.5 SD) response times and none response(s).
Representing a loss of `r round(loss[["rt_sd_pct"]], 2)`
percent of the data.

```{r only correct inducers}
#| include: FALSE
d |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d

sum(d$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_pct"]]

d |> filter( valid_trials == 1 ) -> d
```

Lastly, `r round(loss[["inducer_fail_trials"]], 2)` trials
were removed due to a wrong response on the inducer trial.
Representing a loss of
`r round(loss[["inducer_fail_pct"]], 2)` percent of the data.

A total of
`r loss$exclude_par_trials + loss$rt_sd_trials + loss$inducer_fail_trials`
trials were lost. Representing a loss of
`r round(loss$exclude_par_pct + loss$rt_sd_pct + loss$inducer_fail_pct, 2)`
percent of the data.

```{r}
#| include: FALSE
# data summary
d |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id, congruent) |>
  summarize(rt = mean(rt, na.rm = TRUE),
            pct = sum(correct_response==1) / length(correct_response)) |>
  pivot_wider( names_from = congruent, values_from = c(rt, pct) ) |>
  ungroup() -> d2
```

```{r RT tables}
#| echo: false

# Freq:
## response times
rt_test <- t.test( d2$rt_FALSE, d2$rt_TRUE, paired = TRUE, alternative = "greater" )
rt_test_b <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = T, iterations = 10000, posterior = F )
rt_test_b2 <- ttestBF( d2$rt_FALSE, d2$rt_TRUE, paired = T, iterations = 10000, posterior = T )
rt_test_hdi <- hdi(rt_test_b2)
  # weird if this is how you have to do it
d2 |>
  summarise(
    name = "RT",
    m_incongruent = mean(rt_FALSE),
    sd_incongruent = sd(rt_FALSE),
    incon_comb = paste0( fmt_APA_num(m_incongruent), " (", fmt_APA_num(sd_incongruent), ")" ),
    m_congruent = mean(rt_TRUE),
    sd_congruent = sd(rt_TRUE),
    con_comb = paste0( fmt_APA_num(m_congruent), " (", fmt_APA_num(sd_congruent), ")" ),
    Mdiff = mean( rt_FALSE - rt_TRUE),
    t = rt_test$statistic,
    df = rt_test$parameter,
    p = rt_test$p.value,
    p.cor = p.adjust(p, "bonferroni", n=2),
    b.est = mean(rt_test_b2[,"mu"]),
    hdi = paste0("[", fmt_APA_num(rt_test_hdi$CI_low[1]),", ", fmt_APA_num(rt_test_hdi$CI_high[1]),"]"),
    bf = extractBF(rt_test_b)$bf,
    d = cohensD(rt_FALSE, rt_TRUE, method = "corrected"),
    )  -> d_rt

## proportion correct trials
pct_test <- t.test(  d2$pct_FALSE, d2$pct_TRUE, paired = TRUE, alternative = "less" )
pct_test_b <- ttestBF( d2$pct_FALSE, d2$pct_TRUE, paired = T, iterations = 10000, posterior = F )
pct_test_b2 <- ttestBF( d2$pct_FALSE, d2$pct_TRUE, paired = T, iterations = 10000, posterior = T )
pct_test_hdi <- hdi(pct_test_b2)
  # weird if this is how you have to do it

d2 |>
  summarise(
    name = "PCT",
    m_incongruent = mean( pct_FALSE ),
    sd_incongruent = sd( pct_FALSE ),
    incon_comb = paste0( fmt_APA_num(m_incongruent), " (", fmt_APA_num(sd_incongruent), ")" ),
    m_congruent = mean( pct_TRUE ),
    sd_congruent = mean( pct_TRUE ),
    con_comb = paste0( fmt_APA_num(m_congruent), " (", fmt_APA_num(sd_congruent), ")" ),
    Mdiff = mean( pct_FALSE - pct_TRUE ),
    t = pct_test$statistic,
    df = pct_test$parameter,
    p = pct_test$p.value,
    p.cor = p.adjust(p, "bonferroni", n=2),
    b.est = mean(pct_test_b2[,"mu"]),
    hdi = paste0("[",fmt_APA_num(pct_test_hdi$CI_low[1]),", ", fmt_APA_num(pct_test_hdi$CI_high[1]),"]"),
    bf = extractBF(pct_test_b)$bf,
    d = cohensD(pct_FALSE, pct_TRUE, method = "corrected"),
  ) -> d_pct

```


## Diagnostic table
```{r stat table}
#| echo: false
rbind(d_rt, d_pct) -> b
b |> summarize(x=sum(df)/length(df)) |> pull() -> d2_df
b |> pull(p) |> min() -> p_min

if(d2_df != floor(d2_df)){warning("NOT SIMILAR, CHECK DF")}
  # degrees of freedom

rbind(d_rt, d_pct) |>
  mutate(ps = case_when(p.cor < .05 ~ "*", p < 0.01 ~ "**", p < 0.001 ~ "***", T ~ ""),
         Mdiff = paste0(fmt_APA_num(Mdiff), ps),
         em1 = "", em2="", em3="") |>
  gt() |>
  cols_hide(c(p, t, df, p.cor, ps, m_incongruent, sd_incongruent, m_congruent, sd_congruent)) |>
  tab_spanner(  "Incongruent", incon_comb )  |>
  cols_label(   incon_comb = md("*M* (*SD*)") ) |> 
  tab_spanner(  "Congruent", con_comb ) |> 
  cols_label(   con_comb = md("*M* (*SD*)") |> 
  tab_spanner(  "Bayes", c(b.est, bf, hdi)) |>
  cols_label(   b.est = md("*M*"), bf = md("BF~10~"), hdi = "HDI", # html("BF<sub>10</sub>")
                Mdiff = md("*M*~diff~") )  |> # html("<i>M</i><sub>diff</sub>") 
  #fmt_markdown() |>
  cols_move(    "ps", Mdiff ) |> 
  cols_move(    "em1", sd_incongruent ) |>
  cols_move(    "em2", ps ) |>
  cols_hide(     ) |> 
  cols_label(   em1="",em2="", name = "", d = md("*d*"), em3="") |>
  cols_align(   "center", c(2:15)) |> 
  cols_move(    "em3", hdi) |>
  fmt_number()

```
*Note.* P's are Bonferroni corrected for 2 tests. The tests
have `r  d2_df` degrees of freedom.  \n
`r fmt_APA_p_table_fig(p_min)` \n
*M* = Mean, *SD* = standard deviation, *M*~diff~ = Differences
of the means, HDI = highest density interval, *d* = Effect size.



```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 250

# This way of visualizing is not necessarily the best -- it can illustate each
# change in data (congruent/incongruent), but summary score should not be used with it

d |>
  filter(!is.na(congruent)) |>
  group_by(id, congruent) |>
    # ????????????????  inducer_run
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con = ifelse(congruent==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con, y = rt, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .3)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .3)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .5)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(450, 750))+
                        # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Response time", x = "", y = "Response time (ms)") -> p1


d |>
  filter(!is.na(congruent)) |>
  group_by(id, congruent) |>
    # ????????????????  inducer_run
  summarize(pct = mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con = ifelse(congruent==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con, y = pct, group=id, col = factor(con)))+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "point", fun = mean, alpha = .3)+
  stat_summary(aes(col=NULL), position=position_dodge(.1), geom = "line", fun = mean, alpha = .3)+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5, alpha = .5)+
  stat_summary(aes(group=NULL, col=NULL), fun.data = mean_se, geom = "point", size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(.75, 1.01))+
                      # Adjust
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Proportion of correct trials", x = "", y = "Proportion") -> p2

p1+p2
```



```{r}
#| echo: false
#| warning: false
#| message: false
#| error: false
#| fig-dpi: 250

d |>
  filter(!is.na(congruent)) |>
  group_by(id, congruent) |>
    # ????????????????  inducer_run
  summarize(rt = mean(rt)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con = ifelse(congruent==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con, y = rt,fill = factor(con)))+
  stat_summary(fun = mean, geom = "col")+
  stat_summary(fun.data = mean_se, geom = "errorbar", width = .2, size = 1.5, alpha = 1)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,2000,50), minor_breaks = NULL)+
  coord_cartesian(ylim = c(450, 760))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Response time", x = "", y = "Response time (ms)") -> p1

d |>
  filter(!is.na(congruent)) |>
  group_by(id, congruent) |>
    # ????????????????  inducer_run
  summarize(pct = mean(correct_response)) |>
    # Summarize the proportion of correct per block
  ungroup() |>  
  mutate(con = ifelse(congruent==T,1,0)) |>
  #mutate(con = ifelse(congruent==TRUE,1,0)) |>
  ggplot(aes(x = con, y = pct, fill = factor(con)))+
  stat_summary(fun=mean, geom="col")+
  stat_summary(aes(group=NULL), fun.data = mean_se, geom = "errorbar", width=.2, size = 1.5)+
  scale_x_continuous(breaks = c(0,1), labels = c("Incongruent", "Congruent"), name="",
                     expand = c(.2,.2), minor_breaks = NULL)+
  scale_y_continuous(breaks = seq(0,1,.05), minor_breaks = NULL)+
  coord_cartesian(ylim = c(.75, 1.01))+
                        # Adjust? 
  theme_minimal()+
  theme(axis.text.x = element_text(size = 10), legend.position = "none")+
  labs(title = "Proportion of correct trials", x = "", y = "Proportion") -> p2

p1+p2
```


```{r}
d_ind <- 
  data |> 
  select(id, trial_info, inducer_run, correct_response, rt) |>
  filter(trial_info == "Inducer trial" | trial_info=="Inducer instructions" ) |>
  filter(inducer_run > 0) |>
  pivot_wider(names_from = trial_info, values_from = c(correct_response, rt)) |> 
  mutate(instructions = ifelse(is.na(`rt_Inducer instructions`)>20000, 20000, `rt_Inducer instructions`),
         trial = ifelse(is.na(`rt_Inducer trial`), 2000, `rt_Inducer trial` ))


d_ind |> 
  group_by(`correct_response_Inducer trial`) |>
  summarize(cor = cor(instructions, trial),
            #correct = mean(`correct_response_Inducer trial`), 
            instructions =  mean(instructions),
            trial = mean(trial),
            ) #|>
  ungroup()# |>
  summarize(cor = cor(trial, instructions))

d_ind |> 
  pivot_wider(names_from = trial_info, values_from = c(correct_response, rt)) |>
  mutate(instructions = ifelse(is.na(`rt_Inducer instructions`)>20000, 20000, `rt_Inducer instructions`),
         trial = ifelse(is.na(`rt_Inducer trial`), 2000, `rt_Inducer trial` )) |>
  ggplot(aes(instructions, trial, col = id)) +
  geom_point()+
  geom_smooth(method=lm)+
  labs(y = "Trial response time (ms)", x = "Instruction response time (ms)")+
  scale_x_continuous(breaks=seq(0,20000,1000))+
  theme(legend.position = "none")+
  coord_cartesian(ylim=c(0,2000))
```


```{r}

```








