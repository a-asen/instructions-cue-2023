  ---
title: "Experiment 2 post-cue sampling"
format: docx
lang: en-GB
title: "Diag simulation"
editor: 
  markdown:
      wrap: 62
---


# Sampling from experiment 1

First we can sample effects from experiment 1.

```{r}
#| include: false
load("../data/trans/exp1_data.rdata")
load("../data/sim/diagnostic_length_simulation.rdata")

library(tidyverse)
library(lsr)
library(pbapply)
library(afex)
library(gt)

run_create_animations <- FALSE
run_create_simulations <- FALSE
```

```{r}
#| echo: false
d <-
  exp1_d |>
  dplyr::select(id, trial_info, inducer_run, diagnostic_run, correct_response, rt, con) |>
  filter(trial_info == "Diagnostic trial" | trial_info == "Inducer trial") |>
  filter(!is.na(correct_response)) |>
  mutate(rt = as.integer(rt)) 
```

```{r}
#| echo: false
#| warning: false
#| message: false
d |>
  filter(diagnostic_run <5) |>
  dplyr::group_by(id, con) |>
  summarise(rt = mean(rt, na.rm=T),
            pct = mean(correct_response,na.rm=T)) |>
  pivot_longer(c(rt,pct)) |>
  ggplot(aes(con, value))+
  facet_wrap(~name, scales ="free")+
  stat_summary()
```
Congruency present for raw data.


```{r}
#| echo: false
diag_trials <-
  d |>
  filter(diagnostic_run<17) |>
  ungroup()
```


First, I will test how many diagnostic trials we need to find a sig difference, based on the results we already have. 
```{r}
map_df(seq_along(1:16), \(x){
  diag_trials |>
    filter(diagnostic_run<x) |>
    group_by(id, con) |>
    summarise(
      rt = mean(rt),
      pct = mean(correct_response) ) |> 
    ungroup() |>
    summarise(
      n = x,
      est = t.test(rt~con, paired=T)$estimate,
      t = t.test(rt ~ con, paired=T)$statistic,
      p = t.test(rt ~ con, paired=T)$p.value,
      df = t.test(rt ~ con, paired=T)$parameter,
      )
}) -> n_back_test
n_back_test |>
  ggplot(aes(n, p))+
  geom_line()+
  geom_hline(yintercept=.05)
```
Sampling from all blocks, across all participants, we appear to need between 8-10 trials (per block) to find a significant congruency effect. 

Now I will attempt to see how many diagnostic trials are necessary to find the congruency effect through random sampling of the data from experiment 1. 
```{r}
#| echo: false
#| message: false
#| warning: false
#| error: false
stat_test <- function(size){
  # n = size 
  
  slice_sample(diag_trials, by = c(id, con), n = size) |>
    group_by(id, con) |>
    summarise(l = length(rt),
              rt = mean(rt),
              pct = mean(correct_response)) |>
    ungroup() |>
    pivot_wider(names_from=con, values_from=c(l, rt,pct)) |>
    reframe(
      n = size,
      rt_con = mean(rt_TRUE, na.rm=T),
      rt_incon = mean(rt_FALSE, na.rm=T),
      rt_est  = mean(rt_FALSE-rt_TRUE, na.rm=T),
      rt_t  = t.test(rt_FALSE, rt_TRUE, paried=T, na.rm=T)$statistic,
      rt_p  = t.test(rt_FALSE, rt_TRUE, paried=T, na.rm=T)$p.value,
      rt_d = cohensD(rt_FALSE, rt_TRUE, method="corrected"),
      pct_con = mean(pct_TRUE, na.rm=T),
      pct_incon = mean(pct_FALSE, na.rm=T),
      pct_est  = mean(pct_FALSE-pct_TRUE, na.rm=T),
      pct_t  = t.test(pct_FALSE, pct_TRUE, paried=T, na.rm=T)$statistic,
      pct_p  = t.test(pct_FALSE, pct_TRUE, paried=T, na.rm=T)$p.value,
      pct_d = cohensD(pct_FALSE, pct_TRUE, method="corrected")
    )
}
```

```{r}
map_df(1:50, \(x){
  stat_test(x)
}) -> sample1 

sample1 |>
  ggplot(aes(n, rt_p))+
  geom_line()
```

Generally this appears to be unstable. The increase in diagnostic trials does not appear to change the significance at all. Weird.

To solve this, we can repeat each sampling of a particular size a couple of times to average the differences.
```{r}
#| echo: false
#| error: false
#| warning: false
#| message: false
rep_test <- function(maxdiag, rep){
  # range = number of diagnostics
  # rep = how many times we repeat the same sampling

  map_df(1:maxdiag, \(x){
    # for each diag we repeat the diag length "rep" times
    map_df(1:rep, \(y){
      stat_test(x)
    })
  })
}
rep_test(50, 30) -> sample2
  # From 1 to 50 diagnostic trials, repeat each 20 times. 
sample2 |>
  ggplot(aes(n, rt_p))+
  stat_summary()
```


```{r}
sample2 |>
  ggplot(aes(n, rt_d))+
  stat_summary()
```
This did not appear to solve the problem at all. 

I suspect there is some unequalness with the sampling... 
We can move over to generated data to see how increased samples "should" trend the data towards more significant differences. 


## Expected loss of diagnostic trials:

```{r loss est}
#| echo: false
d -> d_ex
loss <- list()
loss$data_trials <- nrow(d_ex)

# accur
d_ex |>
  filter( trial_info == "Diagnostic trial" | trial_info == "Inducer trial" ) |>
  group_by( id ) |>
  mutate( correct_response = ifelse( trial_info=="Inducer trial" & is.na(rt), 0, correct_response) ) |>
    #' !  Non-responses count as a wrong response & are subject to the exclusion criteria.  !
  summarise( acc = sum(correct_response, na.rm = TRUE) / length( !is.na(correct_response) ) ) |>
  filter( acc < .7 ) |>
  pull( id ) -> loss$exclude_par

loss[["exclude_par_trials"]] <- length( d_ex$rt[d_ex$id == loss$exclude_par] )
loss[["exclude_par_pct"]]    <- length( d_ex$rt[d_ex$id == loss$exclude_par] ) / loss$data_trials * 100

d_ex |> filter( !(id %in% loss$exclude_par) ) -> d_ex
# rt dev+miss
d_ex |>
  mutate(rt = as.integer(rt)) |>
  ungroup() |>
  group_by(id) |>
  mutate(
    rt_crit = ifelse( 
      trial_info == "Diagnostic trial",
      mean( rt ) + sd( rt ) * 2.5,
      NA ),
      retain_trials = ifelse(
        (rt > rt_crit & trial_info == "Diagnostic trial") | # **OR**
          (is.na(rt) & trial_info == "Diagnostic trial"),
        0, 1 ) 
    ) -> d_ex

sum(d_ex$retain_trials == 0) -> loss[["rt_sd_trials"]]
sum(d_ex$retain_trials == 0) / loss$data_trials * 100 -> loss[["rt_sd_pct"]]

d_ex |> 
  filter( retain_trials == 1 ) -> d_ex
# inducers:
d_ex |>
  mutate( valid_trials = case_when( trial_info=="Inducer trial" & correct_response==1 ~ 1,
                                    trial_info=="Inducer trial" & correct_response==0 ~ 0,
                                    trial_info=="Inducer trial" & is.na(correct_response) ~ 0,
                                      # non-responses count as a wrong response
                                    T ~ NA ) ) |>
  fill(valid_trials, .direction = "up") -> d_ex

sum(d_ex$valid_trials==0) -> loss[["inducer_fail_trials"]]
sum(d_ex$valid_trials==0) / loss$data_trials * 100 -> loss[["inducer_fail_pct"]]

d_ex |> filter( valid_trials == 1 ) -> d_ex

d_ex |> 
  filter(trial_info == "Diagnostic trial") |>
  group_by(id) |>
  count()
```

The above table indicate the number of diagnostic trials that are left after all excluding trials. 

On average, this leaves us with:
```{r}
#| echo: false
d_ex |>
  filter(trial_info=="Diagnostic trial") |>
  group_by(id) |>
  count() |>
  ungroup() |>
  summarise(avg = mean(n)) |> gt()
```
trials.

This is a loss of approximately: `r 180/240`. Whatever post-cue run we decide, we need to estimate an expected loss of about .75. 



# Generating data

Generate normal distributions with a mean of 0 and a standard deviation of 1.
Effect.size adjusts the effect on the congruent trials by "eff.rt" and "eff.pct". 
(It is not necessary to have two effect size. One is sufficient)

```{r}
gen_sample <- function(N, OBS, eff.rt, eff.pct){
  #' @param N Number of subjects
  #' @param OBS Number of observation per N
  #' @param eff.rt  Effect size of congruency on response time
  #' @param eff.pct Effect size of congruency on proportion of correct trials 

  tibble(
    id = rep(1:N, each = OBS*2),
    con = rep.int( c("con","incon"), N*OBS),
    rt  = rnorm(N*OBS*2, 0 + as.integer(con=="con") * eff.rt, 1),
    pct = rnorm(N*OBS*2, 0 + as.integer(con=="con") * eff.pct, 1),
  ) 
}
```

We simulate generate data over (1) difference effect sizes for (2) various sample sizes for (3) various diagnostic lengths -- each repeated 300 times.


```{r big simulation}
#| echo: false

# You dont want to start this if you have the data.... 
if(!exists(gen_data) & run_create_simulations){
  
  library(pbapply)
  library(parallel)
  
  # Create a "cluster" to simulate faster
  # Take half the computers cores 
  makeCluster( floor(detectCores() * .90) ) -> cl # Use 90% of the available cores
  # Export the local function
  clusterExport(cl, varlist = c("gen_sample"))
  # Initiate libraries in clusters
  clusterEvalQ(cl, {
    library(tidyverse)
    library(pbapply)
    library(lsr)
  })
  
  
  # For each different effect size (*y*)...
  map_df(seq(0.05,.75, .05), \(eff.size){
    
    # For each sample size (i)...
    pblapply(10:90, \(samp_size){
    
      # For each diagnostic length (x)...
      map_df(10:90, \(diag_len){
          # diag length corresponds to pairs of diagnostic values! 
        
          # Repeat the sampling 300 times 
          map_df(1:300, \(rep){
            
            # SAMPLE....
            gen_sample(samp_size, diag_len, eff.size/4, eff.size) |> 
              group_by(id) |> 
              mutate( n = rep( 1:(length(rt)/2 ), each=2) ) |> 
              pivot_wider(names_from=con, values_from = c(rt,pct))  |> 
              ungroup() |> 
              summarise(
                eff        = eff.size, 
                size       = samp_size,
                dia.len    = diag_len,
                rep        = rep, 
                rt.con     = mean(rt_con),
                rt.incon   = mean(rt_incon),
                rt.dif     = mean(rt_incon-rt_con),
                rt.p       = t.test(rt_incon, rt_con, paired=T)$p.value,
                rt.t       = t.test(rt_incon, rt_con, paired=T)$statistic,
                rt.d       = cohensD(rt_incon, rt_con, method = "paired"),
                pct.con    = mean(pct_con),
                pct.incon  = mean(pct_incon),
                pct.dif    = mean(pct_incon-pct_con),
                pct.p      = t.test(pct_incon, pct_con, paired=T)$p.value,
                pct.t      = t.test(pct_incon, pct_con, paired=T)$statistic,
                pct.d      = cohensD(pct_incon, pct_con, method = "paired"),
                )
            
          })                   # repeat 300 
        })                       # for each diagnostic length 10:90
      }, cl = cl) |> map_df(~.x)   # for each sample size 10:90
                                     # For each effect size seq(.05, .75, .05)
    }) -> diag_simu 
  
  # # Update dia.len to correspond (b/c each len correspond to one congruent and one incongruent -- i.e., a pair of observation! )
  # diag_simu |>
  #   mutate(dia.len = dia.len*2) -> diag_simu
  
  # save(diag_simu, file = "../data/sim/diag_simu_raw.rdata")
  
  # diag_simu_sum <-
  #   diag_simu |>
  #   group_by(eff, size, dia.len) |>
  #   summarise(eff=unique(eff),
  #             size=unique(size),
  #             dia.len=unique(dia.len),
  #             rt.pow = mean(rt.p<.05),
  #             pct.pow = mean(pct.p<.05),
  #             across(c(starts_with("rt."), starts_with("pct.")), mean)
  #             )
  # save(diag_simu_sum, file="../data/sim/diag_simu_sum.rdata")
  
  # stop cluster
  stopCluster(cl)
  
} else {
  diag_simu
}
```

### Visualizing
#### animate:

```{r first animation attempt}
#| echo: false

if(run_create_animations){
  diag_simu_sum |>
    filter(eff > .10) |>
    mutate(`Effect size` = factor(eff)) |>
    ggplot(aes(dia.len, pct.pow, col = `Effect size`)) +
    geom_line() +
    geom_hline( yintercept=.9 ) +
    scale_y_continuous(breaks=seq(0,1,.1)) +
    scale_x_continuous(breaks=seq(0,100,5)) +
    coord_cartesian(ylim=c(.5, 1), expand = F) +
    labs(title = "Diagnostic length: {size}", y = "Power", x="Sample size") +
    theme_minimal() +
    transition_time(size) +
    ease_aes("linear") -> p_ani
  # Save
  anim_save("../figs/anim/anim1.gif", p_ani, path="./")
}
```

Animate the impact of increasing the sample size (see [LINK]). 

```{r animate sample size increases}
#| echo: false
#| message: false

# This animates power of various diagnostic lengths over different sample sizes: 
if(run_create_animations){
  walk(seq(min(diag_simu_sum$size), max(diag_simu_sum$size), 1), \(x){
    #cat("\nSample size:", x)
    p <- 
      diag_simu_sum |>
      filter(size == x) |>
      filter(eff < .45) |>
      mutate(`Effect size` = factor(eff)) |>
      ggplot(aes(dia.len, pct.pow, col = `Effect size`)) +
      geom_line() +
      geom_hline( yintercept = .9 ) +
      scale_y_continuous(breaks = seq(0, 1, .1)) +
      scale_x_continuous(breaks = seq(0, 300, 10)) +
      coord_cartesian(ylim=c(.5, 1), expand = F) +
      labs(title = paste0("Sample size: ", x), y = "Power", x="Diagnostic length") +
      theme_minimal()+
      theme(plot.background = element_rect(colour="white"))
    
      ggsave(plot = p, filename = paste0("../figs/anim/anim2/anim_diag_", x, ".png"),
            width = 7, heigh = 5) 
  })
  
  # get path to graphs
  list.files("../figs/anim/anim2/", full.names = T) -> figfnames
  # fix arrangement
  tibble(figfnames) |>
    mutate(arr = as.integer( str_split(figfnames, "[_.]") |> map_chr(5) )) |>
    arrange(arr) |>
    pull(figfnames) -> o_figfnames
  
  # create gif
  gifski(o_figfnames, "../figs/anim/anim_sample_size_increase.gif", delay = .25)
  
  # create video format
  av_encode_video(o_figfnames, "../figs/anim/anim_sample_size_increase.mkv", framerate = 4)
}
```

Animate the impact of changes in diagnostic lengths (see [LINK]).

```{r animate diagnostic increases}
#| echo: false
#| message: false
#| warning: false
#| messages: false

# This the power the power over sample size split by loss of data

walk(seq(56, max(diag_simu_sum$dia.len), 2), \(x){
  #cat("\nDiag length: ",x )  
  samp_size <- 30
  loss <- .75
  
  diag_length_adj   <- ifelse( (x/2) %% 2 == 0, floor( x/2 ), floor( x/2 - 1 ) )
  diag_length_adj_l <- ifelse(floor(diag_length_adj*loss) %% 2 == 0, 
                              floor( diag_length_adj*loss ), floor( diag_length_adj*loss-1 ) ) 
  diag_simu_sum |>
    filter(eff < .45) |>
    filter(dia.len == diag_length_adj |
             dia.len == diag_length_adj_l) |>
    group_by(eff, size) |>
    mutate(`Effect size` = factor(eff),
           dia.len = dia.len * 2 ) |>
    ggplot(aes(size, pct.pow, col = `Effect size`))+
    facet_wrap(~ dia.len)+
    # geom_smooth() +
    geom_line() +
    geom_hline(yintercept = .9)+
    geom_vline(xintercept = samp_size) +
    scale_x_continuous(breaks = seq(0, 100, 10)) +
    scale_y_continuous(breaks = seq(0, 100, .1)) +
    labs(
      x = "Sample size", y = "Power",
      subtitle = paste("Diagnostic length: ", x,"\n
                        25 % loss                                                 Original")
                       ,
    )+
    theme_minimal()+
    coord_cartesian(ylim=c(.5, 1), expand =.0001) +
    theme(plot.background = element_rect(colour="white")) -> p
  
    ggsave(plot = p, filename = paste0("../figs/anim/anim3/anim_diag_", x, ".png"),
          width = 7, heigh = 5, dpi = 300) 
})
# get list
list.files("../figs/anim/anim3/", full.names = T) -> figfnames
tibble(figfnames) |>
  mutate(arr = as.integer( str_split(figfnames, "[_.]") |> map_chr(5) )) |>
  arrange(arr) |>
  pull(figfnames) -> o_figfnames

gifski(o_figfnames, "../figs/anim/anim_diag_len_increase.gif", delay = .25)

av_encode_video(o_figfnames, "../figs/anim/anim_diag_len_increase.mkv", framerate = 4)
""
```

In the plot below we can see how the set diagnostic limit (right) and then the diagnostic limit after the assumed exclusion (left). 

#### Visualize
```{r}
#| echo: false

samp_size <- 30
diag_length <- 60
loss <- .75

diag_length_adj   <- ifelse(round(diag_length/2) %% 2 == 0, floor( diag_length/2 ), floor( diag_length/2-1 ) )
diag_length_adj_l <- ifelse(floor(diag_length_adj*loss) %% 2 == 0, 
                            floor( diag_length_adj*loss ), floor( diag_length_adj*loss-1 ) ) 
diag_simu_sum |>
  filter(eff < .45) |>
  filter(dia.len == diag_length_adj |
           dia.len == diag_length_adj_l) |>
  group_by(eff, size) |>
  mutate(`Effect size` = factor(eff),
         dia.len = dia.len * 2 ) |>
  ggplot(aes(size, pct.pow, col = `Effect size`))+
  facet_wrap(~ dia.len)+
  # geom_smooth() +
  geom_line() +
  geom_hline(yintercept = .9)+
  geom_vline(xintercept = samp_size) +
  scale_x_continuous(breaks = seq(0, 100, 10)) +
  scale_y_continuous(breaks = seq(0, 100, .1)) +
  labs(
    x = "Sample size", y = "Power",
    subtitle = "Left plot corresponds to the right plot after data exclusion",
  )
```

Assuming a sample size of 30 participants, we can achieve 90% power with an effect size of about .2 (right plot). However, considering the expected loss of around 25%, we are left with 44 trials (left; rounded to the closest pair), rather than 60. This reduces the power to just under .8. 
Granted the arbitrary loss of data, we may be left with deviating lengths of congruent and incongruent trials. In other words, we should overshoot a couple of trials to ensure sufficient pairs.

We have to solution too the lacking power: Increase the sample size or increase the number of diagnostic trials. Regarding the diagnostic trials, we are weary of adding too many diagnostic trials given that the cue is supposed to signal "sooner-rather-than-later" switching. Increasing the number of diagnostic trials might influence the utility of the cue. 

The plot below visualizes the effect size across diagnostic length for a sample size of 30.  

```{r}
#| echo: false

samp_size <- 30
diag_length <- 70
diag_loss <- .75

diag_simu_sum |> 
  filter(eff < .3) |>
  filter(size == samp_size) |>
  mutate(`Effect size` = factor(eff) ) |>
  ggplot(aes(dia.len, pct.pow, col = `Effect size`))+
  # geom_smooth() +
  geom_line() +
  geom_hline(yintercept = .9)+
  geom_vline(xintercept = diag_length * diag_loss, linetype = "dashed") +
  geom_vline(xintercept = diag_length) +
  scale_x_continuous(breaks = seq(0, 500, 10) ) +
  scale_y_continuous(breaks = seq(0, 100, .1) ) +
  labs(
    x = "Diagnostic length", 
    y = "Power",
    subtitle = paste0("Sample size: ", samp_size, 
                      # "   Diagnostic length: ", diag_length, 
                      # "   Diagnostic pairs: ", diag_length/2,
                      "   Loss of: ", diag_loss),
    caption = "Horizontal line correspond to 90% power. \n
    Solid vertical line correspond to the set diagnostic length. \n
    Dashed vertical line correspond to the estimated remaining trials after exclusion (trials*loss)")
```

Exactly counteract the loss (60 * 1.25):

```{r}
#| echo: false

samp_size <- 30
diag_length <- 70
diag_loss <- .75

diag_simu_sum |> 
  filter(eff < .3) |>
  filter(size == 30) |>
  mutate(`Effect size` = factor(eff) ) |>
  ggplot(aes(dia.len, pct.pow, col = `Effect size`))+
  facet_wrap(~size)+
  geom_line() +
  geom_hline(yintercept = .9)+
  geom_vline(xintercept = diag_length * diag_loss, linetype = "dashed") +
  geom_vline(xintercept = diag_length) +
  scale_x_continuous(breaks = seq(0, 500, 10) ) +
  scale_y_continuous(breaks = seq(0, 100, .1) ) +
  labs(
    x = "Diagnostic length", 
    y = "Power",
    subtitle = paste0("Sample size: ", samp_size, 
                      # "   Diagnostic length: ", diag_length, 
                      # "   Diagnostic pairs: ", diag_length/2,
                      "   Loss of: ", diag_loss),
    caption = "Horizontal line correspond to 90% power. \n
    Solid vertical line correspond to the set diagnostic length. \n
    Dashed vertical line correspond to the estimated remaining trials after exclusion (trials*loss)")
```

Try larger sample:

```{r}
#| echo: false
samp_size <- c(30,34)
diag_length <- 70
diag_loss <- .75

diag_simu_sum |> 
  filter(eff < .3) |>
  filter(size %in% samp_size) |>
  mutate(`Effect size` = factor(eff) ) |>
  ggplot(aes(dia.len, pct.pow, col = `Effect size`)) +
  facet_wrap(~ size)+
  geom_line() +
  geom_hline(yintercept = .9)+
  geom_vline(xintercept = diag_length * diag_loss, linetype = "dashed") +
  geom_vline(xintercept = diag_length) +
  scale_x_continuous(breaks = seq(0, 500, 25) ) +
  scale_y_continuous(breaks = seq(0, 100, .1) ) +
  labs(
    x = "Diagnostic length", 
    y = "Power",
    subtitle = paste0("Split by sample sizes ", paste(samp_size, collapse = " & "), 
                      "\nDiagnostic length: ", diag_length,
                      "     Loss: ", diag_loss, "   =~ ", floor(diag_length*.75)),
    caption = "Horizontal line correspond to 90% power. \n
    Solid vertical line correspond to the set diagnostic length. \n
    Dashed vertical line correspond to the estimated remaining trials after exclusion (trials*loss)")
```

With 34 participants and 70 trials of the post-cue diagnostic runs, we will have about 90% power to detect a small effect of .15. A good compromise.

It should be noted that it might not be necessary to expect such a small effect size. Indeed, the integrated scores suggest that we may expect an effect size of about .4. Which would show a significant effect at much less:

```{r}
#| echo: false
samp_size <- c(20,30)
diag_length <- 60
diag_loss <- .75

diag_simu_sum |> 
  filter(eff <.5, eff>.2) |>
  filter(size %in% samp_size) |>
  mutate(`Effect size` = factor(eff) ) |>
  ggplot(aes(dia.len, pct.pow, col = `Effect size`)) +
  facet_wrap(~size) +
  geom_line() +
  geom_hline(yintercept = .9)+
  geom_vline(xintercept = diag_length * diag_loss, linetype = "dashed") +
  geom_vline(xintercept = diag_length) +
  scale_x_continuous(breaks = seq(0, 500, 20) ) +
  scale_y_continuous(breaks = seq(0, 1, .1) ) +
  labs(
    x = "Diagnostic length", 
    y = "Power",
    subtitle = paste0("Sample size:", paste(samp_size, collapse=" & "), 
                      "\nDiagnostic length: ", diag_length,
                      "     Loss: ", diag_loss, "   =~ ", floor(diag_length*.75)))
```

Expecting an effect size of .4 would essentially mean that we could detect a significant effect with very few participants and very few observations. For our purposes, we will attempt to find an effect even on response times, which we found to be .17 in experiment 1. 


